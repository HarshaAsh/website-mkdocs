<!doctype html><html lang=en class=no-js> <head><script>
      (function () {
        var adsLoaded = false;

        function loadAds() {
          if (adsLoaded) return;
          adsLoaded = true;

          var ads = document.createElement("script");
          ads.async = true;
          ads.src = "https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8786690539845043";
          ads.crossOrigin = "anonymous";
          document.head.appendChild(ads);

          var amp = document.createElement("script");
          amp.async = true;
          amp.setAttribute("custom-element", "amp-auto-ads");
          amp.src = "https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js";
          document.head.appendChild(amp);

          var autoAds = document.createElement("amp-auto-ads");
          autoAds.setAttribute("type", "adsense");
          autoAds.setAttribute("data-ad-client", "ca-pub-8786690539845043");
          document.body.appendChild(autoAds);
        }

        function onFirstInteraction() {
          loadAds();
          removeListeners();
        }

        function removeListeners() {
          window.removeEventListener("scroll", onFirstInteraction, { passive: true });
          window.removeEventListener("mousemove", onFirstInteraction, { passive: true });
          window.removeEventListener("touchstart", onFirstInteraction, { passive: true });
          window.removeEventListener("keydown", onFirstInteraction, { passive: true });
        }

        window.addEventListener("scroll", onFirstInteraction, { passive: true });
        window.addEventListener("mousemove", onFirstInteraction, { passive: true });
        window.addEventListener("touchstart", onFirstInteraction, { passive: true });
        window.addEventListener("keydown", onFirstInteraction, { passive: true });

        window.addEventListener("load", function () {
          setTimeout(loadAds, 5000);
        }, { once: true });
      })();
    </script><script>
      (function () {
        function deferThirdParties() {
          var optimize = document.createElement("script");
          optimize.src = "https://www.googleoptimize.com/optimize.js?id=OPT-M98W6LW";
          optimize.async = true;
          document.head.appendChild(optimize);

          window._mfq = window._mfq || [];
          var mf = document.createElement("script");
          mf.type = "text/javascript";
          mf.defer = true;
          mf.src = "//cdn.mouseflow.com/projects/7b4494c9-7974-49f0-9777-d14450db37e6.js";
          document.head.appendChild(mf);
        }

        if (document.readyState === "complete") {
          deferThirdParties();
        } else {
          window.addEventListener("load", deferThirdParties, { once: true });
        }
      })();
    </script><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Mastering Probability Concepts in R. Understand probability theory through hands-on R examples covering discrete and continuous distributions."><meta name=author content="Harsha Achyuthuni"><link href=https://www.harshaash.com/R/Probability/ rel=canonical><link rel=icon href=../../assets/images/logo.jpg><meta name=generator content="mkdocs-1.6.1, mkdocs-material-7.2.4"><title>Probability amd discrete distributions - Data Science with Harsha</title><link rel=preload href=../../assets/stylesheets/main.f7f47774.min.css as=style onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel=stylesheet href=../../assets/stylesheets/main.f7f47774.min.css></noscript><link rel=preload href=../../assets/stylesheets/palette.3f5d1f46.min.css as=style onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel=stylesheet href=../../assets/stylesheets/palette.3f5d1f46.min.css></noscript><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback"></noscript><style>:root{--md-text-font-family:"Roboto";--md-code-font-family:"Roboto Mono"}</style><link rel=preload href=../../overrides/assets/stylesheets/user_defined.css as=style onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel=stylesheet href=../../overrides/assets/stylesheets/user_defined.css></noscript><script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-65034507-2","auto"),ga("set","anonymizeIp",!0),ga("send","pageview"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){var e;this.value&&(e=document.location.pathname,ga("send","pageview",e+"?q="+this.value))}),"undefined"!=typeof location$&&location$.subscribe(function(e){ga("send","pageview",e.pathname)})})</script><script async src=https://www.google-analytics.com/analytics.js></script></head> <body dir=ltr data-md-color-scheme data-md-color-primary data-md-color-accent> <script>function __prefix(e){return new URL("../..",location).pathname+"."+e}function __get(e,t=localStorage){return JSON.parse(t.getItem(__prefix(e)))}</script> <script>var palette=__get("__palette");if(null!==palette&&"object"==typeof palette.color)for(var key in palette.color)document.body.setAttribute("data-md-color-"+key,palette.color[key])</script> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer style="margin-bottom: 0;"></label> <div data-md-component=skip> <a href=#why-is-probability-important class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header style="background-color: navy;" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="Data Science with Harsha" class="md-header__button md-logo" aria-label="Data Science with Harsha" data-md-component=logo> <img src=../../assets/images/logo.jpg alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Data Science with Harsha </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Probability amd discrete distributions </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme data-md-color-primary data-md-color-accent aria-hidden=true type=radio name=__palette id=__palette_1> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_2> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M7 10a2 2 0 0 1 2 2 2 2 0 0 1-2 2 2 2 0 0 1-2-2 2 2 0 0 1 2-2m10-3a5 5 0 0 1 5 5 5 5 0 0 1-5 5H7a5 5 0 0 1-5-5 5 5 0 0 1 5-5h10M7 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3h10a3 3 0 0 0 3-3 3 3 0 0 0-3-3H7z"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme data-md-color-primary data-md-color-accent aria-hidden=true type=radio name=__palette id=__palette_3> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=red data-md-color-accent=red aria-label="Switch to light mode" type=radio name=__palette id=__palette_4> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_3 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3z"/></svg> </label> </form> <div class=md-header__option> <div class=md-select id=language-selector> <button class=md-header__button aria-label="Select language" id=lang-button style="font-weight: 500; font-size: 0.9rem; padding: 0.2rem 0.5rem;"> <span id=current-lang>En</span> </button> <div class=md-select__inner id=lang-dropdown style="display: none;"> <ul class=md-select__list> <li class=md-select__item> <a href=# class=md-select__link data-lang=en>English</a> </li> <li class=md-select__item> <a href=# class=md-select__link data-lang=hi>हिन्दी</a> </li> <li class=md-select__item> <a href=# class=md-select__link data-lang=te>తెలుగు</a> </li> </ul> </div> </div> </div> <script>
      (function() {
        const button = document.getElementById('lang-button');
        const dropdown = document.getElementById('lang-dropdown');
        const langLinks = document.querySelectorAll('[data-lang]');
        const currentLangDisplay = document.getElementById('current-lang');
        
        // Detect current language from URL
        const currentPath = window.location.pathname;
        if (currentPath.includes('/hi/')) {
          currentLangDisplay.textContent = 'अ(A/అ)';
        } else if (currentPath.includes('/te/')) {
          currentLangDisplay.textContent = 'అ(A/अ)';
        } else {
          currentLangDisplay.textContent = 'Eng(अ/అ)'; // Default to English
        }
        
        // Toggle dropdown on button click
        button.addEventListener('click', function(e) {
          e.stopPropagation();
          dropdown.style.display = dropdown.style.display === 'none' ? 'block' : 'none';
        });
        
        // Close dropdown when clicking outside
        document.addEventListener('click', function() {
          dropdown.style.display = 'none';
        });
        
        // Handle language selection
        langLinks.forEach(function(link) {
          link.addEventListener('click', function(e) {
            e.preventDefault();
            const selectedLang = this.getAttribute('data-lang');
            const currentPath = window.location.pathname;
            let newPath;
            
            if (selectedLang === 'en') {
              // Remove /hi/ or /te/ from path
              newPath = currentPath.replace(/\/(hi|te)\//, '/');
            } else if (selectedLang === 'hi') {
              // Add or replace with /hi/
              if (currentPath.includes('/te/')) {
                newPath = currentPath.replace('/te/', '/hi/');
              } else if (currentPath.includes('/hi/')) {
                newPath = currentPath;
              } else {
                newPath = '/hi' + currentPath;
              }
            } else if (selectedLang === 'te') {
              // Add or replace with /te/
              if (currentPath.includes('/hi/')) {
                newPath = currentPath.replace('/hi/', '/te/');
              } else if (currentPath.includes('/te/')) {
                newPath = currentPath;
              } else {
                newPath = '/te' + currentPath;
              }
            }
            
            window.location.href = newPath;
          });
        });
      })();
    </script> <a href=../../contact title="Contact Me" class=md-header__button aria-label="Contact Me" style="display: inline-flex; align-items: center; gap: 0.3rem; white-space: nowrap;"> <span class=md-icon style="display: inline-flex;"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m20 8-8 5-8-5V6l8 5 8-5m0-2H4c-1.11 0-2 .89-2 2v12a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V6a2 2 0 0 0-2-2z"/></svg> </span> <span style="font-size: 0.8rem;">Contact Me</span> </a> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08z"/></svg> </a> <button type=reset class="md-search__icon md-icon" aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="Data Science with Harsha" class="md-nav__button md-logo" aria-label="Data Science with Harsha" data-md-component=logo> <img src=../../assets/images/logo.jpg alt=logo> </a> Data Science with Harsha </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> Home </a> </li> <li class=md-nav__item> <a href=../../resume/ class=md-nav__link> Resume </a> </li> <li class=md-nav__item> <a href=../../learn/ class=md-nav__link> Learn </a> </li> <li class=md-nav__item> <a href=../../contact/ class=md-nav__link> Contact </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_5 type=checkbox id=__nav_5 checked> <label class=md-nav__link for=__nav_5> Blog <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Blog data-md-level=1> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Blog </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Others/Table_of_Contents/ class=md-nav__link> Table of Contents </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_5_2 type=checkbox id=__nav_5_2> <label class=md-nav__link for=__nav_5_2> Visualization <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Visualization data-md-level=2> <label class=md-nav__title for=__nav_5_2> <span class="md-nav__icon md-icon"></span> Visualization </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Python/Vizualisation%20using%20python%20Part%201/ class=md-nav__link> Vizualizing tabular data (Python) </a> </li> <li class=md-nav__item> <a href=../../Python/Visualization%20for%20predictive%20analytics/ class=md-nav__link> Vizualising for predictive analytics (Python) </a> </li> <li class=md-nav__item> <a href=../Univariate-analysis/ class=md-nav__link> Univariate Analysis (R) </a> </li> <li class=md-nav__item> <a href=../multivariateAnalysis/ class=md-nav__link> Multivariate Analysis (R) </a> </li> <li class=md-nav__item> <a href=../multicollinearity/ class=md-nav__link> Multicollinearity (R) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_5_3 type=checkbox id=__nav_5_3 checked> <label class=md-nav__link for=__nav_5_3> Statistics basics <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Statistics basics" data-md-level=2> <label class=md-nav__title for=__nav_5_3> <span class="md-nav__icon md-icon"></span> Statistics basics </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Python/Statistics%20basics/ class=md-nav__link> Statistics Basics (Python) </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" data-md-toggle=toc type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> Probability (R) <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> Probability (R) </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#why-is-probability-important class=md-nav__link> Why is probability important </a> </li> <li class=md-nav__item> <a href=#elements-of-the-probabilistic-model class=md-nav__link> Elements of the probabilistic model </a> <nav class=md-nav aria-label="Elements of the probabilistic model"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#laws-of-probability class=md-nav__link> Laws of probability </a> </li> <li class=md-nav__item> <a href=#conditional-probability class=md-nav__link> Conditional probability </a> </li> <li class=md-nav__item> <a href=#bayes-theorem class=md-nav__link> Bayes theorem </a> </li> <li class=md-nav__item> <a href=#random-variables class=md-nav__link> Random Variables </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#distribution-functions class=md-nav__link> Distribution functions </a> <nav class=md-nav aria-label="Distribution functions"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#discrete-random-variables class=md-nav__link> Discrete random variables </a> <nav class=md-nav aria-label="Discrete random variables"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#bernoulli-distribution class=md-nav__link> Bernoulli distribution </a> </li> <li class=md-nav__item> <a href=#binomial-distribution class=md-nav__link> Binomial distribution </a> </li> <li class=md-nav__item> <a href=#geometric-distribution class=md-nav__link> Geometric distribution </a> </li> <li class=md-nav__item> <a href=#poisson-distribution class=md-nav__link> Poisson distribution </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#continuous-random-variables class=md-nav__link> Continuous random variables </a> <nav class=md-nav aria-label="Continuous random variables"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#uniform-distribution class=md-nav__link> Uniform distribution </a> </li> <li class=md-nav__item> <a href=#exponential-distribution class=md-nav__link> Exponential distribution </a> </li> <li class=md-nav__item> <a href=#normal-distribution class=md-nav__link> Normal distribution </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#references class=md-nav__link> References </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../vectors/ class=md-nav__link> Vectors (R) </a> </li> <li class=md-nav__item> <a href=../matrices/ class=md-nav__link> Matrices (R) </a> </li> <li class=md-nav__item> <a href=../../Python/Call%20center%20distributions/ class=md-nav__link> Call center distributions (Python) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_5_4 type=checkbox id=__nav_5_4> <label class=md-nav__link for=__nav_5_4> Hypothesis Testing <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Hypothesis Testing" data-md-level=2> <label class=md-nav__title for=__nav_5_4> <span class="md-nav__icon md-icon"></span> Hypothesis Testing </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../attendance_t_test/ class=md-nav__link> z-test and t-test (R) </a> </li> <li class=md-nav__item> <a href=../anova/ class=md-nav__link> ANOVA Test (R) </a> </li> <li class=md-nav__item> <a href=../chi-sq-goodness-of-fit/ class=md-nav__link> Chi-Square Goodness of fit (R) </a> </li> <li class=md-nav__item> <a href=../chi-sq-test-of-independence/ class=md-nav__link> Chi-Square test of independence (R) </a> </li> <li class=md-nav__item> <a href=../../Python/Hypothesis_Testing_Python/ class=md-nav__link> Hypothesis testing using Python </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_5_5 type=checkbox id=__nav_5_5> <label class=md-nav__link for=__nav_5_5> Factor Analysis <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Factor Analysis" data-md-level=2> <label class=md-nav__title for=__nav_5_5> <span class="md-nav__icon md-icon"></span> Factor Analysis </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../Curse-of-Dimensionality/ class=md-nav__link> Curse of dimensionality </a> </li> <li class=md-nav__item> <a href=../EFA/ class=md-nav__link> Exploratory factor analysis (R) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_5_6 type=checkbox id=__nav_5_6> <label class=md-nav__link for=__nav_5_6> Preprocessing data <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Preprocessing data" data-md-level=2> <label class=md-nav__title for=__nav_5_6> <span class="md-nav__icon md-icon"></span> Preprocessing data </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../KNN_Imputation/ class=md-nav__link> Null Value Imputation (R) </a> </li> <li class=md-nav__item> <a href=../../Python/Machine%20Learning%20Part%201/ class=md-nav__link> Feature engineering (Python) </a> </li> <li class=md-nav__item> <a href=../Handling-Imbalanced-classes/ class=md-nav__link> Handling Imbalanced Classes </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_5_7 type=checkbox id=__nav_5_7> <label class=md-nav__link for=__nav_5_7> Prediction algorithms <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Prediction algorithms" data-md-level=2> <label class=md-nav__title for=__nav_5_7> <span class="md-nav__icon md-icon"></span> Prediction algorithms </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_5_7_1 type=checkbox id=__nav_5_7_1> <label class=md-nav__link for=__nav_5_7_1> Classification Algorithms <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Classification Algorithms" data-md-level=3> <label class=md-nav__title for=__nav_5_7_1> <span class="md-nav__icon md-icon"></span> Classification Algorithms </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../logistic-regression/ class=md-nav__link> Logistic Regression (R) </a> </li> <li class=md-nav__item> <a href=../CHAID/ class=md-nav__link> CHAID Decision Trees (R) </a> </li> <li class=md-nav__item> <a href=../CART-Classification/ class=md-nav__link> CART Classification (R) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_5_7_2 type=checkbox id=__nav_5_7_2> <label class=md-nav__link for=__nav_5_7_2> Regression Algorithms <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Regression Algorithms" data-md-level=3> <label class=md-nav__title for=__nav_5_7_2> <span class="md-nav__icon md-icon"></span> Regression Algorithms </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../part-and-partial-corr/ class=md-nav__link> Part and partial correlation </a> </li> <li class=md-nav__item> <a href=../Linear-regression/ class=md-nav__link> Linear Regression (R) </a> </li> <li class=md-nav__item> <a href=../../Python/Linear%20regression%20usecase%20mpg%20prediction/ class=md-nav__link> Lasso and Ridge regression (Python) </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_5_8 type=checkbox id=__nav_5_8> <label class=md-nav__link for=__nav_5_8> Machine Learning <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Machine Learning" data-md-level=2> <label class=md-nav__title for=__nav_5_8> <span class="md-nav__icon md-icon"></span> Machine Learning </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=https://harshaachyuthuni.shinyapps.io/Machine_Learning/ class=md-nav__link> Interactive Machine Learning (RShiny) </a> </li> <li class=md-nav__item> <a href=../../Python/ML%20using%20scikit-learn/ class=md-nav__link> Multi models (Python) </a> </li> <li class=md-nav__item> <a href=../../Python/Explainable%20models%20using%20Heart%20Failure/ class=md-nav__link> Explainable ML (Python) </a> </li> <li class=md-nav__item> <a href=../../Python/Demonstrating%20online%20learning/ class=md-nav__link> Streaming Machine Learning (Python) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_5_9 type=checkbox id=__nav_5_9> <label class=md-nav__link for=__nav_5_9> Time Series forecasting <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Time Series forecasting" data-md-level=2> <label class=md-nav__title for=__nav_5_9> <span class="md-nav__icon md-icon"></span> Time Series forecasting </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../time-series/ class=md-nav__link> Introduction to stationarity (R) </a> </li> <li class=md-nav__item> <a href=../Stationarity-tests/ class=md-nav__link> Stationary Tests (R) </a> </li> <li class=md-nav__item> <a href=../ARIMA/ class=md-nav__link> ARIMA in R </a> </li> <li class=md-nav__item> <a href=../../Python/ARIMA%20Forecasting/ class=md-nav__link> ARIMA in Python </a> </li> <li class=md-nav__item> <a href=../Seasonal-Time-Series/ class=md-nav__link> Seasonal time series (R) </a> </li> <li class=md-nav__item> <a href=../VAR-models/ class=md-nav__link> VAR Models (R) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_5_10 type=checkbox id=__nav_5_10> <label class=md-nav__link for=__nav_5_10> Deep learning <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Deep learning" data-md-level=2> <label class=md-nav__title for=__nav_5_10> <span class="md-nav__icon md-icon"></span> Deep learning </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Python/ANN-1/ class=md-nav__link> Perceptron </a> </li> <li class=md-nav__item> <a href=../../Python/Backpropagation/ class=md-nav__link> Backpropagation </a> </li> <li class=md-nav__item> <a href=../../Python/DNN/ class=md-nav__link> Tensorflow and Keras </a> </li> <li class=md-nav__item> <a href=../../Python/Time%20series%20deep%20learning/ class=md-nav__link> Time series (python) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_5_11 type=checkbox id=__nav_5_11> <label class=md-nav__link for=__nav_5_11> Generative AI <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Generative AI" data-md-level=2> <label class=md-nav__title for=__nav_5_11> <span class="md-nav__icon md-icon"></span> Generative AI </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Python/LLM%20Tokenizers/ class=md-nav__link> LLM Tokenizers </a> </li> <li class=md-nav__item> <a href=../../Python/prompt_engineering_techniques/ class=md-nav__link> Prompt Engineering </a> </li> <li class=md-nav__item> <a href=../../Python/Agentic%20AI/ class=md-nav__link> Agentic AI </a> </li> <li class=md-nav__item> <a href=../../Python/RAG/ class=md-nav__link> RAG </a> </li> <li class=md-nav__item> <a href=../../Python/Blog%20validation/ class=md-nav__link> LangGraphs </a> </li> <li class=md-nav__item> <a href=../../Python/CrewAI/ class=md-nav__link> CrewAI </a> </li> <li class=md-nav__item> <a href=../../Others/yashoda_presentation/ class=md-nav__link> AI in Healthcare </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_5_12 type=checkbox id=__nav_5_12> <label class=md-nav__link for=__nav_5_12> Prescriptive Analytics <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Prescriptive Analytics" data-md-level=2> <label class=md-nav__title for=__nav_5_12> <span class="md-nav__icon md-icon"></span> Prescriptive Analytics </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../Linear-programming/ class=md-nav__link> Linear Programming (R) </a> </li> <li class=md-nav__item> <a href=../../Others/integer_programming_blog/ class=md-nav__link> Integer Programming tricks </a> </li> <li class=md-nav__item> <a href=../../Python/inventory_optimization_eoq_ortools/ class=md-nav__link> Inventory Optimisation (Python) </a> </li> <li class=md-nav__item> <a href=../adoption_of_new_product/ class=md-nav__link> Adoption of new product (R) </a> </li> <li class=md-nav__item> <a href=../../Python/Diffusion%20on%20networks/ class=md-nav__link> Bass Forecasting model (Python) </a> </li> <li class=md-nav__item> <a href=../../Others/AHP/ class=md-nav__link> Analytic Hierarchy Process </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_5_13 type=checkbox id=__nav_5_13> <label class=md-nav__link for=__nav_5_13> Clustering <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Clustering data-md-level=2> <label class=md-nav__title for=__nav_5_13> <span class="md-nav__icon md-icon"></span> Clustering </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../hierarchical_clustering/ class=md-nav__link> Hierarchical Clustering </a> </li> <li class=md-nav__item> <a href=../kMeansClustering/ class=md-nav__link> K-Means Clustering </a> </li> <li class=md-nav__item> <a href=../../Python/train_delays/ class=md-nav__link> DBSCAN Clustering (Python) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_5_14 type=checkbox id=__nav_5_14> <label class=md-nav__link for=__nav_5_14> Reinforcement Learning <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Reinforcement Learning" data-md-level=2> <label class=md-nav__title for=__nav_5_14> <span class="md-nav__icon md-icon"></span> Reinforcement Learning </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../CustomerLifetimeValue/ class=md-nav__link> Customer Lifetime Value </a> </li> <li class=md-nav__item> <a href=../recommendation-systems/ class=md-nav__link> Recommendation Systems (R) </a> </li> <li class=md-nav__item> <a href=../../Python/Neural_collaborative_filtering/ class=md-nav__link> Collaborative Filtering (Python) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_5_15 type=checkbox id=__nav_5_15> <label class=md-nav__link for=__nav_5_15> Networks <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Networks data-md-level=2> <label class=md-nav__title for=__nav_5_15> <span class="md-nav__icon md-icon"></span> Networks </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Python/Introduction%20to%20Networkx/ class=md-nav__link> Introduction to NetworkX (Python) </a> </li> <li class=md-nav__item> <a href=../../Python/Network%20Science/ class=md-nav__link> Network Science (Python) </a> </li> <li class=md-nav__item> <a href=../../Python/Network%20centrality/ class=md-nav__link> Network Centrality (Python) </a> </li> <li class=md-nav__item> <a href=../../Python/Shortest%20path%20problems/ class=md-nav__link> Shortest path using integer programming (Python) </a> </li> <li class=md-nav__item> <a href=../../Python/Network%20Flow%20problems/ class=md-nav__link> Network flow problems (Python) </a> </li> <li class=md-nav__item> <a href=../../Python/Community%20detection/ class=md-nav__link> Community detection (Python) </a> </li> <li class=md-nav__item> <a href=../../Python/Bipartite%20matching/ class=md-nav__link> Bipartite matching (Python) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_5_16 type=checkbox id=__nav_5_16> <label class=md-nav__link for=__nav_5_16> Deployment <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Deployment data-md-level=2> <label class=md-nav__title for=__nav_5_16> <span class="md-nav__icon md-icon"></span> Deployment </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Python/Machine%20learning%20as%20HTTP%20Request/ class=md-nav__link> ML deployment in Flask (Python) </a> </li> <li class=md-nav__item> <a href=../../Python/Saving%20predictions%20in%20database/ class=md-nav__link> Handling databases using python </a> </li> <li class=md-nav__item> <a href=../../Python/ORM/ class=md-nav__link> ORM (Python) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_5_17 type=checkbox id=__nav_5_17> <label class=md-nav__link for=__nav_5_17> Career lessons <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Career lessons" data-md-level=2> <label class=md-nav__title for=__nav_5_17> <span class="md-nav__icon md-icon"></span> Career lessons </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Others/learnings/ class=md-nav__link> Learnings from failures </a> </li> <li class=md-nav__item> <a href=../../Others/podcast/ class=md-nav__link> Making ML Consumable </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_5_18 type=checkbox id=__nav_5_18> <label class=md-nav__link for=__nav_5_18> Higher education review <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Higher education review" data-md-level=2> <label class=md-nav__title for=__nav_5_18> <span class="md-nav__icon md-icon"></span> Higher education review </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Others/IIMB%20BAI/ class=md-nav__link> IIMB BAI </a> </li> <li class=md-nav__item> <a href=../../Others/part%20time%20data%20science%20masters/ class=md-nav__link> Part-time DS masters </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_5_19 type=checkbox id=__nav_5_19> <label class=md-nav__link for=__nav_5_19> External blogs <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="External blogs" data-md-level=2> <label class=md-nav__title for=__nav_5_19> <span class="md-nav__icon md-icon"></span> External blogs </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Others/Imperial%20College%20London/ class=md-nav__link> Imperial college London </a> </li> <li class=md-nav__item> <a href=../../Others/Publications/ class=md-nav__link> Publications/conferences </a> </li> <li class=md-nav__item> <a href=../../Others/Deployed%20apps/ class=md-nav__link> Deployed apps </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_5_20 type=checkbox id=__nav_5_20> <label class=md-nav__link for=__nav_5_20> Projects <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Projects data-md-level=2> <label class=md-nav__title for=__nav_5_20> <span class="md-nav__icon md-icon"></span> Projects </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Others/preventive_maintainence/ class=md-nav__link> Preventive maintainence </a> </li> <li class=md-nav__item> <a href=../../Others/Contract%20Intelligence%20tool/ class=md-nav__link> Contract Intelligence </a> </li> <li class=md-nav__item> <a href=../../Others/competitor%20intelligence/ class=md-nav__link> Competitor intelligence </a> </li> <li class=md-nav__item> <a href=../../Others/quiz%20generation/ class=md-nav__link> Quiz Generation </a> </li> <li class=md-nav__item> <a href=../../Others/Scarecrow/ class=md-nav__link> Intelligent annotation </a> </li> <li class=md-nav__item> <a href=../../Others/Demand%20Forecasting/ class=md-nav__link> Demand Forecasting </a> </li> <li class=md-nav__item> <a href=../../Others/bid%20allocation%20model/ class=md-nav__link> Bid Allocation </a> </li> <li class=md-nav__item> <a href=../../Others/IIMB%20project/ class=md-nav__link> Reward and Recognition contests </a> </li> <li class=md-nav__item> <a href=../../Others/supply%20chain%20analytics/ class=md-nav__link> Supply chain analytics </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#why-is-probability-important class=md-nav__link> Why is probability important </a> </li> <li class=md-nav__item> <a href=#elements-of-the-probabilistic-model class=md-nav__link> Elements of the probabilistic model </a> <nav class=md-nav aria-label="Elements of the probabilistic model"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#laws-of-probability class=md-nav__link> Laws of probability </a> </li> <li class=md-nav__item> <a href=#conditional-probability class=md-nav__link> Conditional probability </a> </li> <li class=md-nav__item> <a href=#bayes-theorem class=md-nav__link> Bayes theorem </a> </li> <li class=md-nav__item> <a href=#random-variables class=md-nav__link> Random Variables </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#distribution-functions class=md-nav__link> Distribution functions </a> <nav class=md-nav aria-label="Distribution functions"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#discrete-random-variables class=md-nav__link> Discrete random variables </a> <nav class=md-nav aria-label="Discrete random variables"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#bernoulli-distribution class=md-nav__link> Bernoulli distribution </a> </li> <li class=md-nav__item> <a href=#binomial-distribution class=md-nav__link> Binomial distribution </a> </li> <li class=md-nav__item> <a href=#geometric-distribution class=md-nav__link> Geometric distribution </a> </li> <li class=md-nav__item> <a href=#poisson-distribution class=md-nav__link> Poisson distribution </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#continuous-random-variables class=md-nav__link> Continuous random variables </a> <nav class=md-nav aria-label="Continuous random variables"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#uniform-distribution class=md-nav__link> Uniform distribution </a> </li> <li class=md-nav__item> <a href=#exponential-distribution class=md-nav__link> Exponential distribution </a> </li> <li class=md-nav__item> <a href=#normal-distribution class=md-nav__link> Normal distribution </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#references class=md-nav__link> References </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1>Probability (R)</h1> <script type=text/javascript src=https://cdn.mathjax.org/mathjax/latest/MathJax.js>
MathJax.Hub.Config({
 extensions: ["tex2jax.js","TeX/AMSmath.js","TeX/AMSsymbols.js"],
 jax: ["input/TeX", "output/HTML-CSS"],
 tex2jax: {
     inlineMath: [ ['$','$'], ["\\(","\\)"] ],
     displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
 },
 "HTML-CSS": { availableFonts: ["TeX"] }
});
</script> <h2 id=why-is-probability-important>Why is probability important<a class=headerlink href=#why-is-probability-important title="Permanent link">&para;</a></h2> <p>One of the fundamental topics of data science is probability. This is because, in the real world, there are always random effects that cause randomness in even the most predictable events. Randomness is found in daily life to research conducted to business applications we encounter. Probability is a field which provides us with tools to fight against uncertainty and is, therefore, the backbone of statistics, econometrics, game theory and machine learning. </p> <h2 id=elements-of-the-probabilistic-model>Elements of the probabilistic model<a class=headerlink href=#elements-of-the-probabilistic-model title="Permanent link">&para;</a></h2> <p>Let us take an experiment where the potential outcomes are <span class=arithmatex>\(\omega_1, \omega_2,...\)</span>. <br> For example, if we roll a six-sided die, the outcomes are <span class=arithmatex>\(\omega_1 = 1, \omega_2 = 2, \omega_3 = 3, \omega_4 = 4, \omega_5 = 5, \omega_6 = 6\)</span>. This set of all outcomes is called a <em>sample space</em> and is denoted by <span class=arithmatex>\(\Omega\)</span>. A subset of the sample space is called an <em>event</em>. For example, getting 3 or 4 in a six-headed die roll is an event. </p> <h3 id=laws-of-probability>Laws of probability<a class=headerlink href=#laws-of-probability title="Permanent link">&para;</a></h3> <p>Which event is more likely to occur and which event is less likely to occur. This is explained by using a probability function P(A). There are four laws of probability: <br> 1. <span class=arithmatex>\(0 \leq P(A) \leq 1\)</span>: The probability of an event is between 0 and 100%. <br> 2. <span class=arithmatex>\(P(\Omega) = 1\)</span>: the probability of the sample space is 1. <br> 3. If event A and event B are disjoint, then <span class=arithmatex>\(P(A \cup B) = P(A) + P(B)\)</span>.<br> 4. If events <span class=arithmatex>\(A_i\)</span> are pairwise disjoint events, i.e. <span class=arithmatex>\(A_i \cap A_j = \phi\)</span>, then <span class=arithmatex>\(P(\cup_{i=1}^{\infty}A_i) = \sum_{i=0}^\infty P(A_i)\)</span> <br> Any probability function that satisfies these three axioms are considered to be a valid probability function. </p> <p>Some properties that can be derived from these axioms are:<br> 1. <span class=arithmatex>\(P(A^C) = 1-P(A)\)</span><br> 2. <span class=arithmatex>\(P(A \cap B) = P(A) + P(B) - P(A \cup B)\)</span> <br> 3. If <span class=arithmatex>\(A \subset B\)</span> then <span class=arithmatex>\(P(A) \leq P(B)\)</span><br> 4. If <span class=arithmatex>\(P(A \cap B) = P(A)P(B)\)</span>, then A and B are independent </p> <h3 id=conditional-probability>Conditional probability<a class=headerlink href=#conditional-probability title="Permanent link">&para;</a></h3> <p>Let A and B be two events from the same sample space. The conditional probability of A given B is the probability of A happening if B has already taken place. This is given by <span class=arithmatex>\(P(A|B) = \frac{P(A \cap B)}{P(B)}\)</span> </p> <p>From the above, we can get the following: <br> 1. <span class=arithmatex>\(P(A \cap B) = P(B)\times P(A|B) = P(A)\times P(B|A)\)</span> <br> 2. <span class=arithmatex>\(P(A) = \sum_{i=1}^n P(A|B_i)\times P(B_i)\)</span> where <span class=arithmatex>\(B_i\)</span> form a partition of the sample space. This is called as the formula of total probability </p> <h3 id=bayes-theorem>Bayes theorem<a class=headerlink href=#bayes-theorem title="Permanent link">&para;</a></h3> <p>If A and B are two events where P(A)&gt;0, then <br> <span class=arithmatex>\(P(A | B) = \frac{P(B|A)P(A)}{\sum_{i=1}^n P(B|A_i)\times P(A_i)}\)</span> <br> where <span class=arithmatex>\(A_j\)</span>'s form a partition of the sample space <span class=arithmatex>\(\cup_{i=1}^{\infty}A_i = \Omega\)</span> and for <span class=arithmatex>\(i\neq j, A_i \neq A_j\)</span> </p> <h3 id=random-variables>Random Variables<a class=headerlink href=#random-variables title="Permanent link">&para;</a></h3> <p>Random variables will help us understand the probability distributions. A random variable maps the outcomes from an experiment from the sample space to a numerical quantity. For example, if we flip a coin four times, we can get the following outcomes with H for heads and T for Tails: HTHT, HHTT, HHHT, TTTH, TTTT etc. if we take a variable that measures the number of heads in the series, we get a mapping like: HTHT - 2; HHTT - 2; HHHT - 3; TTTH - 1; TTTT - 0 and so on. The randomness of a random variable is attached to the event, and not the experiment. Random variables are this mapping which maps the outcomes of the experiment to numerical quantities. There are two types of random variables, discrete and continuous random variables. <br> The range of a discrete random variable contains a finite or countably infinite sequence of values. Some examples are:<br> 1. No of heads in 10 coin flips: finite <br> 2. The number of flips of a coin until heads appear: countable infinite </p> <p>Continuous random variables have their range as an interval of real numbers which can be finite or infinite. An example would be the time until the next customer arrives in a store. </p> <h2 id=distribution-functions>Distribution functions<a class=headerlink href=#distribution-functions title="Permanent link">&para;</a></h2> <p>Distribution functions are used to characterise the behaviour of random variables, like the mean, standard deviation and probabilities. There are two types of distribution functions, probability distribution functions and cumulative distribution functions.<br> For discrete random variables, we use <em>probability mass function</em>, which is the probability that a random variable will take a specific value. For continuous random variables, the probability of a random variable will be in an interval is arrived by integrating the <em>probability density function. <br> The *cumulative distribution functions</em> depict the variable will take the value less than equal to the range. <br> Two random variables <span class=arithmatex>\(Y_1\)</span> and <span class=arithmatex>\(Y_2\)</span> are said to be independent of each other if <span class=arithmatex>\(P(Y_1 \in A, Y_2 \in B) = P(Y_1 \in A)\times P(Y_2 \in B)\)</span> </p> <h3 id=discrete-random-variables>Discrete random variables<a class=headerlink href=#discrete-random-variables title="Permanent link">&para;</a></h3> <p>For discrete random variables, the PMF and CDF are defined as follows: <br> $$ PMF = p_X(x) := P(X = x) $$ <br> $$ CMF = F_X(x) := P(X\leq x) $$ </p> <p><strong>The mean and variance of discrete random variables</strong><br> Let X be a random variable with range {<span class=arithmatex>\(x_1, x_2, ...\)</span>}. The mean and variance of a random variable are given by: <br> Expected value (Mean): <span class=arithmatex>\(E[X] := \sum_{i=1}^n x_i \times P(X=x_i)\)</span><br> Variance: <span class=arithmatex>\(Var(X) := E[(X-E[X])^2] = E[X^2]-E[X]^2\)</span> <br> Standard Deviation <span class=arithmatex>\(SD(X) = \sqrt{Var(X)}\)</span> </p> <p>If two events X and Y are independent, then <br> 1. E[XY] = E[X]E[Y] <br> 2. <span class=arithmatex>\(Var(aX+bY) = a^2Var(X) + b^2 Var(Y)\)</span> </p> <h4 id=bernoulli-distribution>Bernoulli distribution<a class=headerlink href=#bernoulli-distribution title="Permanent link">&para;</a></h4> <p>Imagine an experiment that can have two outcomes, success or failure but not both. We call such an experiment as a Bernoulli trial. Consider the random variable X, which assigns 1 when we have success and 0 when we have a failure. If the probability of success is 'p', then the Probability mass function is given by: <br> <span class=arithmatex>\(P(X=x)=\left\{ \begin{array}{ll} p \qquad x=1\\ 1-p \quad x=0 \end{array} \right.\)</span><br> Consider flipping a coin which has a probability of heads as 60%(probability of success) 100 times. Below is a simulation of the same: </p> <div class=highlight><pre><span></span><code><span class=n>dist</span><span class=w> </span><span class=o>&lt;-</span><span class=w> </span><span class=nf>rbinom</span><span class=p>(</span><span class=m>100</span><span class=p>,</span><span class=w> </span><span class=m>1</span><span class=p>,</span><span class=w> </span><span class=m>0.6</span><span class=p>)</span>
<span class=nf>plot</span><span class=p>(</span><span class=n>dist</span><span class=p>)</span>
</code></pre></div> <p><img alt src=../Probability_files/figure-html/exp-1.png><!-- --></p> <p>The PMF and CDF of Bernoulli distribution are as shown: </p> <div class=highlight><pre><span></span><code><span class=n>range</span><span class=w> </span><span class=o>&lt;-</span><span class=w> </span><span class=nf>c</span><span class=p>(</span><span class=m>0</span><span class=p>,</span><span class=m>1</span><span class=p>)</span>
<span class=n>pmf</span><span class=w> </span><span class=o>&lt;-</span><span class=w> </span><span class=nf>dbinom</span><span class=p>(</span><span class=n>x</span><span class=o>=</span><span class=n>range</span><span class=p>,</span><span class=w> </span><span class=n>size</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=m>1</span><span class=p>,</span><span class=n>prob</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=m>0.6</span><span class=p>)</span>
<span class=n>cdf</span><span class=w> </span><span class=o>&lt;-</span><span class=w> </span><span class=nf>pbinom</span><span class=p>(</span><span class=n>q</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>range</span><span class=p>,</span><span class=w> </span><span class=n>size</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=m>1</span><span class=p>,</span><span class=w> </span><span class=n>prob</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=m>0.6</span><span class=p>)</span>
<span class=nf>plot_pmf</span><span class=p>(</span><span class=n>pmf</span><span class=p>,</span><span class=n>range</span><span class=p>)</span>
</code></pre></div> <p><img alt src=../Probability_files/figure-html/unnamed-chunk-1-1.png><!-- --></p> <div class=highlight><pre><span></span><code><span class=nf>plot_cdf</span><span class=p>(</span><span class=n>cdf</span><span class=p>,</span><span class=w> </span><span class=n>range</span><span class=p>)</span>
</code></pre></div> <p><img alt src=../Probability_files/figure-html/unnamed-chunk-1-2.png><!-- --></p> <p>The mean and variance of the Bernoulli distribution is <span class=arithmatex>\(E[X] = p\)</span> and <span class=arithmatex>\(Var(X) = p\times q\)</span> This can be verified using the below code</p> <div class=highlight><pre><span></span><code><span class=nf>mean</span><span class=p>(</span><span class=n>dist</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>## [1] 0.54
</code></pre></div> <div class=highlight><pre><span></span><code><span class=nf>var</span><span class=p>(</span><span class=n>dist</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>## [1] 0.2509091
</code></pre></div> <h4 id=binomial-distribution>Binomial distribution<a class=headerlink href=#binomial-distribution title="Permanent link">&para;</a></h4> <p>Imagine an experiment where we are repeating independent Bernoulli trails n times. Then we can characterise this distribution using only two parameters, the success probability p and the number of trails n. If we have r successes out of n trials, we represent the probability of that event happening using a binomial distribution. The PMF of the binomial distribution is given as </p> <p><span class=arithmatex>\(P(X=x)=(^nc_r)\times p^r\times q^{n-r}\)</span> </p> <p>A binomial random variable is the sum of n Bernoulli distributions.<br> Consider flipping a coin 10 times which has a probability of heads as 60%(probability of success). For the range 0 to 10, the total number of heads in 10 flips is simulated below: </p> <div class=highlight><pre><span></span><code><span class=n>dist</span><span class=w> </span><span class=o>&lt;-</span><span class=w> </span><span class=nf>rbinom</span><span class=p>(</span><span class=m>100</span><span class=p>,</span><span class=w> </span><span class=m>10</span><span class=p>,</span><span class=w> </span><span class=m>0.6</span><span class=p>)</span>
<span class=nf>plot</span><span class=p>(</span><span class=n>dist</span><span class=p>)</span>
</code></pre></div> <p><img alt src=../Probability_files/figure-html/experimet-1.png><!-- --></p> <p>The PMF and CDF of bernoulli distribution are as shown: </p> <div class=highlight><pre><span></span><code><span class=n>range</span><span class=w> </span><span class=o>&lt;-</span><span class=w> </span><span class=nf>c</span><span class=p>(</span><span class=m>0</span><span class=p>,</span><span class=m>1</span><span class=p>,</span><span class=m>2</span><span class=p>,</span><span class=m>3</span><span class=p>,</span><span class=m>4</span><span class=p>,</span><span class=m>5</span><span class=p>,</span><span class=m>6</span><span class=p>,</span><span class=m>7</span><span class=p>,</span><span class=m>8</span><span class=p>,</span><span class=m>9</span><span class=p>,</span><span class=m>10</span><span class=p>)</span>
<span class=n>pmf</span><span class=w> </span><span class=o>&lt;-</span><span class=w> </span><span class=nf>dbinom</span><span class=p>(</span><span class=n>x</span><span class=o>=</span><span class=n>range</span><span class=p>,</span><span class=w> </span><span class=n>size</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=m>10</span><span class=p>,</span><span class=n>prob</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=m>0.6</span><span class=p>)</span>
<span class=n>cdf</span><span class=w> </span><span class=o>&lt;-</span><span class=w> </span><span class=nf>pbinom</span><span class=p>(</span><span class=n>q</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>range</span><span class=p>,</span><span class=w> </span><span class=n>size</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=m>10</span><span class=p>,</span><span class=w> </span><span class=n>prob</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=m>0.6</span><span class=p>)</span>
<span class=nf>plot_pmf</span><span class=p>(</span><span class=n>pmf</span><span class=p>,</span><span class=n>range</span><span class=p>)</span>
</code></pre></div> <p><img alt src=../Probability_files/figure-html/unnamed-chunk-3-1.png><!-- --></p> <div class=highlight><pre><span></span><code><span class=nf>plot_cdf</span><span class=p>(</span><span class=n>cdf</span><span class=p>,</span><span class=w> </span><span class=n>range</span><span class=p>)</span>
</code></pre></div> <p><img alt src=../Probability_files/figure-html/unnamed-chunk-3-2.png><!-- --></p> <p>The mean and variance of the binomial distribution are <span class=arithmatex>\(E[X] = np\)</span> and <span class=arithmatex>\(Var[X] = npq\)</span> This can be derived as shown below and verified using the below code:<br> Derivations: </p> <p><span class=arithmatex>\(E[X] = E[Z_1 + Z_2 + ...] = E[Z_1] + E[Z_2] +E[Z_3] + ...E[Z_n] = np\)</span><br> where <span class=arithmatex>\(Z_1, Z_2..Z_n\)</span> are Bernoulli events which constitute the binomial distribution. </p> <p><span class=arithmatex>\(Var[x] = Var[Z_1 + Z_2 + ...] = Var[Z_1] + Var[Z_2] +Var[Z_3] + ...Var[Z_n] = npq\)</span> as <span class=arithmatex>\(Z_1, Z_2..Z_n\)</span> are independent.<br> The same can also be verified by taking the mean and variance of the sample data:</p> <div class=highlight><pre><span></span><code><span class=nf>mean</span><span class=p>(</span><span class=n>dist</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>## [1] 6.11
</code></pre></div> <div class=highlight><pre><span></span><code><span class=nf>var</span><span class=p>(</span><span class=n>dist</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>## [1] 2.523131
</code></pre></div> <h4 id=geometric-distribution>Geometric distribution<a class=headerlink href=#geometric-distribution title="Permanent link">&para;</a></h4> <p>Imagine an experiment where we are repeating independent Bernoulli trails n times. We can characterise this distribution using only two parameters, the success probability p and the number of trails n. Consider the event where we get the first success after n failures. The distribution associated with this event is the geometric distribution. The PMF of the binomial distribution is given as </p> <p><span class=arithmatex>\(P(X=x)=p\times (1-p)^{r}\)</span> </p> <p>The range of this function is all Real Values from 0,1,2,3,4,... <br> Consider flipping a coin unitil we get heads, where the probability of heads is 50%(probability of success). For the range 0 to 10, the probability of n failures until the first heads is given by: </p> <div class=highlight><pre><span></span><code><span class=n>dist</span><span class=w> </span><span class=o>&lt;-</span><span class=w> </span><span class=nf>rgeom</span><span class=p>(</span><span class=m>100</span><span class=p>,</span><span class=w> </span><span class=m>0.5</span><span class=p>)</span>
<span class=nf>plot</span><span class=p>(</span><span class=n>dist</span><span class=p>)</span>
</code></pre></div> <p><img alt src=../Probability_files/figure-html/experimen-1.png><!-- --></p> <p>The PMF and CDF of Geometric distribution are as shown: </p> <div class=highlight><pre><span></span><code><span class=n>range</span><span class=w> </span><span class=o>&lt;-</span><span class=w> </span><span class=nf>c</span><span class=p>(</span><span class=m>0</span><span class=p>,</span><span class=m>1</span><span class=p>,</span><span class=m>2</span><span class=p>,</span><span class=m>3</span><span class=p>,</span><span class=m>4</span><span class=p>,</span><span class=m>5</span><span class=p>,</span><span class=m>6</span><span class=p>,</span><span class=m>7</span><span class=p>,</span><span class=m>8</span><span class=p>,</span><span class=m>9</span><span class=p>,</span><span class=m>10</span><span class=p>)</span>
<span class=n>pmf</span><span class=w> </span><span class=o>&lt;-</span><span class=w> </span><span class=nf>dgeom</span><span class=p>(</span><span class=n>x</span><span class=o>=</span><span class=n>range</span><span class=p>,</span><span class=w> </span><span class=n>prob</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=m>0.5</span><span class=p>)</span>
<span class=n>cdf</span><span class=w> </span><span class=o>&lt;-</span><span class=w> </span><span class=nf>pgeom</span><span class=p>(</span><span class=n>q</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>range</span><span class=p>,</span><span class=n>prob</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=m>0.5</span><span class=p>)</span>
<span class=nf>plot_pmf</span><span class=p>(</span><span class=n>pmf</span><span class=p>,</span><span class=n>range</span><span class=p>)</span>
</code></pre></div> <p><img alt src=../Probability_files/figure-html/unnamed-chunk-5-1.png><!-- --></p> <div class=highlight><pre><span></span><code><span class=nf>plot_cdf</span><span class=p>(</span><span class=n>cdf</span><span class=p>,</span><span class=w> </span><span class=n>range</span><span class=p>)</span>
</code></pre></div> <p><img alt src=../Probability_files/figure-html/unnamed-chunk-5-2.png><!-- --></p> <p>The mean and variance of the geometric distribution are <span class=arithmatex>\(E[X] = \frac{q}{p}\)</span> and <span class=arithmatex>\(Var[X] = \frac{q}{p^2}\)</span> This can be derived as shown below and verified using the below code:<br> Derivations:</p> <p><span class=arithmatex>\(E[X] = 0p+1qp+2q^2p+3q^3p+..=qp(1+2q+3q^2+..) = qp\frac{1}{(1-q)^2} = q/p\)</span> </p> <p><span class=arithmatex>\(Var[x] = E[X^2]-E[X]^2 = (0p+1qp+4q^2p+9q^3p+..) -(\frac{q}{p})^2 = \frac{q}{p^2}\)</span> </p> <p>The same can also be verified by taking the mean and variance of the sample data:</p> <div class=highlight><pre><span></span><code><span class=nf>mean</span><span class=p>(</span><span class=n>dist</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>## [1] 0.86
</code></pre></div> <div class=highlight><pre><span></span><code><span class=nf>var</span><span class=p>(</span><span class=n>dist</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>## [1] 1.232727
</code></pre></div> <h4 id=poisson-distribution>Poisson distribution<a class=headerlink href=#poisson-distribution title="Permanent link">&para;</a></h4> <p>The Poisson distribution is used when we are counting the number of successes in an interval of time. Usually, in these situations, the probability of an event occurring at a particular time is small. For example, we might be interested in counting the number of customers that arrive in a bus stand in a period of time. This random variable might follow a Poisson distribution as the probability of success; someone coming to the bus stand at any tick of time is small. Only one parameter is used to define the Poisson distribution, i.e. <span class=arithmatex>\(\lambda\)</span>, which is the average rate of arrivals we are interested in. The PMF is defined as<br> $$ P(X=x)= \frac{\lambda<sup -_lambda=-\lambda>xe</sup> $$ The range of this function is all Real Values from 0,1,2,3,4,... }}{x!<br> For a Poisson distribution of <span class=arithmatex>\(\lambda =10\)</span>, we have</p> <div class=highlight><pre><span></span><code><span class=n>dist</span><span class=w> </span><span class=o>&lt;-</span><span class=w> </span><span class=nf>rpois</span><span class=p>(</span><span class=m>100</span><span class=p>,</span><span class=w> </span><span class=m>10</span><span class=p>)</span>
<span class=nf>plot</span><span class=p>(</span><span class=n>dist</span><span class=p>)</span>
</code></pre></div> <p><img alt src=../Probability_files/figure-html/ex-1.png><!-- --></p> <p>The PMF and CDF of Poisson distribution are as shown: </p> <div class=highlight><pre><span></span><code><span class=n>range</span><span class=w> </span><span class=o>&lt;-</span><span class=w> </span><span class=nf>c</span><span class=p>(</span><span class=m>0</span><span class=p>,</span><span class=m>1</span><span class=p>,</span><span class=m>2</span><span class=p>,</span><span class=m>3</span><span class=p>,</span><span class=m>4</span><span class=p>,</span><span class=m>5</span><span class=p>,</span><span class=m>6</span><span class=p>,</span><span class=m>7</span><span class=p>,</span><span class=m>8</span><span class=p>,</span><span class=m>9</span><span class=p>,</span><span class=m>10</span><span class=p>,</span><span class=w> </span><span class=m>11</span><span class=p>,</span><span class=w> </span><span class=m>12</span><span class=p>,</span><span class=w> </span><span class=m>13</span><span class=p>,</span><span class=w> </span><span class=m>14</span><span class=p>,</span><span class=w> </span><span class=m>15</span><span class=p>,</span><span class=w> </span><span class=m>16</span><span class=p>,</span><span class=w> </span><span class=m>17</span><span class=p>,</span><span class=w> </span><span class=m>18</span><span class=p>,</span><span class=w> </span><span class=m>19</span><span class=p>,</span><span class=w> </span><span class=m>20</span><span class=p>,</span><span class=w> </span><span class=m>21</span><span class=p>)</span>
<span class=n>pmf</span><span class=w> </span><span class=o>&lt;-</span><span class=w> </span><span class=nf>dpois</span><span class=p>(</span><span class=n>x</span><span class=o>=</span><span class=n>range</span><span class=p>,</span><span class=w> </span><span class=n>lambda</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=m>10</span><span class=p>)</span>
<span class=n>cdf</span><span class=w> </span><span class=o>&lt;-</span><span class=w> </span><span class=nf>ppois</span><span class=p>(</span><span class=n>q</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>range</span><span class=p>,</span><span class=w> </span><span class=n>lambda</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=m>10</span><span class=p>)</span>
<span class=nf>plot_pmf</span><span class=p>(</span><span class=n>pmf</span><span class=p>,</span><span class=n>range</span><span class=p>)</span>
</code></pre></div> <p><img alt src=../Probability_files/figure-html/unnamed-chunk-7-1.png><!-- --></p> <div class=highlight><pre><span></span><code><span class=nf>plot_cdf</span><span class=p>(</span><span class=n>cdf</span><span class=p>,</span><span class=w> </span><span class=n>range</span><span class=p>)</span>
</code></pre></div> <p><img alt src=../Probability_files/figure-html/unnamed-chunk-7-2.png><!-- --></p> <p>The mean and variance of the Poisson distribution are <span class=arithmatex>\(E[X] = \lambda\)</span> and <span class=arithmatex>\(Var[X] = \lambda\)</span> This can be derived as shown below and verified using the below code:<br> Derivations:<br> <span class=arithmatex>\(E[X] = \sum x\frac{\lambda^xe^{-\lambda}}{x!} = \lambda \sum\frac{\lambda^{x-1}e^{-1}}{(x-1)!} = \lambda\)</span><br> The same can also be verified by taking the mean and variance of the sample data:</p> <div class=highlight><pre><span></span><code><span class=nf>mean</span><span class=p>(</span><span class=n>dist</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>## [1] 10.24
</code></pre></div> <div class=highlight><pre><span></span><code><span class=nf>var</span><span class=p>(</span><span class=n>dist</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>## [1] 12.28525
</code></pre></div> <h3 id=continuous-random-variables>Continuous random variables<a class=headerlink href=#continuous-random-variables title="Permanent link">&para;</a></h3> <p>Unlike discrete random variables, continuous random variables can take all real values in an interval which can be finite or infinite. A continuous random variable X has a <em>probability density function</em> <span class=arithmatex>\(f_X(X)\)</span>. PDF is different from PMF while its usage in calculating the probability of an event is similar. For instance, the probability of an event A is calculated by summing the probabilities of each discrete variable(PMF), while we integrate the probabilities for all the outcomes for continuous variables(PDF). Similarly, for CDF, we integrate from <span class=arithmatex>\(-\infty\)</span> to x. </p> <p><span class=arithmatex>\(PDF:= f_X(x)\)</span> </p> <p><span class=arithmatex>\(P(X\in A) = \int_A f_X(y) dy\)</span> </p> <p><span class=arithmatex>\(CDF:= F_X(x) = \int_{-\infty}^{x} f_x(y) dy\)</span> </p> <p>Therefore PDF and CDF are lated by <span class=arithmatex>\(\frac{d}{dx}F(X) = f(x)\)</span> and <span class=arithmatex>\(P(X \in (x+\epsilon, x-\epsilon)) = 2\epsilon \times f(x)\)</span>.</p> <h4 id=uniform-distribution>Uniform distribution<a class=headerlink href=#uniform-distribution title="Permanent link">&para;</a></h4> <p>The uniform distribution is used when we do not have the underlying distribution at hand. We make a simplifying assumption that every element in our range has the same probability of occurring. The PDF of a uniform distribution is given by: </p> <p><span class=arithmatex>\(PDF:= f(x) = \frac{1}{b-a}, \, x \in (a,b)\)</span> </p> <p>We need two parameters to characterise a uniform distribution, which is <em>a</em> and <em>b</em>. The distribution is as shown: </p> <div class=highlight><pre><span></span><code><span class=n>dist</span><span class=w> </span><span class=o>&lt;-</span><span class=w> </span><span class=nf>runif</span><span class=p>(</span><span class=n>n</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=m>100</span><span class=p>,</span><span class=w> </span><span class=n>min</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=m>5</span><span class=p>,</span><span class=w> </span><span class=n>max</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=m>10</span><span class=p>)</span>
<span class=nf>plot</span><span class=p>(</span><span class=n>dist</span><span class=p>)</span>
</code></pre></div> <p><img alt src=../Probability_files/figure-html/unnamed-chunk-9-1.png><!-- --></p> <p>The PDF and CDF are plotted below:</p> <div class=highlight><pre><span></span><code><span class=n>range</span><span class=w> </span><span class=o>&lt;-</span><span class=w> </span><span class=m>1</span><span class=o>:</span><span class=m>150</span><span class=o>/</span><span class=m>10</span>
<span class=n>pdf</span><span class=w> </span><span class=o>&lt;-</span><span class=w> </span><span class=nf>dunif</span><span class=p>(</span><span class=n>x</span><span class=o>=</span><span class=n>range</span><span class=p>,</span><span class=w> </span><span class=n>min</span><span class=o>=</span><span class=m>5</span><span class=p>,</span><span class=w> </span><span class=n>max</span><span class=o>=</span><span class=m>10</span><span class=p>)</span>
<span class=n>cdf</span><span class=w> </span><span class=o>&lt;-</span><span class=w> </span><span class=nf>punif</span><span class=p>(</span><span class=n>q</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>range</span><span class=p>,</span><span class=w> </span><span class=n>min</span><span class=o>=</span><span class=m>5</span><span class=p>,</span><span class=w> </span><span class=n>max</span><span class=o>=</span><span class=m>10</span><span class=p>)</span>
<span class=nf>plot_pdf</span><span class=p>(</span><span class=n>pdf</span><span class=p>,</span><span class=n>range</span><span class=p>)</span>
</code></pre></div> <p><img alt src=../Probability_files/figure-html/unnamed-chunk-10-1.png><!-- --></p> <div class=highlight><pre><span></span><code><span class=nf>plot_cdf_continuous</span><span class=p>(</span><span class=n>cdf</span><span class=p>,</span><span class=w> </span><span class=n>range</span><span class=p>)</span>
</code></pre></div> <p><img alt src=../Probability_files/figure-html/unnamed-chunk-10-2.png><!-- --></p> <p>For the uniform distribution, the mean is <span class=arithmatex>\(E[X]=\frac{a+b}{2}\)</span> and variance is <span class=arithmatex>\(Var[X] = \frac{(a-b)^2}{12}\)</span>. This can be proven using: </p> <p><span class=arithmatex>\(E[X] = \int_a^bx\times\frac{1}{b-a}dx = \frac{a+b}{2}\)</span> </p> <p><span class=arithmatex>\(Var[X] = E[X^2] - E[X]^2 = \int_a^b x^2\times \frac{1}{b-a}dx - (\frac{a+b}{2})^2 = \frac{(b^3-a^3)}{3(b-a)}- \frac{(a+b)^2}{4} = \frac{a^2+b^2+ab}{4}-\frac{(a+b)^2}{4} = \frac{(a-b)^2}{12}\)</span> </p> <p>The same can also be verified by taking the mean and variance of the sample data:</p> <div class=highlight><pre><span></span><code><span class=nf>mean</span><span class=p>(</span><span class=n>dist</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>## [1] 7.592581
</code></pre></div> <div class=highlight><pre><span></span><code><span class=nf>var</span><span class=p>(</span><span class=n>dist</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>## [1] 2.017721
</code></pre></div> <h4 id=exponential-distribution>Exponential distribution<a class=headerlink href=#exponential-distribution title="Permanent link">&para;</a></h4> <p>In the geometric distribution, we looked at the probability of first success happening after n failures. In the exponential distribution, we look at the time taken until which an event occurs, or time elapsed between events. Only one parameter is sufficient to describe an exponential distribution, <span class=arithmatex>\(\lambda\)</span> which describes the successes per unit time. The PDF of an exponential distribution is given as: </p> <p><span class=arithmatex>\(PDF:= f(x) = \lambda\times e^{-\lambda x}\)</span> </p> <p>The CDF can be derived as </p> <p><span class=arithmatex>\(CDF = P(X&lt;x) = F(X) = \int_0^x \lambda\times e^{-\lambda y} dy = 1-e^{-\lambda x}\)</span></p> <p>Therefore 1-CDF can be written as <br> <span class=arithmatex>\(P(X&gt;x) = e^{-\lambda x}\)</span> </p> <p>The intervel <span class=arithmatex>\(x&gt;0\)</span> and <span class=arithmatex>\(\lambda&gt;0\)</span>. The distribution if an event happens on an average once every two minutes is as shown: </p> <div class=highlight><pre><span></span><code><span class=n>dist</span><span class=w> </span><span class=o>&lt;-</span><span class=w> </span><span class=nf>rexp</span><span class=p>(</span><span class=n>n</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=m>100</span><span class=p>,</span><span class=n>rate</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=m>0.5</span><span class=p>)</span>
<span class=nf>plot</span><span class=p>(</span><span class=n>dist</span><span class=p>)</span>
</code></pre></div> <p><img alt src=../Probability_files/figure-html/unnamed-chunk-12-1.png><!-- --></p> <p>The PDF and CDF are plotted below:</p> <div class=highlight><pre><span></span><code><span class=n>range</span><span class=w> </span><span class=o>&lt;-</span><span class=w> </span><span class=m>1</span><span class=o>:</span><span class=m>150</span><span class=o>/</span><span class=m>10</span>
<span class=n>pdf</span><span class=w> </span><span class=o>&lt;-</span><span class=w> </span><span class=nf>dexp</span><span class=p>(</span><span class=n>x</span><span class=o>=</span><span class=n>range</span><span class=p>,</span><span class=w> </span><span class=n>rate</span><span class=o>=</span><span class=w> </span><span class=m>0.5</span><span class=p>)</span>
<span class=n>cdf</span><span class=w> </span><span class=o>&lt;-</span><span class=w> </span><span class=nf>pexp</span><span class=p>(</span><span class=n>q</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>range</span><span class=p>,</span><span class=w> </span><span class=n>rate</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=m>0.5</span><span class=p>)</span>
<span class=nf>plot_pdf</span><span class=p>(</span><span class=n>pdf</span><span class=p>,</span><span class=n>range</span><span class=p>)</span>
</code></pre></div> <p><img alt src=../Probability_files/figure-html/unnamed-chunk-13-1.png><!-- --></p> <div class=highlight><pre><span></span><code><span class=nf>plot_cdf_continuous</span><span class=p>(</span><span class=n>cdf</span><span class=p>,</span><span class=w> </span><span class=n>range</span><span class=p>)</span>
</code></pre></div> <p><img alt src=../Probability_files/figure-html/unnamed-chunk-13-2.png><!-- --></p> <p>For the exponential distribution, the mean is <span class=arithmatex>\(E[X]=\frac{1}{\lambda}\)</span> and variance is <span class=arithmatex>\(Var[X] = \frac{1}{\lambda^2}\)</span>.<br> The same can also be verified by taking the mean and variance of the sample data:</p> <div class=highlight><pre><span></span><code><span class=nf>mean</span><span class=p>(</span><span class=n>dist</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>## [1] 2.309103
</code></pre></div> <div class=highlight><pre><span></span><code><span class=nf>var</span><span class=p>(</span><span class=n>dist</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>## [1] 5.504272
</code></pre></div> <h4 id=normal-distribution>Normal distribution<a class=headerlink href=#normal-distribution title="Permanent link">&para;</a></h4> <p>The normal distribution is the most famous continuous distribution. It has a unique bell-shaped curve. Randomness generally presents as a normal distribution. It is widespread in nature. Two parameters define a normal distribution, its mean <span class=arithmatex>\(\mu\)</span> and standard deviation <span class=arithmatex>\(\sigma\)</span>.<br> <span class=arithmatex>\(PDF:= f(x) = \frac{1}{2\pi \sigma^2}e^{-\frac{(x-\mu)^2}{2\sigma^2}}\)</span><br> The distribution with mean 10 and standard deviation 2 is as shown: </p> <div class=highlight><pre><span></span><code><span class=n>dist</span><span class=w> </span><span class=o>&lt;-</span><span class=w> </span><span class=nf>rnorm</span><span class=p>(</span><span class=n>n</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=m>100</span><span class=p>,</span><span class=n>mean</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=m>10</span><span class=p>,</span><span class=w> </span><span class=n>sd</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=m>2</span><span class=p>)</span>
<span class=nf>plot</span><span class=p>(</span><span class=n>dist</span><span class=p>)</span>
</code></pre></div> <p><img alt src=../Probability_files/figure-html/unnamed-chunk-15-1.png><!-- --></p> <p>The PDF and CDF are plotted below:</p> <div class=highlight><pre><span></span><code><span class=n>range</span><span class=w> </span><span class=o>&lt;-</span><span class=w> </span><span class=m>50</span><span class=o>:</span><span class=m>150</span><span class=o>/</span><span class=m>10</span>
<span class=n>pdf</span><span class=w> </span><span class=o>&lt;-</span><span class=w> </span><span class=nf>dnorm</span><span class=p>(</span><span class=n>x</span><span class=o>=</span><span class=n>range</span><span class=p>,</span><span class=w> </span><span class=n>mean</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=m>10</span><span class=p>,</span><span class=w> </span><span class=n>sd</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=m>2</span><span class=p>)</span>
<span class=n>cdf</span><span class=w> </span><span class=o>&lt;-</span><span class=w> </span><span class=nf>pnorm</span><span class=p>(</span><span class=n>q</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>range</span><span class=p>,</span><span class=w> </span><span class=n>mean</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=m>10</span><span class=p>,</span><span class=w> </span><span class=n>sd</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=m>2</span><span class=p>)</span>
<span class=nf>plot_pdf</span><span class=p>(</span><span class=n>pdf</span><span class=p>,</span><span class=n>range</span><span class=p>)</span>
</code></pre></div> <p><img alt src=../Probability_files/figure-html/unnamed-chunk-16-1.png><!-- --></p> <div class=highlight><pre><span></span><code><span class=nf>plot_cdf_continuous</span><span class=p>(</span><span class=n>cdf</span><span class=p>,</span><span class=w> </span><span class=n>range</span><span class=p>)</span>
</code></pre></div> <p><img alt src=../Probability_files/figure-html/unnamed-chunk-16-2.png><!-- --></p> <h2 id=references>References<a class=headerlink href=#references title="Permanent link">&para;</a></h2> <ol> <li>Blitzstein, JK and Hwang, J (2014). Introduction to Probability. CRC Press LLC </li> <li>Dinesh Kumar (2019). Business Analytics: the science of Data-Driven Decision Making </li> </ol> <div class=giscus></div> <script src=https://giscus.app/client.js data-repo=HarshaAsh/website-mkdocs data-repo-id="MDEwOlJlcG9zaXRvcnkzOTg4MjYzNjk=" data-category=General data-category-id=DIC_kwDOF8Wbgc4C2jiA data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=en crossorigin=anonymous async>
                  </script> </article> </div> </div> <a href=# class="md-top md-icon" data-md-component=top data-md-state=hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"/></svg> Back to top </a> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../../Python/Statistics%20basics/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Statistics Basics (Python)" rel=prev> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </div> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> Previous </span> Statistics Basics (Python) </div> </div> </a> <a href=../vectors/ class="md-footer__link md-footer__link--next" aria-label="Next: Vectors (R)" rel=next> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> Next </span> Vectors (R) </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright> <div class=md-footer-copyright__highlight> <img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png> </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-footer-contact style="text-align: center; margin: 1rem 0;"> <a href=../../contact title="Contact Me" style="display: inline-flex; align-items: center; gap: 0.5rem; color: rgba(255, 255, 255, 0.7); text-decoration: none;"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24" style="width: 1.2rem; height: 1.2rem; fill: rgba(255, 255, 255, 0.7);"> <path d="M20 4H4c-1.1 0-1.99.9-1.99 2L2 18c0 1.1.9 2 2 2h16c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zm0 4l-8 5-8-5V6l8 5 8-5v2z"/> </svg> <span>Contact Me</span> </a> </div> <div class=md-footer-social> <a href=https://github.com/HarshaAsh target=_blank rel=noopener title=github.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </a> <a href=https://www.linkedin.com/in/sri-harsha-achyuthuni/ target=_blank rel=noopener title=www.linkedin.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg> </a> <a href=https://www.instagram.com/harshaash_com/ target=_blank rel=noopener title=www.instagram.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M224.1 141c-63.6 0-114.9 51.3-114.9 114.9s51.3 114.9 114.9 114.9S339 319.5 339 255.9 287.7 141 224.1 141zm0 189.6c-41.1 0-74.7-33.5-74.7-74.7s33.5-74.7 74.7-74.7 74.7 33.5 74.7 74.7-33.6 74.7-74.7 74.7zm146.4-194.3c0 14.9-12 26.8-26.8 26.8-14.9 0-26.8-12-26.8-26.8s12-26.8 26.8-26.8 26.8 12 26.8 26.8zm76.1 27.2c-1.7-35.9-9.9-67.7-36.2-93.9-26.2-26.2-58-34.4-93.9-36.2-37-2.1-147.9-2.1-184.9 0-35.8 1.7-67.6 9.9-93.9 36.1s-34.4 58-36.2 93.9c-2.1 37-2.1 147.9 0 184.9 1.7 35.9 9.9 67.7 36.2 93.9s58 34.4 93.9 36.2c37 2.1 147.9 2.1 184.9 0 35.9-1.7 67.7-9.9 93.9-36.2 26.2-26.2 34.4-58 36.2-93.9 2.1-37 2.1-147.8 0-184.8zM398.8 388c-7.8 19.6-22.9 34.7-42.6 42.6-29.5 11.7-99.5 9-132.1 9s-102.7 2.6-132.1-9c-19.6-7.8-34.7-22.9-42.6-42.6-11.7-29.5-9-99.5-9-132.1s-2.6-102.7 9-132.1c7.8-19.6 22.9-34.7 42.6-42.6 29.5-11.7 99.5-9 132.1-9s102.7-2.6 132.1 9c19.6 7.8 34.7 22.9 42.6 42.6 11.7 29.5 9 99.5 9 132.1s2.7 102.7-9 132.1z"/></svg> </a> <a href=https://www.facebook.com/sri.harsha.achyuthuni/ target=_blank rel=noopener title=www.facebook.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><path d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.28c-30.8 0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../..", "features": ["content.code.annotate", "content.tabs.link", "header.autohide", "navigation.sections", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest"], "search": "../../assets/javascripts/workers/search.709b4209.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "version": null}</script> <script src=../../assets/javascripts/bundle.56838a2c.min.js></script> </body> </html>