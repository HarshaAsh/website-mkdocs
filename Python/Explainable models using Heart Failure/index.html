<!doctype html><html lang=en class=no-js> <head><!-- Code from google optimiser --><script src="https://www.googleoptimize.com/optimize.js?id=OPT-M98W6LW"></script><!-- Code from Mouseflow --><script type=text/javascript>
      window._mfq = window._mfq || [];
      (function() {
        var mf = document.createElement("script");
        mf.type = "text/javascript"; mf.defer = true;
        mf.src = "//cdn.mouseflow.com/projects/7b4494c9-7974-49f0-9777-d14450db37e6.js";
        document.getElementsByTagName("head")[0].appendChild(mf);
      })();
    </script><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Harsha's notes on data science"><meta name=author content="Harsha Achyuthuni"><link href=https://www.harshaash.com/Python/Explainable%20models%20using%20Heart%20Failure/ rel=canonical><link rel=icon href=../../assets/images/logo.jpg><meta name=generator content="mkdocs-1.5.0, mkdocs-material-7.2.4"><title>Explainable models (Python) - Data Science with Harsha</title><link rel=stylesheet href=../../assets/stylesheets/main.f7f47774.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.3f5d1f46.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback"><style>:root{--md-text-font-family:"Roboto";--md-code-font-family:"Roboto Mono"}</style><link rel=stylesheet href=../../overrides/assets/stylesheets/user_defined.css><script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-65034507-2","auto"),ga("set","anonymizeIp",!0),ga("send","pageview"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){var e;this.value&&(e=document.location.pathname,ga("send","pageview",e+"?q="+this.value))}),"undefined"!=typeof location$&&location$.subscribe(function(e){ga("send","pageview",e.pathname)})})</script><script async src=https://www.google-analytics.com/analytics.js></script></head> <body dir=ltr data-md-color-scheme data-md-color-primary data-md-color-accent> <script>function __prefix(e){return new URL("../..",location).pathname+"."+e}function __get(e,t=localStorage){return JSON.parse(t.getItem(__prefix(e)))}</script> <script>var palette=__get("__palette");if(null!==palette&&"object"==typeof palette.color)for(var key in palette.color)document.body.setAttribute("data-md-color-"+key,palette.color[key])</script> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#explainable-models-heart-failure-analysis class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="Data Science with Harsha" class="md-header__button md-logo" aria-label="Data Science with Harsha" data-md-component=logo> <img src=../../assets/images/logo.jpg alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Data Science with Harsha </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Explainable models (Python) </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme data-md-color-primary data-md-color-accent aria-hidden=true type=radio name=__palette id=__palette_1> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_2> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M7 10a2 2 0 0 1 2 2 2 2 0 0 1-2 2 2 2 0 0 1-2-2 2 2 0 0 1 2-2m10-3a5 5 0 0 1 5 5 5 5 0 0 1-5 5H7a5 5 0 0 1-5-5 5 5 0 0 1 5-5h10M7 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3h10a3 3 0 0 0 3-3 3 3 0 0 0-3-3H7z"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme data-md-color-primary data-md-color-accent aria-hidden=true type=radio name=__palette id=__palette_3> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=red data-md-color-accent=red aria-label="Switch to light mode" type=radio name=__palette id=__palette_4> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_3 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3z"/></svg> </label> </form> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08z"/></svg> </a> <button type=reset class="md-search__icon md-icon" aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="Data Science with Harsha" class="md-nav__button md-logo" aria-label="Data Science with Harsha" data-md-component=logo> <img src=../../assets/images/logo.jpg alt=logo> </a> Data Science with Harsha </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> Home </a> </li> <li class=md-nav__item> <a href=../../resume/ class=md-nav__link> Resume </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3 type=checkbox id=__nav_3 checked> <label class=md-nav__link for=__nav_3> Blog <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Blog data-md-level=1> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Blog </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Others/Table_of_Contents/ class=md-nav__link> Table of Contents </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_2 type=checkbox id=__nav_3_2> <label class=md-nav__link for=__nav_3_2> Visualization <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Visualization data-md-level=2> <label class=md-nav__title for=__nav_3_2> <span class="md-nav__icon md-icon"></span> Visualization </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../Vizualisation%20using%20python%20Part%201/ class=md-nav__link> Vizualizing tabular data (Python) </a> </li> <li class=md-nav__item> <a href=../Visualization%20for%20predictive%20analytics/ class=md-nav__link> Vizualising for predictive analytics (Python) </a> </li> <li class=md-nav__item> <a href=../../R/Univariate-analysis/ class=md-nav__link> Univariate Analysis (R) </a> </li> <li class=md-nav__item> <a href=../../R/multivariateAnalysis/ class=md-nav__link> Multivariate Analysis (R) </a> </li> <li class=md-nav__item> <a href=../../R/multicollinearity/ class=md-nav__link> Multicollinearity (R) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_3 type=checkbox id=__nav_3_3> <label class=md-nav__link for=__nav_3_3> Statistics basics <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Statistics basics" data-md-level=2> <label class=md-nav__title for=__nav_3_3> <span class="md-nav__icon md-icon"></span> Statistics basics </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../Statistics%20basics/ class=md-nav__link> Statistics Basics (Python) </a> </li> <li class=md-nav__item> <a href=../../R/Probability/ class=md-nav__link> Probability (R) </a> </li> <li class=md-nav__item> <a href=../../R/vectors/ class=md-nav__link> Vectors (R) </a> </li> <li class=md-nav__item> <a href=../../R/matrices/ class=md-nav__link> Matrices (R) </a> </li> <li class=md-nav__item> <a href=../Call%20center%20distributions/ class=md-nav__link> Call center distributions (Python) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_4 type=checkbox id=__nav_3_4> <label class=md-nav__link for=__nav_3_4> Hypothesis Testing <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Hypothesis Testing" data-md-level=2> <label class=md-nav__title for=__nav_3_4> <span class="md-nav__icon md-icon"></span> Hypothesis Testing </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../R/attendance_t_test/ class=md-nav__link> z-test and t-test (R) </a> </li> <li class=md-nav__item> <a href=../../R/anova/ class=md-nav__link> ANOVA Test (R) </a> </li> <li class=md-nav__item> <a href=../../R/chi-sq-goodness-of-fit/ class=md-nav__link> Chi-Square Goodness of fit (R) </a> </li> <li class=md-nav__item> <a href=../../R/chi-sq-test-of-independence/ class=md-nav__link> Chi-Square test of independence (R) </a> </li> <li class=md-nav__item> <a href=../Hypothesis_Testing_Python/ class=md-nav__link> Hypothesis testing using Python </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_5 type=checkbox id=__nav_3_5> <label class=md-nav__link for=__nav_3_5> Factor Analysis <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Factor Analysis" data-md-level=2> <label class=md-nav__title for=__nav_3_5> <span class="md-nav__icon md-icon"></span> Factor Analysis </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../R/Curse-of-Dimensionality/ class=md-nav__link> Curse of dimensionality </a> </li> <li class=md-nav__item> <a href=../../R/EFA/ class=md-nav__link> Exploratory factor analysis (R) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_6 type=checkbox id=__nav_3_6> <label class=md-nav__link for=__nav_3_6> Prediction algorithms <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Prediction algorithms" data-md-level=2> <label class=md-nav__title for=__nav_3_6> <span class="md-nav__icon md-icon"></span> Prediction algorithms </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_6_1 type=checkbox id=__nav_3_6_1> <label class=md-nav__link for=__nav_3_6_1> Classification Algorithms <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Classification Algorithms" data-md-level=3> <label class=md-nav__title for=__nav_3_6_1> <span class="md-nav__icon md-icon"></span> Classification Algorithms </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../R/logistic-regression/ class=md-nav__link> Logistic Regression (R) </a> </li> <li class=md-nav__item> <a href=../Linear%20regression%20usecase%20mpg%20prediction/ class=md-nav__link> Lasso and Ridge regression (Python) </a> </li> <li class=md-nav__item> <a href=../../R/CHAID/ class=md-nav__link> CHAID Decision Trees (R) </a> </li> <li class=md-nav__item> <a href=../../R/CART-Classification/ class=md-nav__link> CART Classification (R) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_6_2 type=checkbox id=__nav_3_6_2> <label class=md-nav__link for=__nav_3_6_2> Regression Algorithms <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Regression Algorithms" data-md-level=3> <label class=md-nav__title for=__nav_3_6_2> <span class="md-nav__icon md-icon"></span> Regression Algorithms </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../R/part-and-partial-corr/ class=md-nav__link> Part and partial correlation </a> </li> <li class=md-nav__item> <a href=../../R/Linear-regression/ class=md-nav__link> Linear Regression (R) </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_7 type=checkbox id=__nav_3_7> <label class=md-nav__link for=__nav_3_7> Preprocessing data <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Preprocessing data" data-md-level=2> <label class=md-nav__title for=__nav_3_7> <span class="md-nav__icon md-icon"></span> Preprocessing data </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../R/KNN_Imputation/ class=md-nav__link> Null Value Imputation (R) </a> </li> <li class=md-nav__item> <a href=../Machine%20Learning%20Part%201/ class=md-nav__link> Feature engineering (Python) </a> </li> <li class=md-nav__item> <a href=../../R/Handling-Imbalanced-classes/ class=md-nav__link> Handling Imbalanced Classes </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_8 type=checkbox id=__nav_3_8 checked> <label class=md-nav__link for=__nav_3_8> Machine Learning <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Machine Learning" data-md-level=2> <label class=md-nav__title for=__nav_3_8> <span class="md-nav__icon md-icon"></span> Machine Learning </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=https://harshaachyuthuni.shinyapps.io/Machine_Learning/ class=md-nav__link> Interactive Machine Learning (RShiny) </a> </li> <li class=md-nav__item> <a href=../ML%20using%20scikit-learn/ class=md-nav__link> Multi models (Python) </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" data-md-toggle=toc type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> Explainable models (Python) <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> Explainable models (Python) </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#dataset class=md-nav__link> Dataset </a> </li> <li class=md-nav__item> <a href=#use-case-description class=md-nav__link> Use Case Description </a> </li> <li class=md-nav__item> <a href=#explainable-models class=md-nav__link> Explainable Models </a> </li> <li class=md-nav__item> <a href=#eda-exploratory-data-analysis class=md-nav__link> EDA (Exploratory Data Analysis) </a> </li> <li class=md-nav__item> <a href=#feature-engineering-and-cleaning class=md-nav__link> Feature Engineering and Cleaning </a> <nav class=md-nav aria-label="Feature Engineering and Cleaning"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#preprocessing-pipelines class=md-nav__link> Preprocessing &amp; Pipelines </a> </li> <li class=md-nav__item> <a href=#trainvalidationtest-split class=md-nav__link> Train/Validation/Test split </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#baseline-model class=md-nav__link> Baseline model </a> </li> <li class=md-nav__item> <a href=#key-classification-metrics class=md-nav__link> Key Classification Metrics </a> </li> <li class=md-nav__item> <a href=#logistic-regression class=md-nav__link> Logistic Regression </a> </li> <li class=md-nav__item> <a href=#decision-tree-shallow-rule-based class=md-nav__link> Decision Tree (Shallow, Rule-Based) </a> </li> <li class=md-nav__item> <a href=#cart-decision-tree-with-cost-complexity-pruning class=md-nav__link> CART (Decision Tree with Cost-Complexity Pruning) </a> </li> <li class=md-nav__item> <a href=#naive-bayes-gaussian class=md-nav__link> Naive Bayes (Gaussian) </a> </li> <li class=md-nav__item> <a href=#k-nearest-neighbors-k-nn class=md-nav__link> k-Nearest Neighbors (k-NN) </a> </li> <li class=md-nav__item> <a href=#diagnostics-of-the-best-model class=md-nav__link> Diagnostics of the Best Model </a> <nav class=md-nav aria-label="Diagnostics of the Best Model"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#roc-auc-curve class=md-nav__link> ROC-AUC Curve </a> </li> <li class=md-nav__item> <a href=#sensitivity-specificity-curve class=md-nav__link> Sensitivity-Specificity Curve </a> </li> <li class=md-nav__item> <a href=#learning-curves class=md-nav__link> Learning curves </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#ethics-and-robustness class=md-nav__link> Ethics and robustness </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../Demonstrating%20online%20learning/ class=md-nav__link> Streaming Machine Learning (Python) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_9 type=checkbox id=__nav_3_9> <label class=md-nav__link for=__nav_3_9> Time Series forecasting <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Time Series forecasting" data-md-level=2> <label class=md-nav__title for=__nav_3_9> <span class="md-nav__icon md-icon"></span> Time Series forecasting </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../R/time-series/ class=md-nav__link> Introduction to stationarity (R) </a> </li> <li class=md-nav__item> <a href=../../R/Stationarity-tests/ class=md-nav__link> Stationary Tests (R) </a> </li> <li class=md-nav__item> <a href=../../R/ARIMA/ class=md-nav__link> ARIMA in R </a> </li> <li class=md-nav__item> <a href=../ARIMA%20Forecasting/ class=md-nav__link> ARIMA in Python </a> </li> <li class=md-nav__item> <a href=../../R/Seasonal-Time-Series/ class=md-nav__link> Seasonal time series (R) </a> </li> <li class=md-nav__item> <a href=../../R/VAR-models/ class=md-nav__link> VAR Models (R) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_10 type=checkbox id=__nav_3_10> <label class=md-nav__link for=__nav_3_10> Deep learning <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Deep learning" data-md-level=2> <label class=md-nav__title for=__nav_3_10> <span class="md-nav__icon md-icon"></span> Deep learning </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../ANN-1/ class=md-nav__link> Perceptron </a> </li> <li class=md-nav__item> <a href=../Backpropagation/ class=md-nav__link> Backpropagation </a> </li> <li class=md-nav__item> <a href=../DNN/ class=md-nav__link> Tensorflow and Keras </a> </li> <li class=md-nav__item> <a href=../Time%20series%20deep%20learning/ class=md-nav__link> Time series (python) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_11 type=checkbox id=__nav_3_11> <label class=md-nav__link for=__nav_3_11> Generative AI <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Generative AI" data-md-level=2> <label class=md-nav__title for=__nav_3_11> <span class="md-nav__icon md-icon"></span> Generative AI </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../LLM%20Tokenizers/ class=md-nav__link> LLM Tokenizers </a> </li> <li class=md-nav__item> <a href=../Agentic%20AI/ class=md-nav__link> Agentic AI </a> </li> <li class=md-nav__item> <a href=../RAG/ class=md-nav__link> RAG </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_12 type=checkbox id=__nav_3_12> <label class=md-nav__link for=__nav_3_12> Prescriptive Analytics <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Prescriptive Analytics" data-md-level=2> <label class=md-nav__title for=__nav_3_12> <span class="md-nav__icon md-icon"></span> Prescriptive Analytics </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../R/Linear-programming/ class=md-nav__link> Linear Programming (R) </a> </li> <li class=md-nav__item> <a href=../../R/adoption_of_new_product/ class=md-nav__link> Adoption of new product (R) </a> </li> <li class=md-nav__item> <a href=../Diffusion%20on%20networks/ class=md-nav__link> Bass Forecasting model (Python) </a> </li> <li class=md-nav__item> <a href=../../Others/AHP/ class=md-nav__link> Analytic Hierarchy Process </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_13 type=checkbox id=__nav_3_13> <label class=md-nav__link for=__nav_3_13> Clustering <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Clustering data-md-level=2> <label class=md-nav__title for=__nav_3_13> <span class="md-nav__icon md-icon"></span> Clustering </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../R/hierarchical_clustering/ class=md-nav__link> Hierarchical Clustering </a> </li> <li class=md-nav__item> <a href=../../R/kMeansClustering/ class=md-nav__link> K-Means Clustering </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_14 type=checkbox id=__nav_3_14> <label class=md-nav__link for=__nav_3_14> Reinforcement Learning <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Reinforcement Learning" data-md-level=2> <label class=md-nav__title for=__nav_3_14> <span class="md-nav__icon md-icon"></span> Reinforcement Learning </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../R/CustomerLifetimeValue/ class=md-nav__link> Customer Lifetime Value </a> </li> <li class=md-nav__item> <a href=../../R/recommendation-systems/ class=md-nav__link> Recommendation Systems (R) </a> </li> <li class=md-nav__item> <a href=../Neural_collaborative_filtering/ class=md-nav__link> Collaborative Filtering (Python) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_15 type=checkbox id=__nav_3_15> <label class=md-nav__link for=__nav_3_15> Networks <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Networks data-md-level=2> <label class=md-nav__title for=__nav_3_15> <span class="md-nav__icon md-icon"></span> Networks </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../Introduction%20to%20Networkx/ class=md-nav__link> Introduction to NetworkX (Python) </a> </li> <li class=md-nav__item> <a href=../Network%20Science/ class=md-nav__link> Network Science (Python) </a> </li> <li class=md-nav__item> <a href=../Network%20centrality/ class=md-nav__link> Network Centrality (Python) </a> </li> <li class=md-nav__item> <a href=../Shortest%20path%20problems/ class=md-nav__link> Shortest path using integer programming (Python) </a> </li> <li class=md-nav__item> <a href=../Network%20Flow%20problems/ class=md-nav__link> Network flow problems (Python) </a> </li> <li class=md-nav__item> <a href=../Community%20detection/ class=md-nav__link> Community detection (Python) </a> </li> <li class=md-nav__item> <a href=../Bipartite%20matching/ class=md-nav__link> Bipartite matching (Python) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_16 type=checkbox id=__nav_3_16> <label class=md-nav__link for=__nav_3_16> Deployment <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Deployment data-md-level=2> <label class=md-nav__title for=__nav_3_16> <span class="md-nav__icon md-icon"></span> Deployment </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../Machine%20learning%20as%20HTTP%20Request/ class=md-nav__link> ML deployment in Flask (Python) </a> </li> <li class=md-nav__item> <a href=../Saving%20predictions%20in%20database/ class=md-nav__link> Handling databases using python </a> </li> <li class=md-nav__item> <a href=../ORM/ class=md-nav__link> ORM (Python) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_17 type=checkbox id=__nav_3_17> <label class=md-nav__link for=__nav_3_17> Higher education review <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Higher education review" data-md-level=2> <label class=md-nav__title for=__nav_3_17> <span class="md-nav__icon md-icon"></span> Higher education review </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Others/IIMB%20BAI/ class=md-nav__link> IIMB BAI </a> </li> <li class=md-nav__item> <a href=../../Others/part%20time%20data%20science%20masters/ class=md-nav__link> Part-time DS masters </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_18 type=checkbox id=__nav_3_18> <label class=md-nav__link for=__nav_3_18> External blogs <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="External blogs" data-md-level=2> <label class=md-nav__title for=__nav_3_18> <span class="md-nav__icon md-icon"></span> External blogs </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Others/Imperial%20College%20London/ class=md-nav__link> Imperial college London </a> </li> <li class=md-nav__item> <a href=../../Others/Rolls%20Royce/ class=md-nav__link> Rolls Royce </a> </li> <li class=md-nav__item> <a href=../../Others/Publications/ class=md-nav__link> Publications/conferences </a> </li> <li class=md-nav__item> <a href=../../Others/Deployed%20apps/ class=md-nav__link> Deployed apps </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_19 type=checkbox id=__nav_3_19> <label class=md-nav__link for=__nav_3_19> Projects <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Projects data-md-level=2> <label class=md-nav__title for=__nav_3_19> <span class="md-nav__icon md-icon"></span> Projects </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Others/preventive_maintainence/ class=md-nav__link> Preventive maintainence </a> </li> <li class=md-nav__item> <a href=../../Others/Contract%20Intelligence%20tool/ class=md-nav__link> Contract Intelligence </a> </li> <li class=md-nav__item> <a href=../../Others/competitor%20intelligence/ class=md-nav__link> Competitor intelligence </a> </li> <li class=md-nav__item> <a href=../../Others/Scarecrow/ class=md-nav__link> Intelligent annotation </a> </li> <li class=md-nav__item> <a href=../../Others/Demand%20Forecasting/ class=md-nav__link> Demand Forecasting </a> </li> <li class=md-nav__item> <a href=../../Others/bid%20allocation%20model/ class=md-nav__link> Bid Allocation </a> </li> <li class=md-nav__item> <a href=../../Others/IIMB%20project/ class=md-nav__link> Reward and Recognition contests </a> </li> <li class=md-nav__item> <a href=../../Others/supply%20chain%20analytics/ class=md-nav__link> Supply chain analytics </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#dataset class=md-nav__link> Dataset </a> </li> <li class=md-nav__item> <a href=#use-case-description class=md-nav__link> Use Case Description </a> </li> <li class=md-nav__item> <a href=#explainable-models class=md-nav__link> Explainable Models </a> </li> <li class=md-nav__item> <a href=#eda-exploratory-data-analysis class=md-nav__link> EDA (Exploratory Data Analysis) </a> </li> <li class=md-nav__item> <a href=#feature-engineering-and-cleaning class=md-nav__link> Feature Engineering and Cleaning </a> <nav class=md-nav aria-label="Feature Engineering and Cleaning"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#preprocessing-pipelines class=md-nav__link> Preprocessing &amp; Pipelines </a> </li> <li class=md-nav__item> <a href=#trainvalidationtest-split class=md-nav__link> Train/Validation/Test split </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#baseline-model class=md-nav__link> Baseline model </a> </li> <li class=md-nav__item> <a href=#key-classification-metrics class=md-nav__link> Key Classification Metrics </a> </li> <li class=md-nav__item> <a href=#logistic-regression class=md-nav__link> Logistic Regression </a> </li> <li class=md-nav__item> <a href=#decision-tree-shallow-rule-based class=md-nav__link> Decision Tree (Shallow, Rule-Based) </a> </li> <li class=md-nav__item> <a href=#cart-decision-tree-with-cost-complexity-pruning class=md-nav__link> CART (Decision Tree with Cost-Complexity Pruning) </a> </li> <li class=md-nav__item> <a href=#naive-bayes-gaussian class=md-nav__link> Naive Bayes (Gaussian) </a> </li> <li class=md-nav__item> <a href=#k-nearest-neighbors-k-nn class=md-nav__link> k-Nearest Neighbors (k-NN) </a> </li> <li class=md-nav__item> <a href=#diagnostics-of-the-best-model class=md-nav__link> Diagnostics of the Best Model </a> <nav class=md-nav aria-label="Diagnostics of the Best Model"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#roc-auc-curve class=md-nav__link> ROC-AUC Curve </a> </li> <li class=md-nav__item> <a href=#sensitivity-specificity-curve class=md-nav__link> Sensitivity-Specificity Curve </a> </li> <li class=md-nav__item> <a href=#learning-curves class=md-nav__link> Learning curves </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#ethics-and-robustness class=md-nav__link> Ethics and robustness </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <script type=text/javascript src=https://cdn.mathjax.org/mathjax/latest/MathJax.js>
MathJax.Hub.Config({
 extensions: ["tex2jax.js","TeX/AMSmath.js","TeX/AMSsymbols.js"],
 jax: ["input/TeX", "output/HTML-CSS"],
 tex2jax: {
     inlineMath: [ ['$','$'], ["\\(","\\)"] ],
     displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
 },
 "HTML-CSS": { availableFonts: ["TeX"] }
});
</script> <h1 id=explainable-models-heart-failure-analysis>Explainable models: Heart Failure Analysis<a class=headerlink href=#explainable-models-heart-failure-analysis title="Permanent link">&para;</a></h1> <p>This notebook performs a classification analysis on the Heart Failure Prediction dataset in such a way that doctors can use it in their clinics directly without using any blackbox models. The goal is to predict whether a patient has heart disease based on clinical and demographic features such as age, blood pressure, cholesterol level, and exercise-related indicators. </p> <h2 id=dataset>Dataset<a class=headerlink href=#dataset title="Permanent link">&para;</a></h2> <p>The dataset is designed to predict the presence of heart disease using a mix of numeric and categorical attributes collected from patients. It combines data from five well-known heart disease studies into a single, clean dataset with 918 observations. Predicting heart disease risk is critical for early intervention, improving patient outcomes, and supporting healthcare decision-making. </p> <h2 id=use-case-description>Use Case Description<a class=headerlink href=#use-case-description title="Permanent link">&para;</a></h2> <p>Our objective is to classify patients as having heart disease or not using logistic regression techniques. This involves:<br> 1. Exploring relationships between patient attributes and heart disease occurrence<br> 2. Identifying statistically significant predictors<br> 3. Validating model assumptions and performance<br> 4. Diagnosing issues such as multicollinearity and calibration<br> 5. Evaluating model robustness using cross-validation, ROC curves, and threshold tuning </p> <h2 id=explainable-models>Explainable Models<a class=headerlink href=#explainable-models title="Permanent link">&para;</a></h2> <p>For doctors in a hospital setting, simple and highly explainable models are essential because they can be translated into quick, actionable rules for patient screening. These models allow clinicians to make fast decisions without relying on complex computations or black-box algorithms. Some commonly used, interpretable models include:<br> 1. Logistic Regression: Provides clear insights through coefficients and odds ratios, making it easy to understand how each factor influences heart disease risk.<br> 2. Decision Trees: Offer intuitive, rule-based structures that can be visualized and converted into simple “if-then” guidelines for clinical use.<br> 3. Rule-Based Models (e.g., CART or CHAID) – Extend decision trees into sets of human-readable rules for rapid triage.<br> 4. Naïve Bayes: Based on conditional probabilities; Easy to interpret and explain as likelihoods.<br> 5. Simple k-Nearest Neighbors (k-NN): While not inherently rule-based, its logic ("You look most like these N past patients who had/didn’t have heart disease.”) is easy to explain in clinical terms. </p> <p>Dataset card: <a href=https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction>https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction</a><br> Fallback CSV mirror: <a href=https://raw.githubusercontent.com/benbobyabraham/heart_failure_prediction_dataset_kaggle/main/heart.csv>https://raw.githubusercontent.com/benbobyabraham/heart_failure_prediction_dataset_kaggle/main/heart.csv</a> </p> <p>Importing packages</p> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>os</span><span class=o>,</span> <span class=nn>sys</span><span class=o>,</span> <span class=nn>warnings</span><span class=o>,</span> <span class=nn>json</span>
<span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
<span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
<span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
<span class=kn>import</span> <span class=nn>seaborn</span> <span class=k>as</span> <span class=nn>sns</span>

<span class=kn>from</span> <span class=nn>sklearn.compose</span> <span class=kn>import</span> <span class=n>ColumnTransformer</span>
<span class=kn>from</span> <span class=nn>sklearn.pipeline</span> <span class=kn>import</span> <span class=n>Pipeline</span>
<span class=kn>from</span> <span class=nn>sklearn.preprocessing</span> <span class=kn>import</span> <span class=n>OneHotEncoder</span><span class=p>,</span> <span class=n>StandardScaler</span>
<span class=kn>from</span> <span class=nn>sklearn.impute</span> <span class=kn>import</span> <span class=n>SimpleImputer</span>
<span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>train_test_split</span><span class=p>,</span> <span class=n>StratifiedKFold</span><span class=p>,</span> <span class=n>GridSearchCV</span><span class=p>,</span> <span class=n>cross_val_score</span><span class=p>,</span> <span class=n>learning_curve</span><span class=p>,</span> <span class=n>validation_curve</span>
<span class=kn>from</span> <span class=nn>sklearn.metrics</span> <span class=kn>import</span> <span class=p>(</span><span class=n>accuracy_score</span><span class=p>,</span> <span class=n>precision_score</span><span class=p>,</span> <span class=n>recall_score</span><span class=p>,</span> <span class=n>f1_score</span><span class=p>,</span> <span class=n>roc_auc_score</span><span class=p>,</span> <span class=n>roc_curve</span><span class=p>,</span> <span class=n>auc</span><span class=p>,</span>
                             <span class=n>confusion_matrix</span><span class=p>,</span> <span class=n>classification_report</span><span class=p>,</span> <span class=n>precision_recall_curve</span><span class=p>,</span> <span class=n>average_precision_score</span><span class=p>,</span>
                             <span class=n>brier_score_loss</span><span class=p>,</span> <span class=n>RocCurveDisplay</span><span class=p>,</span> <span class=n>PrecisionRecallDisplay</span><span class=p>)</span>
<span class=kn>from</span> <span class=nn>sklearn.linear_model</span> <span class=kn>import</span> <span class=n>LogisticRegression</span>
<span class=kn>from</span> <span class=nn>sklearn.dummy</span> <span class=kn>import</span> <span class=n>DummyClassifier</span>
<span class=kn>from</span> <span class=nn>sklearn.calibration</span> <span class=kn>import</span> <span class=n>CalibratedClassifierCV</span><span class=p>,</span> <span class=n>CalibrationDisplay</span>
<span class=kn>from</span> <span class=nn>sklearn.tree</span> <span class=kn>import</span> <span class=n>export_text</span>
<span class=kn>import</span> <span class=nn>joblib</span>

<span class=kn>import</span> <span class=nn>statsmodels.api</span> <span class=k>as</span> <span class=nn>sm</span>
<span class=kn>import</span> <span class=nn>statsmodels.formula.api</span> <span class=k>as</span> <span class=nn>smf</span>

<span class=n>warnings</span><span class=o>.</span><span class=n>filterwarnings</span><span class=p>(</span><span class=s1>&#39;ignore&#39;</span><span class=p>)</span>
<span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>
<span class=n>sns</span><span class=o>.</span><span class=n>set</span><span class=p>(</span><span class=n>style</span><span class=o>=</span><span class=s1>&#39;whitegrid&#39;</span><span class=p>,</span> <span class=n>context</span><span class=o>=</span><span class=s1>&#39;notebook&#39;</span><span class=p>)</span>
</code></pre></div> <p>We try to read <code>heart.csv</code> from the Data folder. If not present, we fetch a public <strong>read‑only mirror</strong> of the Kaggle CSV from GitHub. </p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>pathlib</span> <span class=kn>import</span> <span class=n>Path</span>
<span class=kn>import</span> <span class=nn>io</span><span class=o>,</span> <span class=nn>urllib.request</span>

<span class=n>DATA_LOCAL</span> <span class=o>=</span> <span class=n>Path</span><span class=p>(</span><span class=s1>&#39;../Data/heart.csv&#39;</span><span class=p>)</span>
<span class=n>DATA_URL</span> <span class=o>=</span> <span class=s1>&#39;https://raw.githubusercontent.com/benbobyabraham/heart_failure_prediction_dataset_kaggle/main/heart.csv&#39;</span>

<span class=k>if</span> <span class=n>DATA_LOCAL</span><span class=o>.</span><span class=n>exists</span><span class=p>():</span>
    <span class=n>df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=n>DATA_LOCAL</span><span class=p>)</span>
<span class=k>else</span><span class=p>:</span>
    <span class=k>try</span><span class=p>:</span>
        <span class=k>with</span> <span class=n>urllib</span><span class=o>.</span><span class=n>request</span><span class=o>.</span><span class=n>urlopen</span><span class=p>(</span><span class=n>DATA_URL</span><span class=p>)</span> <span class=k>as</span> <span class=n>resp</span><span class=p>:</span>
            <span class=n>df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=n>io</span><span class=o>.</span><span class=n>BytesIO</span><span class=p>(</span><span class=n>resp</span><span class=o>.</span><span class=n>read</span><span class=p>()))</span>
    <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
        <span class=k>raise</span> <span class=ne>FileNotFoundError</span><span class=p>(</span><span class=s1>&#39;Could not find heart.csv locally or fetch from the fallback URL. Please download from Kaggle and place heart.csv next to this notebook.&#39;</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=n>df</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
<span class=n>df</span><span class=o>.</span><span class=n>head</span><span class=p>()</span>
</code></pre></div> <div class=highlight><pre><span></span><code>(918, 12)
</code></pre></div> <div> <style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style> <table border=1 class=dataframe> <thead> <tr style="text-align: right;"> <th></th> <th>Age</th> <th>Sex</th> <th>ChestPainType</th> <th>RestingBP</th> <th>Cholesterol</th> <th>FastingBS</th> <th>RestingECG</th> <th>MaxHR</th> <th>ExerciseAngina</th> <th>Oldpeak</th> <th>ST_Slope</th> <th>HeartDisease</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>40</td> <td>M</td> <td>ATA</td> <td>140</td> <td>289</td> <td>0</td> <td>Normal</td> <td>172</td> <td>N</td> <td>0.0</td> <td>Up</td> <td>0</td> </tr> <tr> <th>1</th> <td>49</td> <td>F</td> <td>NAP</td> <td>160</td> <td>180</td> <td>0</td> <td>Normal</td> <td>156</td> <td>N</td> <td>1.0</td> <td>Flat</td> <td>1</td> </tr> <tr> <th>2</th> <td>37</td> <td>M</td> <td>ATA</td> <td>130</td> <td>283</td> <td>0</td> <td>ST</td> <td>98</td> <td>N</td> <td>0.0</td> <td>Up</td> <td>0</td> </tr> <tr> <th>3</th> <td>48</td> <td>F</td> <td>ASY</td> <td>138</td> <td>214</td> <td>0</td> <td>Normal</td> <td>108</td> <td>Y</td> <td>1.5</td> <td>Flat</td> <td>1</td> </tr> <tr> <th>4</th> <td>54</td> <td>M</td> <td>NAP</td> <td>150</td> <td>195</td> <td>0</td> <td>Normal</td> <td>122</td> <td>N</td> <td>0.0</td> <td>Up</td> <td>0</td> </tr> </tbody> </table> </div> <h2 id=eda-exploratory-data-analysis>EDA (Exploratory Data Analysis)<a class=headerlink href=#eda-exploratory-data-analysis title="Permanent link">&para;</a></h2> <p>Data attributes and description</p> <table> <thead> <tr> <th>Column Name</th> <th>Description</th> </tr> </thead> <tbody> <tr> <td><strong>Age</strong></td> <td>Age of the patient (years)</td> </tr> <tr> <td><strong>Sex</strong></td> <td>Gender of the patient (M/F)</td> </tr> <tr> <td><strong>ChestPainType</strong></td> <td>Type of chest pain (ATA, NAP, ASY, TA)</td> </tr> <tr> <td><strong>RestingBP</strong></td> <td>Resting blood pressure (mm Hg)</td> </tr> <tr> <td><strong>Cholesterol</strong></td> <td>Serum cholesterol (mg/dl)</td> </tr> <tr> <td><strong>FastingBS</strong></td> <td>Fasting blood sugar (&gt;120 mg/dl: 1, else: 0)</td> </tr> <tr> <td><strong>RestingECG</strong></td> <td>Resting electrocardiogram results</td> </tr> <tr> <td><strong>MaxHR</strong></td> <td>Maximum heart rate achieved</td> </tr> <tr> <td><strong>ExerciseAngina</strong></td> <td>Exercise-induced angina (Y/N)</td> </tr> <tr> <td><strong>Oldpeak</strong></td> <td>ST depression induced by exercise relative to rest</td> </tr> <tr> <td><strong>ST_Slope</strong></td> <td>Slope of the peak exercise ST segment</td> </tr> <tr> <td><strong>HeartDisease</strong></td> <td>Target variable (1 = disease present, 0 = no disease)</td> </tr> </tbody> </table> <p><strong>Feature types</strong>: Mix of numeric (<em>Age</em>, <em>RestingBP</em>, <em>Cholesterol</em>, <em>MaxHR</em>, <em>Oldpeak</em>) and categorical (<em>Sex</em>, <em>ChestPainType</em>, <em>RestingECG</em>, <em>ExerciseAngina</em>, <em>ST_Slope</em>), plus a binary variable <em>FastingBS</em>.<br> <strong>Unit notes</strong>: e.g., <em>RestingBP</em> in mmHg, <em>Cholesterol</em> in mg/dl; some sources note 0 values may indicate missing/not measured.</p> <div class=highlight><pre><span></span><code><span class=n>df</span><span class=p>[</span><span class=s1>&#39;FastingBS&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>FastingBS</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=nb>str</span><span class=p>)</span>
<span class=n>df</span><span class=p>[</span><span class=s1>&#39;HeartDisease&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>HeartDisease</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=nb>str</span><span class=p>)</span>
<span class=n>df</span><span class=o>.</span><span class=n>describe</span><span class=p>()</span>
</code></pre></div> <div> <style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style> <table border=1 class=dataframe> <thead> <tr style="text-align: right;"> <th></th> <th>Age</th> <th>RestingBP</th> <th>Cholesterol</th> <th>MaxHR</th> <th>Oldpeak</th> </tr> </thead> <tbody> <tr> <th>count</th> <td>918.000000</td> <td>918.000000</td> <td>918.000000</td> <td>918.000000</td> <td>918.000000</td> </tr> <tr> <th>mean</th> <td>53.510893</td> <td>132.396514</td> <td>198.799564</td> <td>136.809368</td> <td>0.887364</td> </tr> <tr> <th>std</th> <td>9.432617</td> <td>18.514154</td> <td>109.384145</td> <td>25.460334</td> <td>1.066570</td> </tr> <tr> <th>min</th> <td>28.000000</td> <td>0.000000</td> <td>0.000000</td> <td>60.000000</td> <td>-2.600000</td> </tr> <tr> <th>25%</th> <td>47.000000</td> <td>120.000000</td> <td>173.250000</td> <td>120.000000</td> <td>0.000000</td> </tr> <tr> <th>50%</th> <td>54.000000</td> <td>130.000000</td> <td>223.000000</td> <td>138.000000</td> <td>0.600000</td> </tr> <tr> <th>75%</th> <td>60.000000</td> <td>140.000000</td> <td>267.000000</td> <td>156.000000</td> <td>1.500000</td> </tr> <tr> <th>max</th> <td>77.000000</td> <td>200.000000</td> <td>603.000000</td> <td>202.000000</td> <td>6.200000</td> </tr> </tbody> </table> </div> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>ml_plottings</span> <span class=kn>import</span> <span class=n>univariate_analysis</span><span class=p>,</span> <span class=n>classification_bivariate_analysis</span><span class=p>,</span> <span class=n>plot_correlation_matrix</span>
<span class=n>univariate_analysis</span><span class=p>(</span><span class=n>df</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>Sex
</code></pre></div> <p><img alt=png src=output_7_1.png></p> <p><img alt=png src=output_7_2.png></p> <div class=highlight><pre><span></span><code>------------------------------------------------------------------------------------------------
ChestPainType
</code></pre></div> <p><img alt=png src=output_7_4.png></p> <p><img alt=png src=output_7_5.png></p> <div class=highlight><pre><span></span><code>------------------------------------------------------------------------------------------------
FastingBS
</code></pre></div> <p><img alt=png src=output_7_7.png></p> <p><img alt=png src=output_7_8.png></p> <div class=highlight><pre><span></span><code>------------------------------------------------------------------------------------------------
RestingECG
</code></pre></div> <p><img alt=png src=output_7_10.png></p> <p><img alt=png src=output_7_11.png></p> <div class=highlight><pre><span></span><code>------------------------------------------------------------------------------------------------
ExerciseAngina
</code></pre></div> <p><img alt=png src=output_7_13.png></p> <p><img alt=png src=output_7_14.png></p> <div class=highlight><pre><span></span><code>------------------------------------------------------------------------------------------------
ST_Slope
</code></pre></div> <p><img alt=png src=output_7_16.png></p> <p><img alt=png src=output_7_17.png></p> <div class=highlight><pre><span></span><code>------------------------------------------------------------------------------------------------
HeartDisease
</code></pre></div> <p><img alt=png src=output_7_19.png></p> <p><img alt=png src=output_7_20.png></p> <div class=highlight><pre><span></span><code>------------------------------------------------------------------------------------------------
Age
</code></pre></div> <p><img alt=png src=output_7_22.png></p> <p><img alt=png src=output_7_23.png></p> <p><img alt=png src=output_7_24.png></p> <div class=highlight><pre><span></span><code>------------------------------------------------------------------------------------------------
RestingBP
</code></pre></div> <p><img alt=png src=output_7_26.png></p> <p><img alt=png src=output_7_27.png></p> <p><img alt=png src=output_7_28.png></p> <div class=highlight><pre><span></span><code>------------------------------------------------------------------------------------------------
Cholesterol
</code></pre></div> <p><img alt=png src=output_7_30.png></p> <p><img alt=png src=output_7_31.png></p> <p><img alt=png src=output_7_32.png></p> <div class=highlight><pre><span></span><code>------------------------------------------------------------------------------------------------
MaxHR
</code></pre></div> <p><img alt=png src=output_7_34.png></p> <p><img alt=png src=output_7_35.png></p> <p><img alt=png src=output_7_36.png></p> <div class=highlight><pre><span></span><code>------------------------------------------------------------------------------------------------
Oldpeak
</code></pre></div> <p><img alt=png src=output_7_38.png></p> <p><img alt=png src=output_7_39.png></p> <p><img alt=png src=output_7_40.png></p> <div class=highlight><pre><span></span><code>------------------------------------------------------------------------------------------------
</code></pre></div> <div class=highlight><pre><span></span><code><span class=n>classification_bivariate_analysis</span><span class=p>(</span><span class=n>df</span><span class=p>,</span> <span class=s1>&#39;HeartDisease&#39;</span><span class=p>)</span>
</code></pre></div> <p><img alt=png src=output_8_0.png></p> <p><img alt=png src=output_8_1.png></p> <p><img alt=png src=output_8_2.png></p> <p><img alt=png src=output_8_3.png></p> <p><img alt=png src=output_8_4.png></p> <p><img alt=png src=output_8_5.png></p> <p><img alt=png src=output_8_6.png></p> <p><img alt=png src=output_8_7.png></p> <p><img alt=png src=output_8_8.png></p> <p><img alt=png src=output_8_9.png></p> <p><img alt=png src=output_8_10.png></p> <p>Defining the categorical and continuous variables</p> <div class=highlight><pre><span></span><code><span class=n>num_cols</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;Age&#39;</span><span class=p>,</span> <span class=s1>&#39;RestingBP&#39;</span><span class=p>,</span> <span class=s1>&#39;Cholesterol&#39;</span><span class=p>,</span> <span class=s1>&#39;MaxHR&#39;</span><span class=p>,</span> <span class=s1>&#39;Oldpeak&#39;</span><span class=p>]</span>
<span class=n>cat_cols</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;Sex&#39;</span><span class=p>,</span> <span class=s1>&#39;ChestPainType&#39;</span><span class=p>,</span> <span class=s1>&#39;RestingECG&#39;</span><span class=p>,</span> <span class=s1>&#39;ExerciseAngina&#39;</span><span class=p>,</span> <span class=s1>&#39;ST_Slope&#39;</span><span class=p>]</span>
<span class=n>binary_cols</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;FastingBS&#39;</span><span class=p>]</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=n>plot_correlation_matrix</span><span class=p>(</span><span class=n>df</span><span class=p>,</span> <span class=n>num_cols</span><span class=o>+</span><span class=n>binary_cols</span><span class=p>)</span>
</code></pre></div> <p><img alt=png src=output_11_0.png></p> <p><strong>Key Insights from Exploratory Data Analysis</strong><br> 1. Univariate Analysis - Target Distribution: About 55% of patients have heart disease, while 45% do not.<br> - Demographics:<br> - Approximately 80% of patients are male.<br> - Age ranges from 28 to 77 years, roughly normally distributed.<br> - Categorical Features:<br> - ChestPainType: Over 50% report ASY (asymptomatic) chest pain.<br> - RestingECG: More than 60% show normal ECG results.<br> - FastingBS: Majority have normal fasting blood sugar.<br> - ST_Slope: Most patients have a flat ST slope.<br> - Numeric Features:<br> - RestingBP: Mostly between 80–120 mmHg, right-skewed; a value of 0 is an outlier.<br> - Cholesterol: About 172 missing values (≈17%), likely unrecorded measurements.<br> - MaxHR: Roughly normal distribution, concentrated between 120–155 bpm.<br> - Oldpeak: Around 375 values are zero, few below zero, rest above 1.0.<br> 2. Bivariate Analysis<br> - Age vs HeartDisease: Probability of heart disease increases with age.<br> - MaxHR vs HeartDisease: Patients with heart disease tend to have lower maximum heart rate.<br> - Sex vs HeartDisease: Males have a higher chance of heart disease.<br> - ChestPainType vs HeartDisease: Patients with ASY chest pain have a higher risk.<br> - FastingBS vs HeartDisease: Elevated fasting blood sugar is associated with higher risk.<br> - ExerciseAngina vs HeartDisease: Presence of exercise-induced angina significantly increases risk.<br> - ST_Slope vs HeartDisease: Patients with ST slope = Up have a lower chance of heart disease. </p> <h2 id=feature-engineering-and-cleaning>Feature Engineering and Cleaning<a class=headerlink href=#feature-engineering-and-cleaning title="Permanent link">&para;</a></h2> <p>The null values in Cholesterol and RestingBP indicate missing values. </p> <div class=highlight><pre><span></span><code><span class=n>df</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=n>df</span><span class=o>.</span><span class=n>Cholesterol</span><span class=o>==</span><span class=mi>0</span><span class=p>,</span> <span class=s1>&#39;Cholesterol&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span>
<span class=n>df</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=n>df</span><span class=o>.</span><span class=n>RestingBP</span><span class=o>==</span><span class=mi>0</span><span class=p>,</span> <span class=s1>&#39;RestingBP&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span>
</code></pre></div> <h3 id=preprocessing-pipelines>Preprocessing &amp; Pipelines<a class=headerlink href=#preprocessing-pipelines title="Permanent link">&para;</a></h3> <p>Before training a machine learning model, it’s essential to address missing data and ensure features are on comparable scales. These steps improve model stability and performance.<br> 1. Handling Missing Values<br> - Mean/Median Imputation: Replace missing numeric values with the mean or median of the column. Median is often preferred for skewed distributions.<br> - Mode Imputation: For categorical variables, fill missing values with the most frequent category.<br> - Advanced Techniques: Use algorithms like KNN imputation or model-based imputation for more accurate estimates when data is not missing completely at random.<br> 2. Feature Scaling <br> - Standardization (Z-score): Transforms features to have zero mean and unit variance. Common for models like logistic regression and SVM.<br> - Min-Max Scaling: Rescales features to a fixed range (usually [0, 1]). Useful for algorithms sensitive to absolute values, such as neural networks.<br> - Robust Scaling: Uses median and interquartile range, making it less sensitive to outliers. </p> <p>A <code>Pipeline</code> in scikit-learn allows us to combine these steps into a single, reproducible workflow. It also makes the workflow modular and reusable for training, tuning, and deployment.Steps in the Pipeline:<br> 1. Imputation<br> - Numeric Features: Replace missing values with the median (robust to outliers).<br> - Categorical Features: Fill missing values with the most frequent category.<br> 2. Scaling<br> - Apply Standardization (Z-score) to numeric features so they have zero mean and unit variance.<br> - This is essential for models like logistic regression that are sensitive to feature scales.<br> 3. Encoding - Use One-Hot Encoding for categorical variables to convert them into numeric form.<br> - Set <code>handle_unknown='ignore'</code> to safely handle unseen categories during inference. </p> <div class=highlight><pre><span></span><code><span class=n>feature_cols</span> <span class=o>=</span> <span class=n>num_cols</span> <span class=o>+</span> <span class=n>cat_cols</span> <span class=o>+</span> <span class=n>binary_cols</span>
<span class=n>X</span> <span class=o>=</span> <span class=n>df</span><span class=p>[</span><span class=n>feature_cols</span><span class=p>]</span>
<span class=n>y</span> <span class=o>=</span> <span class=n>df</span><span class=p>[</span><span class=s1>&#39;HeartDisease&#39;</span><span class=p>]</span>

<span class=n>numeric_transformer</span> <span class=o>=</span> <span class=n>Pipeline</span><span class=p>(</span><span class=n>steps</span><span class=o>=</span><span class=p>[</span>
    <span class=p>(</span><span class=s1>&#39;imputer&#39;</span><span class=p>,</span> <span class=n>SimpleImputer</span><span class=p>(</span><span class=n>strategy</span><span class=o>=</span><span class=s1>&#39;median&#39;</span><span class=p>)),</span>
    <span class=p>(</span><span class=s1>&#39;scaler&#39;</span><span class=p>,</span> <span class=n>StandardScaler</span><span class=p>())</span>
<span class=p>])</span>

<span class=n>categorical_transformer</span> <span class=o>=</span> <span class=n>Pipeline</span><span class=p>(</span><span class=n>steps</span><span class=o>=</span><span class=p>[</span>
    <span class=p>(</span><span class=s1>&#39;imputer&#39;</span><span class=p>,</span> <span class=n>SimpleImputer</span><span class=p>(</span><span class=n>strategy</span><span class=o>=</span><span class=s1>&#39;most_frequent&#39;</span><span class=p>)),</span>
    <span class=p>(</span><span class=s1>&#39;onehot&#39;</span><span class=p>,</span> <span class=n>OneHotEncoder</span><span class=p>(</span><span class=n>handle_unknown</span><span class=o>=</span><span class=s1>&#39;ignore&#39;</span><span class=p>))</span>
<span class=p>])</span>

<span class=n>preprocess</span> <span class=o>=</span> <span class=n>ColumnTransformer</span><span class=p>(</span>
    <span class=n>transformers</span><span class=o>=</span><span class=p>[</span>
        <span class=p>(</span><span class=s1>&#39;num&#39;</span><span class=p>,</span> <span class=n>numeric_transformer</span><span class=p>,</span> <span class=n>num_cols</span><span class=o>+</span><span class=n>binary_cols</span><span class=p>),</span>
        <span class=p>(</span><span class=s1>&#39;cat&#39;</span><span class=p>,</span> <span class=n>categorical_transformer</span><span class=p>,</span> <span class=n>cat_cols</span><span class=p>)</span>
    <span class=p>]</span>
<span class=p>)</span>
</code></pre></div> <h3 id=trainvalidationtest-split>Train/Validation/Test split<a class=headerlink href=#trainvalidationtest-split title="Permanent link">&para;</a></h3> <p>We divide our data into two parts: training data (80%) and testing data (20%). The training set is used to fit the model, while the test set evaluates how well the model generalizes to unseen data. This helps prevent overfitting and gives us a realistic estimate of model performance. We use <strong>Stratified</strong> sampling to preserve class ratio. </p> <div class=highlight><pre><span></span><code><span class=n>X_train</span><span class=p>,</span> <span class=n>X_test</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>y_test</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span>
    <span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span> <span class=n>stratify</span><span class=o>=</span><span class=n>y</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>29</span>
<span class=p>)</span>
<span class=n>X_train</span><span class=o>.</span><span class=n>shape</span><span class=p>,</span> <span class=n>X_test</span><span class=o>.</span><span class=n>shape</span>
</code></pre></div> <div class=highlight><pre><span></span><code>((734, 11), (184, 11))
</code></pre></div> <div class=highlight><pre><span></span><code><span class=c1># Helper to get post‑preprocessing feature names</span>
<span class=k>def</span> <span class=nf>get_feature_names</span><span class=p>(</span><span class=n>ct</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>    Return feature names from a fitted ColumnTransformer `ct`.</span>
<span class=sd>    Works when the inner transformers expose `get_feature_names_out`.</span>
<span class=sd>    &quot;&quot;&quot;</span>
    <span class=n>output_features</span> <span class=o>=</span> <span class=p>[]</span>
    <span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>trans</span><span class=p>,</span> <span class=n>cols</span> <span class=ow>in</span> <span class=n>ct</span><span class=o>.</span><span class=n>transformers_</span><span class=p>:</span>
        <span class=k>if</span> <span class=n>name</span> <span class=o>==</span> <span class=s1>&#39;remainder&#39;</span> <span class=ow>and</span> <span class=n>trans</span> <span class=o>==</span> <span class=s1>&#39;drop&#39;</span><span class=p>:</span>
            <span class=k>continue</span>

        <span class=c1># Pipeline with a final step having get_feature_names_out (e.g., OneHotEncoder)</span>
        <span class=k>if</span> <span class=nb>hasattr</span><span class=p>(</span><span class=n>trans</span><span class=p>,</span> <span class=s1>&#39;named_steps&#39;</span><span class=p>)</span> <span class=ow>and</span> <span class=nb>hasattr</span><span class=p>(</span><span class=n>trans</span><span class=o>.</span><span class=n>named_steps</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;onehot&#39;</span><span class=p>,</span> <span class=kc>None</span><span class=p>),</span> <span class=s1>&#39;get_feature_names_out&#39;</span><span class=p>):</span>
            <span class=n>ohe</span> <span class=o>=</span> <span class=n>trans</span><span class=o>.</span><span class=n>named_steps</span><span class=p>[</span><span class=s1>&#39;onehot&#39;</span><span class=p>]</span>
            <span class=n>feats</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=n>ohe</span><span class=o>.</span><span class=n>get_feature_names_out</span><span class=p>(</span><span class=n>cols</span><span class=p>))</span>
            <span class=n>output_features</span><span class=o>.</span><span class=n>extend</span><span class=p>(</span><span class=n>feats</span><span class=p>)</span>
        <span class=c1># Direct transformer exposing get_feature_names_out (rare for numeric here)</span>
        <span class=k>elif</span> <span class=nb>hasattr</span><span class=p>(</span><span class=n>trans</span><span class=p>,</span> <span class=s1>&#39;get_feature_names_out&#39;</span><span class=p>):</span>
            <span class=n>feats</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=n>trans</span><span class=o>.</span><span class=n>get_feature_names_out</span><span class=p>(</span><span class=n>cols</span><span class=p>))</span>
            <span class=n>output_features</span><span class=o>.</span><span class=n>extend</span><span class=p>(</span><span class=n>feats</span><span class=p>)</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=c1># Fall back to original column names</span>
            <span class=n>output_features</span><span class=o>.</span><span class=n>extend</span><span class=p>(</span><span class=nb>list</span><span class=p>(</span><span class=n>cols</span><span class=p>))</span>

    <span class=k>return</span> <span class=n>output_features</span>


<span class=kn>from</span> <span class=nn>sklearn.metrics</span> <span class=kn>import</span> <span class=p>(</span><span class=n>accuracy_score</span><span class=p>,</span> <span class=n>precision_score</span><span class=p>,</span> <span class=n>recall_score</span><span class=p>,</span> <span class=n>f1_score</span><span class=p>,</span>
                             <span class=n>roc_auc_score</span><span class=p>,</span> <span class=n>average_precision_score</span><span class=p>,</span>
                             <span class=n>confusion_matrix</span><span class=p>,</span> <span class=n>classification_report</span><span class=p>)</span>

<span class=c1># Helper function to evaluate the model accuracy</span>
<span class=k>def</span> <span class=nf>evaluate_classifier</span><span class=p>(</span><span class=n>name</span><span class=p>,</span> <span class=n>model</span><span class=p>,</span> <span class=n>X_te</span><span class=o>=</span><span class=n>X_test</span><span class=p>,</span> <span class=n>y_te</span><span class=o>=</span><span class=n>y_test</span><span class=p>,</span> <span class=n>prob_pos</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
    <span class=n>y_pred</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_te</span><span class=p>)</span>
    <span class=n>y_pred</span> <span class=o>=</span> <span class=n>y_pred</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=nb>int</span><span class=p>)</span>
    <span class=n>y_te</span> <span class=o>=</span> <span class=n>y_test</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=nb>int</span><span class=p>)</span>
    <span class=k>if</span> <span class=n>prob_pos</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
        <span class=k>if</span> <span class=nb>hasattr</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=s1>&#39;predict_proba&#39;</span><span class=p>):</span>
            <span class=n>prob_pos</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict_proba</span><span class=p>(</span><span class=n>X_te</span><span class=p>)[:,</span><span class=mi>1</span><span class=p>]</span>
        <span class=k>elif</span> <span class=nb>hasattr</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=s1>&#39;decision_function&#39;</span><span class=p>):</span>
            <span class=n>scores</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>decision_function</span><span class=p>(</span><span class=n>X_te</span><span class=p>)</span>
            <span class=n>smin</span><span class=p>,</span> <span class=n>smax</span> <span class=o>=</span> <span class=n>scores</span><span class=o>.</span><span class=n>min</span><span class=p>(),</span> <span class=n>scores</span><span class=o>.</span><span class=n>max</span><span class=p>()</span>
            <span class=n>prob_pos</span> <span class=o>=</span> <span class=p>(</span><span class=n>scores</span> <span class=o>-</span> <span class=n>smin</span><span class=p>)</span> <span class=o>/</span> <span class=p>(</span><span class=n>smax</span> <span class=o>-</span> <span class=n>smin</span> <span class=o>+</span> <span class=mf>1e-12</span><span class=p>)</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=n>prob_pos</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros_like</span><span class=p>(</span><span class=n>y_te</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=nb>float</span><span class=p>)</span>
    <span class=n>acc</span>  <span class=o>=</span> <span class=n>accuracy_score</span><span class=p>(</span><span class=n>y_te</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>)</span>
    <span class=n>prec</span> <span class=o>=</span> <span class=n>precision_score</span><span class=p>(</span><span class=n>y_te</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>,</span> <span class=n>zero_division</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
    <span class=n>rec</span>  <span class=o>=</span> <span class=n>recall_score</span><span class=p>(</span><span class=n>y_te</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>,</span> <span class=n>zero_division</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
    <span class=n>f1</span>   <span class=o>=</span> <span class=n>f1_score</span><span class=p>(</span><span class=n>y_te</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>,</span> <span class=n>zero_division</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
    <span class=k>try</span><span class=p>:</span>
        <span class=n>roc</span>  <span class=o>=</span> <span class=n>roc_auc_score</span><span class=p>(</span><span class=n>y_te</span><span class=p>,</span> <span class=n>prob_pos</span><span class=p>)</span>
    <span class=k>except</span> <span class=ne>Exception</span><span class=p>:</span>
        <span class=n>roc</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>nan</span>
    <span class=n>pr_auc</span> <span class=o>=</span> <span class=n>average_precision_score</span><span class=p>(</span><span class=n>y_te</span><span class=p>,</span> <span class=n>prob_pos</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;=== </span><span class=si>{</span><span class=n>name</span><span class=si>}</span><span class=s2> ===&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Accuracy: </span><span class=si>{</span><span class=n>acc</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=se>\n</span><span class=s2>Precision: </span><span class=si>{</span><span class=n>prec</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=se>\n</span><span class=s2>Recall: </span><span class=si>{</span><span class=n>rec</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=se>\n</span><span class=s2>F1: </span><span class=si>{</span><span class=n>f1</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;ROC-AUC: </span><span class=si>{</span><span class=n>roc</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=se>\n</span><span class=s2>PR-AUC: </span><span class=si>{</span><span class=n>pr_auc</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Confusion matrix:</span><span class=se>\n</span><span class=s2>&quot;</span><span class=p>,</span> <span class=n>confusion_matrix</span><span class=p>(</span><span class=n>y_te</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>))</span>
    <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Classification report:</span><span class=se>\n</span><span class=s2>&quot;</span><span class=p>,</span> <span class=n>classification_report</span><span class=p>(</span><span class=n>y_te</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>,</span> <span class=n>zero_division</span><span class=o>=</span><span class=mi>0</span><span class=p>))</span>
    <span class=k>return</span> <span class=nb>dict</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=n>name</span><span class=p>,</span> <span class=n>accuracy</span><span class=o>=</span><span class=n>acc</span><span class=p>,</span> <span class=n>precision</span><span class=o>=</span><span class=n>prec</span><span class=p>,</span> <span class=n>recall</span><span class=o>=</span><span class=n>rec</span><span class=p>,</span> <span class=n>f1</span><span class=o>=</span><span class=n>f1</span><span class=p>,</span> <span class=n>roc_auc</span><span class=o>=</span><span class=n>roc</span><span class=p>,</span> <span class=n>pr_auc</span><span class=o>=</span><span class=n>pr_auc</span><span class=p>)</span>
</code></pre></div> <h2 id=baseline-model>Baseline model<a class=headerlink href=#baseline-model title="Permanent link">&para;</a></h2> <p>A baseline model is a simple reference point used to evaluate whether a more complex model adds real predictive value. For classification tasks, this often means using a Dummy Classifier that predicts the majority class or random guesses based on class distribution. It doesn’t use any features, but sets a minimum performance benchmark, helping us understand if our logistic regression model truly improves upon naive predictions. </p> <div class=highlight><pre><span></span><code><span class=n>baseline</span> <span class=o>=</span> <span class=n>Pipeline</span><span class=p>(</span><span class=n>steps</span><span class=o>=</span><span class=p>[(</span><span class=s1>&#39;prep&#39;</span><span class=p>,</span> <span class=n>preprocess</span><span class=p>),</span> <span class=p>(</span><span class=s1>&#39;mdl&#39;</span><span class=p>,</span> <span class=n>DummyClassifier</span><span class=p>(</span><span class=n>strategy</span><span class=o>=</span><span class=s1>&#39;most_frequent&#39;</span><span class=p>))])</span>
<span class=n>baseline</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
<span class=n>yp</span> <span class=o>=</span> <span class=n>baseline</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
<span class=n>yp_prob</span> <span class=o>=</span> <span class=n>baseline</span><span class=o>.</span><span class=n>predict_proba</span><span class=p>(</span><span class=n>X_test</span><span class=p>)[:,</span><span class=mi>1</span><span class=p>]</span>
</code></pre></div> <h2 id=key-classification-metrics>Key Classification Metrics<a class=headerlink href=#key-classification-metrics title="Permanent link">&para;</a></h2> <ol> <li>Accuracy <ul> <li>Proportion of correct predictions: </li> <li> <div class=arithmatex>\[\text{Accuracy} = \frac{\text{TP + TN}}{\text{Total Samples}}\]</div> </li> <li>Simple but can be misleading if classes are imbalanced. </li> </ul> </li> <li>Precision <ul> <li>Of all predicted positives, how many are actually positive: </li> <li> <div class=arithmatex>\[\text{Precision} = \frac{\text{TP}}{\text{TP + FP}}\]</div> </li> </ul> </li> <li>Recall (Sensitivity) <ul> <li>Of all actual positives, how many did we correctly predict: </li> <li> <div class=arithmatex>\[\text{Recall} = \frac{\text{TP}}{\text{TP + FN}}\]</div> </li> </ul> </li> <li>F1 Score <ul> <li>Harmonic mean of precision and recall: </li> <li> <div class=arithmatex>\[ F1 = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}\]</div> </li> </ul> </li> <li>ROC-AUC <ul> <li>Measures ranking quality across thresholds; higher is better. </li> </ul> </li> </ol> <div class=highlight><pre><span></span><code><span class=c1># Get the accuracy metrics</span>
<span class=n>lr_metrics</span> <span class=o>=</span> <span class=n>evaluate_classifier</span><span class=p>(</span><span class=s2>&quot;baseline model&quot;</span><span class=p>,</span> <span class=n>baseline</span><span class=p>,</span> <span class=n>X_test</span><span class=p>,</span> <span class=n>y_test</span><span class=p>)</span>
<span class=n>preprocess</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>

<span class=c1># Get the feature names</span>
<span class=n>final_feature_names</span> <span class=o>=</span> <span class=n>get_feature_names</span><span class=p>(</span><span class=n>preprocess</span><span class=p>)</span>
<span class=n>final_feature_names</span>
</code></pre></div> <div class=highlight><pre><span></span><code>=== baseline model ===
Accuracy: 0.554
Precision: 0.554
Recall: 1.000
F1: 0.713
ROC-AUC: 0.500
PR-AUC: 0.554
Confusion matrix:
 [[  0  82]
 [  0 102]]
Classification report:
               precision    recall  f1-score   support

           0       0.00      0.00      0.00        82
           1       0.55      1.00      0.71       102

    accuracy                           0.55       184
   macro avg       0.28      0.50      0.36       184
weighted avg       0.31      0.55      0.40       184






[&#39;Age&#39;,
 &#39;RestingBP&#39;,
 &#39;Cholesterol&#39;,
 &#39;MaxHR&#39;,
 &#39;Oldpeak&#39;,
 &#39;FastingBS&#39;,
 &#39;Sex_F&#39;,
 &#39;Sex_M&#39;,
 &#39;ChestPainType_ASY&#39;,
 &#39;ChestPainType_ATA&#39;,
 &#39;ChestPainType_NAP&#39;,
 &#39;ChestPainType_TA&#39;,
 &#39;RestingECG_LVH&#39;,
 &#39;RestingECG_Normal&#39;,
 &#39;RestingECG_ST&#39;,
 &#39;ExerciseAngina_N&#39;,
 &#39;ExerciseAngina_Y&#39;,
 &#39;ST_Slope_Down&#39;,
 &#39;ST_Slope_Flat&#39;,
 &#39;ST_Slope_Up&#39;]
</code></pre></div> <div class=highlight><pre><span></span><code><span class=n>y_test_int</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>asarray</span><span class=p>(</span><span class=n>y_test</span><span class=p>)</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=nb>int</span><span class=p>)</span>
<span class=n>yp_int</span>     <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>asarray</span><span class=p>(</span><span class=n>yp</span><span class=p>)</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=nb>int</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Baseline accuracy:&#39;</span><span class=p>,</span> <span class=n>accuracy_score</span><span class=p>(</span><span class=n>y_test_int</span><span class=p>,</span> <span class=n>yp_int</span><span class=p>))</span>
<span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Baseline F1:&#39;</span><span class=p>,</span> <span class=n>f1_score</span><span class=p>(</span><span class=n>y_test_int</span><span class=p>,</span> <span class=n>yp_int</span><span class=p>,</span> <span class=n>zero_division</span><span class=o>=</span><span class=mi>0</span><span class=p>))</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Precision:&quot;</span><span class=p>,</span> <span class=n>precision_score</span><span class=p>(</span><span class=n>y_test_int</span><span class=p>,</span> <span class=n>yp_int</span><span class=p>,</span> <span class=n>pos_label</span><span class=o>=</span><span class=mi>1</span><span class=p>))</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Recall:&quot;</span><span class=p>,</span> <span class=n>recall_score</span><span class=p>(</span><span class=n>y_test_int</span><span class=p>,</span> <span class=n>yp_int</span><span class=p>,</span> <span class=n>pos_label</span><span class=o>=</span><span class=mi>1</span><span class=p>))</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;F1 Score:&quot;</span><span class=p>,</span> <span class=n>f1_score</span><span class=p>(</span><span class=n>y_test_int</span><span class=p>,</span> <span class=n>yp_int</span><span class=p>,</span> <span class=n>pos_label</span><span class=o>=</span><span class=mi>1</span><span class=p>))</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;ROC-AUC:&quot;</span><span class=p>,</span> <span class=n>roc_auc_score</span><span class=p>(</span><span class=n>y_test_int</span><span class=p>,</span> <span class=n>yp_prob</span><span class=p>))</span>
</code></pre></div> <div class=highlight><pre><span></span><code>Baseline accuracy: 0.5543478260869565
Baseline F1: 0.7132867132867133
Precision: 0.5543478260869565
Recall: 1.0
F1 Score: 0.7132867132867133
ROC-AUC: 0.5
</code></pre></div> <h2 id=logistic-regression>Logistic Regression<a class=headerlink href=#logistic-regression title="Permanent link">&para;</a></h2> <p>Logistic Regression is a generalized linear model used for binary classification. It models the probability of the positive class as:<br> $$ P(y=1|x) = \sigma(w^T x + b), \quad \text{where } \sigma(z) = \frac{1}{1 + e^{-z}}$$ Training is done via maximum likelihood estimation, minimizing log-loss. Coefficients represent log-odds, and exponentiating them gives odds ratios. Regularization options include L2 (ridge), L1 (lasso) for sparsity, and Elastic-Net for a mix. </p> <p><strong>Key Assumptions</strong><br> 1. Correct Model Specification: The log-odds of the outcome are a linear combination of predictors.<br> 2. Independence of Observations: Each observation is independent of others.<br> 3. Limited Multicollinearity: Predictors should not be highly correlated.<br> 4. Sufficient Events per Variable: Enough positive cases relative to the number of predictors to avoid overfitting.<br> 5. No Perfect Separation: Predictors should not perfectly predict the outcome (can cause convergence issues).<br> 6. Linearity in the Logit for Numeric Predictors: Continuous variables should have a linear relationship with the log-odds (often checked via transformations or splines). </p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>sklearn.linear_model</span> <span class=kn>import</span> <span class=n>LogisticRegression</span>

<span class=n>logreg</span> <span class=o>=</span> <span class=n>Pipeline</span><span class=p>(</span><span class=n>steps</span><span class=o>=</span><span class=p>[(</span><span class=s1>&#39;prep&#39;</span><span class=p>,</span> <span class=n>preprocess</span><span class=p>),</span>
                        <span class=p>(</span><span class=s1>&#39;clf&#39;</span><span class=p>,</span>  <span class=n>LogisticRegression</span><span class=p>(</span><span class=n>max_iter</span><span class=o>=</span><span class=mi>1000</span><span class=p>,</span> <span class=n>solver</span><span class=o>=</span><span class=s1>&#39;lbfgs&#39;</span><span class=p>,</span> <span class=n>C</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>))])</span>
<span class=n>logreg</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
<span class=n>lr_metrics</span> <span class=o>=</span> <span class=n>evaluate_classifier</span><span class=p>(</span><span class=s2>&quot;Logistic Regression&quot;</span><span class=p>,</span> <span class=n>logreg</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>=== Logistic Regression ===
Accuracy: 0.842
Precision: 0.861
Recall: 0.853
F1: 0.857
ROC-AUC: 0.909
PR-AUC: 0.923
Confusion matrix:
 [[68 14]
 [15 87]]
Classification report:
               precision    recall  f1-score   support

           0       0.82      0.83      0.82        82
           1       0.86      0.85      0.86       102

    accuracy                           0.84       184
   macro avg       0.84      0.84      0.84       184
weighted avg       0.84      0.84      0.84       184
</code></pre></div> <p>The accuracy is 84% suggesting a better fit to the model when compared to the baseline model. The precision and recall have also improved. To explain the logistic regression result, we can look at the slopes of the variables as the odds ratios. </p> <div class=highlight><pre><span></span><code><span class=n>param_grid_lr</span> <span class=o>=</span> <span class=p>[</span>
    <span class=p>{</span><span class=c1># L2 with lbfgs/newton-cg/sag/saga</span>
     <span class=s1>&#39;clf__solver&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;lbfgs&#39;</span><span class=p>,</span><span class=s1>&#39;newton-cg&#39;</span><span class=p>,</span><span class=s1>&#39;sag&#39;</span><span class=p>,</span><span class=s1>&#39;saga&#39;</span><span class=p>],</span>
     <span class=s1>&#39;clf__penalty&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;l2&#39;</span><span class=p>],</span>
     <span class=s1>&#39;clf__C&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mf>0.01</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>,</span> <span class=mf>10.0</span><span class=p>],</span>
     <span class=s1>&#39;clf__class_weight&#39;</span><span class=p>:</span> <span class=p>[</span><span class=kc>None</span><span class=p>,</span> <span class=s1>&#39;balanced&#39;</span><span class=p>]</span>
    <span class=p>},</span>
    <span class=p>{</span><span class=c1># L1 with liblinear or saga</span>
     <span class=s1>&#39;clf__solver&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;liblinear&#39;</span><span class=p>,</span><span class=s1>&#39;saga&#39;</span><span class=p>],</span>
     <span class=s1>&#39;clf__penalty&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;l1&#39;</span><span class=p>],</span>
     <span class=s1>&#39;clf__C&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mf>0.01</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>,</span> <span class=mf>10.0</span><span class=p>],</span>
     <span class=s1>&#39;clf__class_weight&#39;</span><span class=p>:</span> <span class=p>[</span><span class=kc>None</span><span class=p>,</span> <span class=s1>&#39;balanced&#39;</span><span class=p>]</span>
    <span class=p>},</span>
    <span class=p>{</span><span class=c1># Elastic-Net with saga</span>
     <span class=s1>&#39;clf__solver&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;saga&#39;</span><span class=p>],</span>
     <span class=s1>&#39;clf__penalty&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;elasticnet&#39;</span><span class=p>],</span>
     <span class=s1>&#39;clf__l1_ratio&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mf>0.2</span><span class=p>,</span> <span class=mf>0.5</span><span class=p>,</span> <span class=mf>0.8</span><span class=p>],</span>
     <span class=s1>&#39;clf__C&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mf>0.01</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>,</span> <span class=mf>10.0</span><span class=p>],</span>
     <span class=s1>&#39;clf__class_weight&#39;</span><span class=p>:</span> <span class=p>[</span><span class=kc>None</span><span class=p>,</span> <span class=s1>&#39;balanced&#39;</span><span class=p>]</span>
    <span class=p>}</span>
<span class=p>]</span>
<span class=n>base_lr</span> <span class=o>=</span> <span class=n>Pipeline</span><span class=p>(</span><span class=n>steps</span><span class=o>=</span><span class=p>[</span>
    <span class=p>(</span><span class=s1>&#39;prep&#39;</span><span class=p>,</span> <span class=n>preprocess</span><span class=p>),</span>
    <span class=p>(</span><span class=s1>&#39;clf&#39;</span><span class=p>,</span> <span class=n>LogisticRegression</span><span class=p>())</span>
<span class=p>])</span>
<span class=n>cv</span> <span class=o>=</span> <span class=n>StratifiedKFold</span><span class=p>(</span><span class=n>n_splits</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>29</span><span class=p>)</span>
<span class=n>logreg</span> <span class=o>=</span> <span class=n>GridSearchCV</span><span class=p>(</span><span class=n>base_lr</span><span class=p>,</span> <span class=n>param_grid</span><span class=o>=</span><span class=n>param_grid_lr</span><span class=p>,</span> <span class=n>cv</span><span class=o>=</span><span class=n>cv</span><span class=p>,</span> <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;roc_auc&#39;</span><span class=p>,</span> <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>,</span> <span class=n>refit</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>verbose</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
<span class=n>logreg</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Best AUC (CV):&#39;</span><span class=p>,</span> <span class=n>logreg</span><span class=o>.</span><span class=n>best_score_</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Best params:&#39;</span><span class=p>,</span> <span class=n>logreg</span><span class=o>.</span><span class=n>best_params_</span><span class=p>)</span>

<span class=n>lr_metrics</span> <span class=o>=</span> <span class=n>evaluate_classifier</span><span class=p>(</span><span class=s2>&quot;Logistic Regression (with hyper parameter tuning)&quot;</span><span class=p>,</span> <span class=n>logreg</span><span class=o>.</span><span class=n>best_estimator_</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>Fitting 5 folds for each of 72 candidates, totalling 360 fits
Best AUC (CV): 0.9280405051136758
Best params: {&#39;clf__C&#39;: 0.1, &#39;clf__class_weight&#39;: &#39;balanced&#39;, &#39;clf__l1_ratio&#39;: 0.5, &#39;clf__penalty&#39;: &#39;elasticnet&#39;, &#39;clf__solver&#39;: &#39;saga&#39;}
=== Logistic Regression (with hyper parameter tuning) ===
Accuracy: 0.842
Precision: 0.869
Recall: 0.843
F1: 0.856
ROC-AUC: 0.909
PR-AUC: 0.924
Confusion matrix:
 [[69 13]
 [16 86]]
Classification report:
               precision    recall  f1-score   support

           0       0.81      0.84      0.83        82
           1       0.87      0.84      0.86       102

    accuracy                           0.84       184
   macro avg       0.84      0.84      0.84       184
weighted avg       0.84      0.84      0.84       184
</code></pre></div> <div class=highlight><pre><span></span><code><span class=n>df</span>
</code></pre></div> <div> <style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style> <table border=1 class=dataframe> <thead> <tr style="text-align: right;"> <th></th> <th>Age</th> <th>Sex</th> <th>ChestPainType</th> <th>RestingBP</th> <th>Cholesterol</th> <th>FastingBS</th> <th>RestingECG</th> <th>MaxHR</th> <th>ExerciseAngina</th> <th>Oldpeak</th> <th>ST_Slope</th> <th>HeartDisease</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>40</td> <td>M</td> <td>ATA</td> <td>140.0</td> <td>289.0</td> <td>0</td> <td>Normal</td> <td>172</td> <td>N</td> <td>0.0</td> <td>Up</td> <td>0</td> </tr> <tr> <th>1</th> <td>49</td> <td>F</td> <td>NAP</td> <td>160.0</td> <td>180.0</td> <td>0</td> <td>Normal</td> <td>156</td> <td>N</td> <td>1.0</td> <td>Flat</td> <td>1</td> </tr> <tr> <th>2</th> <td>37</td> <td>M</td> <td>ATA</td> <td>130.0</td> <td>283.0</td> <td>0</td> <td>ST</td> <td>98</td> <td>N</td> <td>0.0</td> <td>Up</td> <td>0</td> </tr> <tr> <th>3</th> <td>48</td> <td>F</td> <td>ASY</td> <td>138.0</td> <td>214.0</td> <td>0</td> <td>Normal</td> <td>108</td> <td>Y</td> <td>1.5</td> <td>Flat</td> <td>1</td> </tr> <tr> <th>4</th> <td>54</td> <td>M</td> <td>NAP</td> <td>150.0</td> <td>195.0</td> <td>0</td> <td>Normal</td> <td>122</td> <td>N</td> <td>0.0</td> <td>Up</td> <td>0</td> </tr> <tr> <th>...</th> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> </tr> <tr> <th>913</th> <td>45</td> <td>M</td> <td>TA</td> <td>110.0</td> <td>264.0</td> <td>0</td> <td>Normal</td> <td>132</td> <td>N</td> <td>1.2</td> <td>Flat</td> <td>1</td> </tr> <tr> <th>914</th> <td>68</td> <td>M</td> <td>ASY</td> <td>144.0</td> <td>193.0</td> <td>1</td> <td>Normal</td> <td>141</td> <td>N</td> <td>3.4</td> <td>Flat</td> <td>1</td> </tr> <tr> <th>915</th> <td>57</td> <td>M</td> <td>ASY</td> <td>130.0</td> <td>131.0</td> <td>0</td> <td>Normal</td> <td>115</td> <td>Y</td> <td>1.2</td> <td>Flat</td> <td>1</td> </tr> <tr> <th>916</th> <td>57</td> <td>F</td> <td>ATA</td> <td>130.0</td> <td>236.0</td> <td>0</td> <td>LVH</td> <td>174</td> <td>N</td> <td>0.0</td> <td>Flat</td> <td>1</td> </tr> <tr> <th>917</th> <td>38</td> <td>M</td> <td>NAP</td> <td>138.0</td> <td>175.0</td> <td>0</td> <td>Normal</td> <td>173</td> <td>N</td> <td>0.0</td> <td>Up</td> <td>0</td> </tr> </tbody> </table> <p>918 rows × 12 columns</p> </div> <div class=highlight><pre><span></span><code><span class=c1># Build formula: categorical vars wrapped in C()</span>

<span class=n>formula</span> <span class=o>=</span> <span class=p>(</span>
    <span class=s1>&#39;HeartDisease ~ Age + RestingBP + Cholesterol + MaxHR + Oldpeak + FastingBS &#39;</span>
    <span class=s1>&#39;+ C(Sex) + C(ChestPainType) + C(RestingECG) + C(ExerciseAngina) + C(ST_Slope)&#39;</span>
<span class=p>)</span>
<span class=n>df</span><span class=p>[</span><span class=s1>&#39;HeartDisease&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>HeartDisease</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=nb>int</span><span class=p>)</span>
<span class=n>sm_model</span> <span class=o>=</span> <span class=n>smf</span><span class=o>.</span><span class=n>logit</span><span class=p>(</span><span class=n>formula</span><span class=o>=</span><span class=n>formula</span><span class=p>,</span> <span class=n>data</span><span class=o>=</span><span class=n>df</span><span class=o>.</span><span class=n>dropna</span><span class=p>())</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>disp</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
<span class=n>sm_model</span><span class=o>.</span><span class=n>summary</span><span class=p>()</span>
</code></pre></div> <table class=simpletable> <caption>Logit Regression Results</caption> <tr> <th>Dep. Variable:</th> <td>HeartDisease</td> <th> No. Observations: </th> <td> 746</td> </tr> <tr> <th>Model:</th> <td>Logit</td> <th> Df Residuals: </th> <td> 730</td> </tr> <tr> <th>Method:</th> <td>MLE</td> <th> Df Model: </th> <td> 15</td> </tr> <tr> <th>Date:</th> <td>Tue, 28 Oct 2025</td> <th> Pseudo R-squ.: </th> <td>0.5317</td> </tr> <tr> <th>Time:</th> <td>14:12:34</td> <th> Log-Likelihood: </th> <td> -241.79</td> </tr> <tr> <th>converged:</th> <td>True</td> <th> LL-Null: </th> <td> -516.31</td> </tr> <tr> <th>Covariance Type:</th> <td>nonrobust</td> <th> LLR p-value: </th> <td>2.319e-107</td> </tr> </table> <table class=simpletable> <tr> <td></td> <th>coef</th> <th>std err</th> <th>z</th> <th>P>|z|</th> <th>[0.025</th> <th>0.975]</th> </tr> <tr> <th>Intercept</th> <td> -5.4373</td> <td> 1.763</td> <td> -3.085</td> <td> 0.002</td> <td> -8.892</td> <td> -1.983</td> </tr> <tr> <th>FastingBS[T.1]</th> <td> 0.2924</td> <td> 0.331</td> <td> 0.883</td> <td> 0.377</td> <td> -0.357</td> <td> 0.941</td> </tr> <tr> <th>C(Sex)[T.M]</th> <td> 1.8655</td> <td> 0.313</td> <td> 5.952</td> <td> 0.000</td> <td> 1.251</td> <td> 2.480</td> </tr> <tr> <th>C(ChestPainType)[T.ATA]</th> <td> -1.6732</td> <td> 0.354</td> <td> -4.721</td> <td> 0.000</td> <td> -2.368</td> <td> -0.979</td> </tr> <tr> <th>C(ChestPainType)[T.NAP]</th> <td> -1.5730</td> <td> 0.303</td> <td> -5.192</td> <td> 0.000</td> <td> -2.167</td> <td> -0.979</td> </tr> <tr> <th>C(ChestPainType)[T.TA]</th> <td> -1.6333</td> <td> 0.484</td> <td> -3.376</td> <td> 0.001</td> <td> -2.582</td> <td> -0.685</td> </tr> <tr> <th>C(RestingECG)[T.Normal]</th> <td> -0.2298</td> <td> 0.284</td> <td> -0.809</td> <td> 0.419</td> <td> -0.787</td> <td> 0.327</td> </tr> <tr> <th>C(RestingECG)[T.ST]</th> <td> -0.1746</td> <td> 0.394</td> <td> -0.443</td> <td> 0.658</td> <td> -0.947</td> <td> 0.598</td> </tr> <tr> <th>C(ExerciseAngina)[T.Y]</th> <td> 0.9074</td> <td> 0.267</td> <td> 3.397</td> <td> 0.001</td> <td> 0.384</td> <td> 1.431</td> </tr> <tr> <th>C(ST_Slope)[T.Flat]</th> <td> 1.3038</td> <td> 0.520</td> <td> 2.509</td> <td> 0.012</td> <td> 0.285</td> <td> 2.323</td> </tr> <tr> <th>C(ST_Slope)[T.Up]</th> <td> -1.2100</td> <td> 0.566</td> <td> -2.140</td> <td> 0.032</td> <td> -2.318</td> <td> -0.102</td> </tr> <tr> <th>Age</th> <td> 0.0314</td> <td> 0.015</td> <td> 2.119</td> <td> 0.034</td> <td> 0.002</td> <td> 0.060</td> </tr> <tr> <th>RestingBP</th> <td> 0.0118</td> <td> 0.007</td> <td> 1.614</td> <td> 0.107</td> <td> -0.003</td> <td> 0.026</td> </tr> <tr> <th>Cholesterol</th> <td> 0.0025</td> <td> 0.002</td> <td> 1.262</td> <td> 0.207</td> <td> -0.001</td> <td> 0.006</td> </tr> <tr> <th>MaxHR</th> <td> 0.0006</td> <td> 0.006</td> <td> 0.100</td> <td> 0.920</td> <td> -0.011</td> <td> 0.012</td> </tr> <tr> <th>Oldpeak</th> <td> 0.4108</td> <td> 0.141</td> <td> 2.921</td> <td> 0.003</td> <td> 0.135</td> <td> 0.687</td> </tr> </table> <div class=highlight><pre><span></span><code><span class=c1># Coefficients -&gt; odds ratios</span>
<span class=n>coefs</span> <span class=o>=</span> <span class=n>logreg</span><span class=o>.</span><span class=n>best_estimator_</span><span class=o>.</span><span class=n>named_steps</span><span class=p>[</span><span class=s1>&#39;clf&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>coef_</span><span class=o>.</span><span class=n>ravel</span><span class=p>()</span>
<span class=n>odds</span>  <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=n>coefs</span><span class=p>)</span>
<span class=n>coef_df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>({</span><span class=s1>&#39;feature&#39;</span><span class=p>:</span> <span class=n>final_feature_names</span><span class=p>,</span> <span class=s1>&#39;coef&#39;</span><span class=p>:</span> <span class=n>coefs</span><span class=p>,</span> <span class=s1>&#39;odds_ratio&#39;</span><span class=p>:</span> <span class=n>odds</span><span class=p>})</span>
<span class=n>coef_df</span> <span class=o>=</span> <span class=n>coef_df</span><span class=o>.</span><span class=n>sort_values</span><span class=p>(</span><span class=s1>&#39;odds_ratio&#39;</span><span class=p>,</span> <span class=n>ascending</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Top risk‑increasing features (odds ratio &gt; 1):&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>coef_df</span><span class=o>.</span><span class=n>head</span><span class=p>(</span><span class=mi>10</span><span class=p>)</span><span class=o>.</span><span class=n>round</span><span class=p>(</span><span class=mi>3</span><span class=p>))</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Protective features (lowest odds ratios):&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>coef_df</span><span class=o>.</span><span class=n>tail</span><span class=p>(</span><span class=mi>10</span><span class=p>)</span><span class=o>.</span><span class=n>round</span><span class=p>(</span><span class=mi>3</span><span class=p>))</span>

<span class=c1># Plain‑English explanation</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Plain‑English explanation (Logistic Regression):&quot;</span><span class=p>)</span>
<span class=k>for</span> <span class=n>_</span><span class=p>,</span> <span class=n>r</span> <span class=ow>in</span> <span class=n>coef_df</span><span class=o>.</span><span class=n>head</span><span class=p>(</span><span class=mi>3</span><span class=p>)</span><span class=o>.</span><span class=n>iterrows</span><span class=p>():</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;• Higher &#39;</span><span class=si>{</span><span class=n>r</span><span class=p>[</span><span class=s1>&#39;feature&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&#39; increases the odds of heart disease by ~</span><span class=si>{</span><span class=n>r</span><span class=p>[</span><span class=s1>&#39;odds_ratio&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>× (holding others constant).&quot;</span><span class=p>)</span>
<span class=k>for</span> <span class=n>_</span><span class=p>,</span> <span class=n>r</span> <span class=ow>in</span> <span class=n>coef_df</span><span class=o>.</span><span class=n>tail</span><span class=p>(</span><span class=mi>3</span><span class=p>)</span><span class=o>.</span><span class=n>sort_values</span><span class=p>(</span><span class=s1>&#39;odds_ratio&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>iterrows</span><span class=p>():</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;• Higher &#39;</span><span class=si>{</span><span class=n>r</span><span class=p>[</span><span class=s1>&#39;feature&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&#39; is associated with ~</span><span class=si>{</span><span class=n>r</span><span class=p>[</span><span class=s1>&#39;odds_ratio&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>× odds (lower than baseline), suggesting protection.&quot;</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>Top risk‑increasing features (odds ratio &gt; 1):
              feature   coef  odds_ratio
8   ChestPainType_ASY  1.120       3.064
18      ST_Slope_Flat  1.027       2.794
5           FastingBS  0.505       1.656
7               Sex_M  0.484       1.622
4             Oldpeak  0.422       1.524
16   ExerciseAngina_Y  0.310       1.364
0                 Age  0.158       1.171
12     RestingECG_LVH  0.000       1.000
17      ST_Slope_Down  0.000       1.000
14      RestingECG_ST  0.000       1.000
Protective features (lowest odds ratios):
              feature   coef  odds_ratio
13  RestingECG_Normal  0.000       1.000
10  ChestPainType_NAP  0.000       1.000
11   ChestPainType_TA  0.000       1.000
1           RestingBP  0.000       1.000
2         Cholesterol  0.000       1.000
9   ChestPainType_ATA -0.162       0.850
3               MaxHR -0.261       0.770
15   ExerciseAngina_N -0.314       0.731
6               Sex_F -0.487       0.615
19        ST_Slope_Up -0.746       0.474
Plain‑English explanation (Logistic Regression):
• Higher &#39;ChestPainType_ASY&#39; increases the odds of heart disease by ~3.06× (holding others constant).
• Higher &#39;ST_Slope_Flat&#39; increases the odds of heart disease by ~2.79× (holding others constant).
• Higher &#39;FastingBS&#39; increases the odds of heart disease by ~1.66× (holding others constant).
• Higher &#39;ST_Slope_Up&#39; is associated with ~0.47× odds (lower than baseline), suggesting protection.
• Higher &#39;Sex_F&#39; is associated with ~0.61× odds (lower than baseline), suggesting protection.
• Higher &#39;ExerciseAngina_N&#39; is associated with ~0.73× odds (lower than baseline), suggesting protection.
</code></pre></div> <div class=highlight><pre><span></span><code><span class=c1># Plot top positive and negative effects</span>
<span class=n>topN</span> <span class=o>=</span> <span class=mi>15</span>
<span class=n>sdf</span> <span class=o>=</span> <span class=n>coef_df</span><span class=o>.</span><span class=n>iloc</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>r_</span><span class=p>[</span><span class=n>coef_df</span><span class=p>[</span><span class=s1>&#39;coef&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>nlargest</span><span class=p>(</span><span class=n>topN</span><span class=p>)</span><span class=o>.</span><span class=n>index</span><span class=p>,</span> <span class=n>coef_df</span><span class=p>[</span><span class=s1>&#39;coef&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>nsmallest</span><span class=p>(</span><span class=n>topN</span><span class=p>)</span><span class=o>.</span><span class=n>index</span><span class=p>]]</span><span class=o>.</span>\
    <span class=n>sort_values</span><span class=p>(</span><span class=s1>&#39;odds_ratio&#39;</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>8</span><span class=p>,</span><span class=mi>10</span><span class=p>))</span>
<span class=n>sns</span><span class=o>.</span><span class=n>barplot</span><span class=p>(</span><span class=n>y</span><span class=o>=</span><span class=s1>&#39;feature&#39;</span><span class=p>,</span> <span class=n>x</span><span class=o>=</span><span class=s1>&#39;coef&#39;</span><span class=p>,</span> <span class=n>data</span><span class=o>=</span><span class=n>sdf</span><span class=p>,</span> <span class=n>palette</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;green&#39;</span> <span class=k>if</span> <span class=n>v</span><span class=o>&lt;</span><span class=mi>0</span> <span class=k>else</span> <span class=s1>&#39;red&#39;</span> <span class=k>for</span> <span class=n>v</span> <span class=ow>in</span> <span class=n>sdf</span><span class=p>[</span><span class=s1>&#39;coef&#39;</span><span class=p>]])</span>
<span class=n>plt</span><span class=o>.</span><span class=n>axvline</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;k&#39;</span><span class=p>,</span> <span class=n>lw</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Top +/- coefficients (log-odds)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <p><img alt=png src=output_31_0.png></p> <h2 id=decision-tree-shallow-rule-based>Decision Tree (Shallow, Rule-Based)<a class=headerlink href=#decision-tree-shallow-rule-based title="Permanent link">&para;</a></h2> <p>Decision Trees are intuitive models that split data based on feature thresholds, forming a set of "if-then" rules. In clinical settings, shallow trees (limited depth) are preferred for their simplicity and interpretability. </p> <p>This section trains a decision tree with depth=3 and evaluates its performance. The tree structure is visualized, and human-readable rules are extracted to support clinical decision-making. </p> <p><strong>Assumptions &amp; notes</strong>: This model is non‑parametric, meaning that the tree structure cannot be recreated solely from optimal metrics. Explainability improves when the tree is shallow (limited max_depth, larger min_samples_leaf). Post‑training, we can prune using cost‑complexity pruning (ccp_alpha) to remove weak branches and keep the ruleset compact. </p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>sklearn.tree</span> <span class=kn>import</span> <span class=n>DecisionTreeClassifier</span><span class=p>,</span> <span class=n>export_text</span><span class=p>,</span> <span class=n>plot_tree</span>

<span class=n>tree_shallow</span> <span class=o>=</span> <span class=n>Pipeline</span><span class=p>(</span><span class=n>steps</span><span class=o>=</span><span class=p>[(</span><span class=s1>&#39;prep&#39;</span><span class=p>,</span> <span class=n>preprocess</span><span class=p>),</span>
                              <span class=p>(</span><span class=s1>&#39;clf&#39;</span><span class=p>,</span>  <span class=n>DecisionTreeClassifier</span><span class=p>(</span><span class=n>max_depth</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>min_samples_leaf</span><span class=o>=</span><span class=mi>30</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>))])</span>
<span class=n>tree_shallow</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
<span class=n>dt_metrics</span> <span class=o>=</span> <span class=n>evaluate_classifier</span><span class=p>(</span><span class=s2>&quot;Decision Tree (depth=3)&quot;</span><span class=p>,</span> <span class=n>tree_shallow</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>=== Decision Tree (depth=3) ===
Accuracy: 0.821
Precision: 0.871
Recall: 0.794
F1: 0.831
ROC-AUC: 0.897
PR-AUC: 0.891
Confusion matrix:
 [[70 12]
 [21 81]]
Classification report:
               precision    recall  f1-score   support

           0       0.77      0.85      0.81        82
           1       0.87      0.79      0.83       102

    accuracy                           0.82       184
   macro avg       0.82      0.82      0.82       184
weighted avg       0.83      0.82      0.82       184
</code></pre></div> <p>Optimising the parameters using grid search and cross validation.</p> <div class=highlight><pre><span></span><code><span class=n>param_grid_dt</span> <span class=o>=</span> <span class=p>[{</span>
    <span class=s1>&#39;clf__criterion&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;gini&#39;</span><span class=p>,</span> <span class=s1>&#39;entropy&#39;</span><span class=p>,</span> <span class=s1>&#39;log_loss&#39;</span><span class=p>],</span>  <span class=c1># splitting criteria</span>
    <span class=s1>&#39;clf__splitter&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;best&#39;</span><span class=p>,</span> <span class=s1>&#39;random&#39;</span><span class=p>],</span>

    <span class=c1># keep trees shallow/compact for rules clinicians can use</span>
    <span class=s1>&#39;clf__max_depth&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span>
    <span class=s1>&#39;clf__min_samples_split&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span>
    <span class=s1>&#39;clf__min_samples_leaf&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span>

    <span class=c1># feature sampling can help generalization; None is simplest</span>
    <span class=s1>&#39;clf__max_features&#39;</span><span class=p>:</span> <span class=p>[</span><span class=kc>None</span><span class=p>,</span> <span class=s1>&#39;sqrt&#39;</span><span class=p>,</span> <span class=s1>&#39;log2&#39;</span><span class=p>],</span>

    <span class=c1># class balance</span>
    <span class=s1>&#39;clf__class_weight&#39;</span><span class=p>:</span> <span class=p>[</span><span class=kc>None</span><span class=p>,</span> <span class=s1>&#39;balanced&#39;</span><span class=p>],</span>

    <span class=c1># CART post-pruning – small positive values prune weak branches</span>
    <span class=s1>&#39;clf__ccp_alpha&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mf>0.0</span><span class=p>,</span> <span class=mf>1e-4</span><span class=p>,</span> <span class=mf>5e-4</span><span class=p>,</span> <span class=mf>1e-3</span><span class=p>]</span>
<span class=p>}]</span>

<span class=n>base_dt</span> <span class=o>=</span> <span class=n>Pipeline</span><span class=p>(</span><span class=n>steps</span><span class=o>=</span><span class=p>[(</span><span class=s1>&#39;prep&#39;</span><span class=p>,</span> <span class=n>preprocess</span><span class=p>),</span>
                          <span class=p>(</span><span class=s1>&#39;clf&#39;</span><span class=p>,</span> <span class=n>DecisionTreeClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>29</span><span class=p>))])</span>

<span class=n>cv</span> <span class=o>=</span> <span class=n>StratifiedKFold</span><span class=p>(</span><span class=n>n_splits</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>29</span><span class=p>)</span>
<span class=n>dt_grid</span> <span class=o>=</span> <span class=n>GridSearchCV</span><span class=p>(</span><span class=n>base_dt</span><span class=p>,</span> <span class=n>param_grid</span><span class=o>=</span><span class=n>param_grid_dt</span><span class=p>,</span> <span class=n>cv</span><span class=o>=</span><span class=n>cv</span><span class=p>,</span>
                       <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;roc_auc&#39;</span><span class=p>,</span> <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>,</span> <span class=n>refit</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>verbose</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>

<span class=n>dt_grid</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Best AUC (CV):&#39;</span><span class=p>,</span> <span class=n>dt_grid</span><span class=o>.</span><span class=n>best_score_</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Best params:&#39;</span><span class=p>,</span> <span class=n>dt_grid</span><span class=o>.</span><span class=n>best_params_</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>Fitting 5 folds for each of 1728 candidates, totalling 8640 fits
Best AUC (CV): 0.9081265647932314
Best params: {&#39;clf__ccp_alpha&#39;: 0.0, &#39;clf__class_weight&#39;: None, &#39;clf__criterion&#39;: &#39;gini&#39;, &#39;clf__max_depth&#39;: 4, &#39;clf__max_features&#39;: None, &#39;clf__min_samples_leaf&#39;: 5, &#39;clf__min_samples_split&#39;: 5, &#39;clf__splitter&#39;: &#39;random&#39;}
</code></pre></div> <div class=highlight><pre><span></span><code><span class=n>dt_metrics</span> <span class=o>=</span> <span class=n>evaluate_classifier</span><span class=p>(</span><span class=s2>&quot;Decision Tree (tuned)&quot;</span><span class=p>,</span> <span class=n>dt_grid</span><span class=o>.</span><span class=n>best_estimator_</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Human‑readable rules (Decision Tree, (hyperparameter tuned):&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>export_text</span><span class=p>(</span><span class=n>dt_grid</span><span class=o>.</span><span class=n>best_estimator_</span><span class=o>.</span><span class=n>named_steps</span><span class=p>[</span><span class=s1>&#39;clf&#39;</span><span class=p>],</span> <span class=n>feature_names</span><span class=o>=</span><span class=n>final_feature_names</span><span class=p>))</span>

<span class=c1># Optional visualization (will display when run in Jupyter)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>14</span><span class=p>,</span><span class=mi>8</span><span class=p>))</span>
<span class=n>plot_tree</span><span class=p>(</span><span class=n>dt_grid</span><span class=o>.</span><span class=n>best_estimator_</span><span class=o>.</span><span class=n>named_steps</span><span class=p>[</span><span class=s1>&#39;clf&#39;</span><span class=p>],</span> <span class=n>feature_names</span><span class=o>=</span><span class=n>final_feature_names</span><span class=p>,</span>
          <span class=n>class_names</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;No HD&#39;</span><span class=p>,</span><span class=s1>&#39;HD&#39;</span><span class=p>],</span> <span class=n>filled</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>rounded</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>max_depth</span><span class=o>=</span><span class=mi>3</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Decision Tree (depth=3)&#39;</span><span class=p>);</span> <span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Plain‑English explanation (Decision Tree):&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;• The top split isolates the strongest single risk condition; subsequent splits form compact if‑then rules.&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;• Leaves summarize risk with class proportions—ideal for quick triage guidelines.&quot;</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>=== Decision Tree (tuned) ===
Accuracy: 0.821
Precision: 0.822
Recall: 0.863
F1: 0.842
ROC-AUC: 0.880
PR-AUC: 0.859
Confusion matrix:
 [[63 19]
 [14 88]]
Classification report:
               precision    recall  f1-score   support

           0       0.82      0.77      0.79        82
           1       0.82      0.86      0.84       102

    accuracy                           0.82       184
   macro avg       0.82      0.82      0.82       184
weighted avg       0.82      0.82      0.82       184

Human‑readable rules (Decision Tree, (hyperparameter tuned):
|--- ST_Slope_Up &lt;= 0.91
|   |--- ChestPainType_ASY &lt;= 0.79
|   |   |--- Sex_F &lt;= 0.91
|   |   |   |--- ST_Slope_Flat &lt;= 0.61
|   |   |   |   |--- class: 0
|   |   |   |--- ST_Slope_Flat &gt;  0.61
|   |   |   |   |--- class: 1
|   |   |--- Sex_F &gt;  0.91
|   |   |   |--- Oldpeak &lt;= 0.61
|   |   |   |   |--- class: 0
|   |   |   |--- Oldpeak &gt;  0.61
|   |   |   |   |--- class: 0
|   |--- ChestPainType_ASY &gt;  0.79
|   |   |--- Sex_M &lt;= 0.04
|   |   |   |--- FastingBS &lt;= 0.57
|   |   |   |   |--- class: 1
|   |   |   |--- FastingBS &gt;  0.57
|   |   |   |   |--- class: 1
|   |   |--- Sex_M &gt;  0.04
|   |   |   |--- Cholesterol &lt;= 0.79
|   |   |   |   |--- class: 1
|   |   |   |--- Cholesterol &gt;  0.79
|   |   |   |   |--- class: 1
|--- ST_Slope_Up &gt;  0.91
|   |--- ChestPainType_ASY &lt;= 0.93
|   |   |--- FastingBS &lt;= 0.71
|   |   |   |--- RestingECG_LVH &lt;= 0.97
|   |   |   |   |--- class: 0
|   |   |   |--- RestingECG_LVH &gt;  0.97
|   |   |   |   |--- class: 0
|   |   |--- FastingBS &gt;  0.71
|   |   |   |--- Oldpeak &lt;= -0.18
|   |   |   |   |--- class: 0
|   |   |   |--- Oldpeak &gt;  -0.18
|   |   |   |   |--- class: 1
|   |--- ChestPainType_ASY &gt;  0.93
|   |   |--- ExerciseAngina_N &lt;= 0.11
|   |   |   |--- Oldpeak &lt;= 0.17
|   |   |   |   |--- class: 1
|   |   |   |--- Oldpeak &gt;  0.17
|   |   |   |   |--- class: 1
|   |   |--- ExerciseAngina_N &gt;  0.11
|   |   |   |--- FastingBS &lt;= 0.97
|   |   |   |   |--- class: 0
|   |   |   |--- FastingBS &gt;  0.97
|   |   |   |   |--- class: 1
</code></pre></div> <p><img alt=png src=output_36_1.png></p> <div class=highlight><pre><span></span><code>Plain‑English explanation (Decision Tree):
• The top split isolates the strongest single risk condition; subsequent splits form compact if‑then rules.
• Leaves summarize risk with class proportions—ideal for quick triage guidelines.
</code></pre></div> <h2 id=cart-decision-tree-with-cost-complexity-pruning>CART (Decision Tree with Cost-Complexity Pruning)<a class=headerlink href=#cart-decision-tree-with-cost-complexity-pruning title="Permanent link">&para;</a></h2> <p>CART applies pruning to reduce overfitting and simplify the tree. Cost-complexity pruning removes branches that contribute little to predictive power, resulting in a more generalizable and compact model. </p> <p>This section fits a full tree, derives pruning paths, and selects an optimal <code>ccp_alpha</code> to build a pruned tree. The final rules are extracted and explained.<br> <strong>Assumptions &amp; notes</strong>: Non‑parametric. Balancing bias–variance via pruning improves generalization. </p> <div class=highlight><pre><span></span><code><span class=c1># Fit full tree on engineered features to obtain pruning path</span>
<span class=n>Xtr_eng</span> <span class=o>=</span> <span class=n>preprocess</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X_train</span><span class=p>)</span>
<span class=kn>from</span> <span class=nn>sklearn.tree</span> <span class=kn>import</span> <span class=n>DecisionTreeClassifier</span>
<span class=n>full_tree</span> <span class=o>=</span> <span class=n>DecisionTreeClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
<span class=n>full_tree</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>Xtr_eng</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>

<span class=n>path</span> <span class=o>=</span> <span class=n>full_tree</span><span class=o>.</span><span class=n>cost_complexity_pruning_path</span><span class=p>(</span><span class=n>Xtr_eng</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
<span class=n>ccp_alphas</span> <span class=o>=</span> <span class=n>path</span><span class=o>.</span><span class=n>ccp_alphas</span>

<span class=c1># Choose a moderate alpha (e.g., median of unique alphas) for simplicity</span>
<span class=n>alpha</span> <span class=o>=</span> <span class=nb>float</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>median</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>unique</span><span class=p>(</span><span class=n>ccp_alphas</span><span class=p>)))</span>
<span class=n>cart</span> <span class=o>=</span> <span class=n>Pipeline</span><span class=p>(</span><span class=n>steps</span><span class=o>=</span><span class=p>[(</span><span class=s1>&#39;prep&#39;</span><span class=p>,</span> <span class=n>preprocess</span><span class=p>),</span>
                      <span class=p>(</span><span class=s1>&#39;clf&#39;</span><span class=p>,</span>  <span class=n>DecisionTreeClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>,</span> <span class=n>ccp_alpha</span><span class=o>=</span><span class=n>alpha</span><span class=p>))])</span>
<span class=n>cart</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
<span class=n>cart_metrics</span> <span class=o>=</span> <span class=n>evaluate_classifier</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;CART (pruned, ccp_alpha=</span><span class=si>{</span><span class=n>alpha</span><span class=si>:</span><span class=s2>.5f</span><span class=si>}</span><span class=s2>)&quot;</span><span class=p>,</span> <span class=n>cart</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>=== CART (pruned, ccp_alpha=0.00242) ===
Accuracy: 0.837
Precision: 0.853
Recall: 0.853
F1: 0.853
ROC-AUC: 0.820
PR-AUC: 0.817
Confusion matrix:
 [[67 15]
 [15 87]]
Classification report:
               precision    recall  f1-score   support

           0       0.82      0.82      0.82        82
           1       0.85      0.85      0.85       102

    accuracy                           0.84       184
   macro avg       0.84      0.84      0.84       184
weighted avg       0.84      0.84      0.84       184
</code></pre></div> <p>Optimising the parameters using grid search and cross validation.</p> <div class=highlight><pre><span></span><code><span class=c1># Derive candidate alphas from the pruning path (on engineered features)</span>
<span class=n>preprocess</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
<span class=n>Xtr_eng</span> <span class=o>=</span> <span class=n>preprocess</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>X_train</span><span class=p>)</span>

<span class=n>clf_full</span> <span class=o>=</span> <span class=n>DecisionTreeClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>29</span><span class=p>)</span>
<span class=n>clf_full</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>Xtr_eng</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
<span class=n>path</span> <span class=o>=</span> <span class=n>clf_full</span><span class=o>.</span><span class=n>cost_complexity_pruning_path</span><span class=p>(</span><span class=n>Xtr_eng</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
<span class=n>ccp_alphas</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>unique</span><span class=p>(</span><span class=n>path</span><span class=o>.</span><span class=n>ccp_alphas</span><span class=p>)</span>

<span class=c1># Build a simple grid over alphas, keeping depth small</span>
<span class=n>param_grid_cart</span> <span class=o>=</span> <span class=p>[{</span>
    <span class=s1>&#39;clf__ccp_alpha&#39;</span><span class=p>:</span> <span class=nb>list</span><span class=p>(</span><span class=n>ccp_alphas</span><span class=p>[::</span><span class=nb>max</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=n>ccp_alphas</span><span class=p>)</span><span class=o>//</span><span class=mi>10</span><span class=p>)]),</span>  <span class=c1># sample ~10 alphas</span>
    <span class=s1>&#39;clf__max_depth&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span>
    <span class=s1>&#39;clf__min_samples_leaf&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span>
    <span class=s1>&#39;clf__criterion&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;gini&#39;</span><span class=p>,</span> <span class=s1>&#39;entropy&#39;</span><span class=p>]</span>
<span class=p>}]</span>

<span class=n>base_cart</span> <span class=o>=</span> <span class=n>Pipeline</span><span class=p>(</span><span class=n>steps</span><span class=o>=</span><span class=p>[(</span><span class=s1>&#39;prep&#39;</span><span class=p>,</span> <span class=n>preprocess</span><span class=p>),</span>
                            <span class=p>(</span><span class=s1>&#39;clf&#39;</span><span class=p>,</span> <span class=n>DecisionTreeClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>29</span><span class=p>))])</span>

<span class=n>cv</span> <span class=o>=</span> <span class=n>StratifiedKFold</span><span class=p>(</span><span class=n>n_splits</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>29</span><span class=p>)</span>
<span class=n>cart_grid</span> <span class=o>=</span> <span class=n>GridSearchCV</span><span class=p>(</span><span class=n>base_cart</span><span class=p>,</span> <span class=n>param_grid</span><span class=o>=</span><span class=n>param_grid_cart</span><span class=p>,</span> <span class=n>cv</span><span class=o>=</span><span class=n>cv</span><span class=p>,</span>
                         <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;roc_auc&#39;</span><span class=p>,</span> <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>,</span> <span class=n>refit</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>verbose</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>

<span class=n>cart_grid</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Best AUC (CV):&#39;</span><span class=p>,</span> <span class=n>cart_grid</span><span class=o>.</span><span class=n>best_score_</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Best params:&#39;</span><span class=p>,</span> <span class=n>cart_grid</span><span class=o>.</span><span class=n>best_params_</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>Fitting 5 folds for each of 144 candidates, totalling 720 fits
Best AUC (CV): 0.897052808678825
Best params: {&#39;clf__ccp_alpha&#39;: 0.0, &#39;clf__criterion&#39;: &#39;entropy&#39;, &#39;clf__max_depth&#39;: 4, &#39;clf__min_samples_leaf&#39;: 5}
</code></pre></div> <div class=highlight><pre><span></span><code><span class=n>cart_metrics</span> <span class=o>=</span> <span class=n>evaluate_classifier</span><span class=p>(</span><span class=s2>&quot;CART (pruned, tuned)&quot;</span><span class=p>,</span> <span class=n>cart_grid</span><span class=o>.</span><span class=n>best_estimator_</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Rules (CART, pruned):&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>export_text</span><span class=p>(</span><span class=n>cart_grid</span><span class=o>.</span><span class=n>best_estimator_</span><span class=o>.</span><span class=n>named_steps</span><span class=p>[</span><span class=s1>&#39;clf&#39;</span><span class=p>],</span> <span class=n>feature_names</span><span class=o>=</span><span class=n>final_feature_names</span><span class=p>))</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Plain‑English explanation (CART):&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;• Pruning removes branches that add little generalizable signal, keeping rules concise.&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;• The final tree provides a short list of if‑then criteria suitable for checklists.&quot;</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>=== CART (pruned, tuned) ===
Accuracy: 0.804
Precision: 0.780
Recall: 0.902
F1: 0.836
ROC-AUC: 0.873
PR-AUC: 0.857
Confusion matrix:
 [[56 26]
 [10 92]]
Classification report:
               precision    recall  f1-score   support

           0       0.85      0.68      0.76        82
           1       0.78      0.90      0.84       102

    accuracy                           0.80       184
   macro avg       0.81      0.79      0.80       184
weighted avg       0.81      0.80      0.80       184

Rules (CART, pruned):
|--- ST_Slope_Up &lt;= 0.50
|   |--- ChestPainType_ASY &lt;= 0.50
|   |   |--- MaxHR &lt;= -0.00
|   |   |   |--- Sex_M &lt;= 0.50
|   |   |   |   |--- class: 0
|   |   |   |--- Sex_M &gt;  0.50
|   |   |   |   |--- class: 1
|   |   |--- MaxHR &gt;  -0.00
|   |   |   |--- ST_Slope_Flat &lt;= 0.50
|   |   |   |   |--- class: 0
|   |   |   |--- ST_Slope_Flat &gt;  0.50
|   |   |   |   |--- class: 1
|   |--- ChestPainType_ASY &gt;  0.50
|   |   |--- Sex_M &lt;= 0.50
|   |   |   |--- FastingBS &lt;= 0.63
|   |   |   |   |--- class: 1
|   |   |   |--- FastingBS &gt;  0.63
|   |   |   |   |--- class: 1
|   |   |--- Sex_M &gt;  0.50
|   |   |   |--- Oldpeak &lt;= -0.70
|   |   |   |   |--- class: 1
|   |   |   |--- Oldpeak &gt;  -0.70
|   |   |   |   |--- class: 1
|--- ST_Slope_Up &gt;  0.50
|   |--- ChestPainType_ASY &lt;= 0.50
|   |   |--- Oldpeak &lt;= 1.03
|   |   |   |--- Cholesterol &lt;= -0.10
|   |   |   |   |--- class: 0
|   |   |   |--- Cholesterol &gt;  -0.10
|   |   |   |   |--- class: 0
|   |   |--- Oldpeak &gt;  1.03
|   |   |   |--- class: 1
|   |--- ChestPainType_ASY &gt;  0.50
|   |   |--- Oldpeak &lt;= -0.41
|   |   |   |--- FastingBS &lt;= 0.63
|   |   |   |   |--- class: 0
|   |   |   |--- FastingBS &gt;  0.63
|   |   |   |   |--- class: 1
|   |   |--- Oldpeak &gt;  -0.41
|   |   |   |--- ExerciseAngina_Y &lt;= 0.50
|   |   |   |   |--- class: 1
|   |   |   |--- ExerciseAngina_Y &gt;  0.50
|   |   |   |   |--- class: 1

Plain‑English explanation (CART):
• Pruning removes branches that add little generalizable signal, keeping rules concise.
• The final tree provides a short list of if‑then criteria suitable for checklists.
</code></pre></div> <h2 id=naive-bayes-gaussian>Naive Bayes (Gaussian)<a class=headerlink href=#naive-bayes-gaussian title="Permanent link">&para;</a></h2> <p>Naive Bayes is a probabilistic classifier based on Bayes' theorem, assuming feature independence. It models continuous features using Gaussian distributions. </p> <p>This section trains and tunes a Gaussian Naive Bayes model, evaluates its performance, and analyzes feature-wise class means to understand which features contribute most to prediction. </p> <p><strong>Assumptions &amp; notes</strong>: Independence across features given the class. Stability is often improved by tuning <code>var_smoothing</code> (which adds a small value to variances). While it has While it has fewer tunable parameters than most models, it is great for fast, interpretable baselines. </p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>sklearn.naive_bayes</span> <span class=kn>import</span> <span class=n>GaussianNB</span>
<span class=kn>from</span> <span class=nn>sklearn.preprocessing</span> <span class=kn>import</span> <span class=n>FunctionTransformer</span>

<span class=c1># Make engineered features dense for GaussianNB</span>
<span class=n>to_dense</span> <span class=o>=</span> <span class=n>FunctionTransformer</span><span class=p>(</span><span class=k>lambda</span> <span class=n>X</span><span class=p>:</span> <span class=n>X</span><span class=o>.</span><span class=n>toarray</span><span class=p>()</span> <span class=k>if</span> <span class=nb>hasattr</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=s1>&#39;toarray&#39;</span><span class=p>)</span> <span class=k>else</span> <span class=n>X</span><span class=p>)</span>
<span class=n>nb</span> <span class=o>=</span> <span class=n>Pipeline</span><span class=p>(</span><span class=n>steps</span><span class=o>=</span><span class=p>[(</span><span class=s1>&#39;prep&#39;</span><span class=p>,</span> <span class=n>preprocess</span><span class=p>),</span>
                    <span class=p>(</span><span class=s1>&#39;dense&#39;</span><span class=p>,</span> <span class=n>to_dense</span><span class=p>),</span>
                    <span class=p>(</span><span class=s1>&#39;clf&#39;</span><span class=p>,</span>  <span class=n>GaussianNB</span><span class=p>())])</span>
<span class=n>nb</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
<span class=n>nb_metrics</span> <span class=o>=</span> <span class=n>evaluate_classifier</span><span class=p>(</span><span class=s2>&quot;Naive Bayes (Gaussian)&quot;</span><span class=p>,</span> <span class=n>nb</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>=== Naive Bayes (Gaussian) ===
Accuracy: 0.837
Precision: 0.867
Recall: 0.833
F1: 0.850
ROC-AUC: 0.909
PR-AUC: 0.923
Confusion matrix:
 [[69 13]
 [17 85]]
Classification report:
               precision    recall  f1-score   support

           0       0.80      0.84      0.82        82
           1       0.87      0.83      0.85       102

    accuracy                           0.84       184
   macro avg       0.83      0.84      0.84       184
weighted avg       0.84      0.84      0.84       184
</code></pre></div> <p>Optimising the parameters using grid search and cross validation.</p> <div class=highlight><pre><span></span><code><span class=n>param_grid_nb</span> <span class=o>=</span> <span class=p>[{</span>
    <span class=c1># var_smoothing adds a fraction of the largest variance for numerical stability</span>
    <span class=s1>&#39;clf__var_smoothing&#39;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>logspace</span><span class=p>(</span><span class=o>-</span><span class=mi>12</span><span class=p>,</span> <span class=o>-</span><span class=mi>7</span><span class=p>,</span> <span class=mi>10</span><span class=p>),</span>
    <span class=s1>&#39;clf__priors&#39;</span><span class=p>:</span> <span class=p>[</span><span class=kc>None</span><span class=p>]</span>  <span class=c1># keep data-driven class priors</span>
<span class=p>}]</span>

<span class=n>base_nb</span> <span class=o>=</span> <span class=n>Pipeline</span><span class=p>(</span><span class=n>steps</span><span class=o>=</span><span class=p>[(</span><span class=s1>&#39;prep&#39;</span><span class=p>,</span> <span class=n>preprocess</span><span class=p>),</span>
                          <span class=p>(</span><span class=s1>&#39;dense&#39;</span><span class=p>,</span> <span class=n>to_dense</span><span class=p>),</span>
                          <span class=p>(</span><span class=s1>&#39;clf&#39;</span><span class=p>,</span> <span class=n>GaussianNB</span><span class=p>())])</span>

<span class=n>cv</span> <span class=o>=</span> <span class=n>StratifiedKFold</span><span class=p>(</span><span class=n>n_splits</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>29</span><span class=p>)</span>
<span class=n>nb_grid</span> <span class=o>=</span> <span class=n>GridSearchCV</span><span class=p>(</span><span class=n>base_nb</span><span class=p>,</span> <span class=n>param_grid</span><span class=o>=</span><span class=n>param_grid_nb</span><span class=p>,</span> <span class=n>cv</span><span class=o>=</span><span class=n>cv</span><span class=p>,</span>
                       <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;roc_auc&#39;</span><span class=p>,</span> <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>,</span> <span class=n>refit</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>verbose</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>

<span class=n>nb_grid</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Best AUC (CV):&#39;</span><span class=p>,</span> <span class=n>nb_grid</span><span class=o>.</span><span class=n>best_score_</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Best params:&#39;</span><span class=p>,</span> <span class=n>nb_grid</span><span class=o>.</span><span class=n>best_params_</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>Fitting 5 folds for each of 10 candidates, totalling 50 fits
Best AUC (CV): 0.9183289499820665
Best params: {&#39;clf__priors&#39;: None, &#39;clf__var_smoothing&#39;: 1e-12}
</code></pre></div> <div class=highlight><pre><span></span><code><span class=n>nb_metrics</span> <span class=o>=</span> <span class=n>evaluate_classifier</span><span class=p>(</span><span class=s2>&quot;Naive Bayes (Gaussian, tuned)&quot;</span><span class=p>,</span> <span class=n>nb_grid</span><span class=o>.</span><span class=n>best_estimator_</span><span class=p>)</span>

<span class=c1># Class means per engineered feature</span>
<span class=n>gnb</span> <span class=o>=</span> <span class=n>nb_grid</span><span class=o>.</span><span class=n>best_estimator_</span><span class=o>.</span><span class=n>named_steps</span><span class=p>[</span><span class=s1>&#39;clf&#39;</span><span class=p>]</span>
<span class=n>Xtr_engineered</span> <span class=o>=</span> <span class=n>nb_grid</span><span class=o>.</span><span class=n>best_estimator_</span><span class=o>.</span><span class=n>named_steps</span><span class=p>[</span><span class=s1>&#39;dense&#39;</span><span class=p>]</span><span class=o>.</span>\
    <span class=n>transform</span><span class=p>(</span><span class=n>nb_grid</span><span class=o>.</span><span class=n>best_estimator_</span><span class=o>.</span><span class=n>named_steps</span><span class=p>[</span><span class=s1>&#39;prep&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>X_train</span><span class=p>))</span>
<span class=n>means_0</span> <span class=o>=</span> <span class=n>gnb</span><span class=o>.</span><span class=n>theta_</span><span class=p>[</span><span class=mi>0</span><span class=p>];</span> <span class=n>means_1</span> <span class=o>=</span> <span class=n>gnb</span><span class=o>.</span><span class=n>theta_</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span>
<span class=n>nb_df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>({</span><span class=s1>&#39;feature&#39;</span><span class=p>:</span> <span class=n>final_feature_names</span><span class=p>,</span>
                      <span class=s1>&#39;mean_no_disease&#39;</span><span class=p>:</span> <span class=n>means_0</span><span class=p>,</span>
                      <span class=s1>&#39;mean_disease&#39;</span><span class=p>:</span>   <span class=n>means_1</span><span class=p>,</span>
                      <span class=s1>&#39;diff(disease - no_disease)&#39;</span><span class=p>:</span> <span class=n>means_1</span> <span class=o>-</span> <span class=n>means_0</span><span class=p>})</span>
<span class=n>nb_df</span> <span class=o>=</span> <span class=n>nb_df</span><span class=o>.</span><span class=n>sort_values</span><span class=p>(</span><span class=s1>&#39;diff(disease - no_disease)&#39;</span><span class=p>,</span> <span class=n>ascending</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Plain‑English explanation (Naive Bayes):&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;• A feature value more typical under the disease class shifts the posterior toward heart disease; the opposite shifts toward no disease.&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Top features with largest class‑mean differences (NB view):&quot;</span><span class=p>)</span>
<span class=n>nb_df</span><span class=o>.</span><span class=n>head</span><span class=p>(</span><span class=mi>10</span><span class=p>)</span><span class=o>.</span><span class=n>round</span><span class=p>(</span><span class=mi>3</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>=== Naive Bayes (Gaussian, tuned) ===
Accuracy: 0.837
Precision: 0.867
Recall: 0.833
F1: 0.850
ROC-AUC: 0.909
PR-AUC: 0.923
Confusion matrix:
 [[69 13]
 [17 85]]
Classification report:
               precision    recall  f1-score   support

           0       0.80      0.84      0.82        82
           1       0.87      0.83      0.85       102

    accuracy                           0.84       184
   macro avg       0.83      0.84      0.84       184
weighted avg       0.84      0.84      0.84       184

Plain‑English explanation (Naive Bayes):
• A feature value more typical under the disease class shifts the posterior toward heart disease; the opposite shifts toward no disease.
Top features with largest class‑mean differences (NB view):
</code></pre></div> <div> <style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style> <table border=1 class=dataframe> <thead> <tr style="text-align: right;"> <th></th> <th>feature</th> <th>mean_no_disease</th> <th>mean_disease</th> <th>diff(disease - no_disease)</th> </tr> </thead> <tbody> <tr> <th>4</th> <td>Oldpeak</td> <td>-0.465</td> <td>0.376</td> <td>0.841</td> </tr> <tr> <th>0</th> <td>Age</td> <td>-0.334</td> <td>0.270</td> <td>0.604</td> </tr> <tr> <th>5</th> <td>FastingBS</td> <td>-0.320</td> <td>0.259</td> <td>0.579</td> </tr> <tr> <th>18</th> <td>ST_Slope_Flat</td> <td>0.186</td> <td>0.759</td> <td>0.573</td> </tr> <tr> <th>8</th> <td>ChestPainType_ASY</td> <td>0.253</td> <td>0.773</td> <td>0.520</td> </tr> <tr> <th>16</th> <td>ExerciseAngina_Y</td> <td>0.143</td> <td>0.618</td> <td>0.475</td> </tr> <tr> <th>1</th> <td>RestingBP</td> <td>-0.132</td> <td>0.107</td> <td>0.239</td> </tr> <tr> <th>7</th> <td>Sex_M</td> <td>0.655</td> <td>0.894</td> <td>0.239</td> </tr> <tr> <th>2</th> <td>Cholesterol</td> <td>-0.079</td> <td>0.064</td> <td>0.144</td> </tr> <tr> <th>14</th> <td>RestingECG_ST</td> <td>0.149</td> <td>0.227</td> <td>0.077</td> </tr> </tbody> </table> </div> <h2 id=k-nearest-neighbors-k-nn>k-Nearest Neighbors (k-NN)<a class=headerlink href=#k-nearest-neighbors-k-nn title="Permanent link">&para;</a></h2> <p>k-NN is a non-parametric, instance-based learning algorithm. It predicts the class of a sample based on the majority vote of its k nearest neighbors. </p> <p>This section trains and tunes a k-NN model, evaluates its performance, and inspects the neighbors of a sample to explain the prediction in clinical terms. </p> <p><strong>Assumptions &amp; notes</strong>: KNN is sensitive to scaling and the distance metric. Key hyperparameters include <code>n_neighbors</code>, <code>weights</code> (uniform vs distance), and <code>metric</code> (Minkowski with p=&frac12;). </p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>sklearn.neighbors</span> <span class=kn>import</span> <span class=n>KNeighborsClassifier</span>

<span class=n>knn</span> <span class=o>=</span> <span class=n>Pipeline</span><span class=p>(</span><span class=n>steps</span><span class=o>=</span><span class=p>[(</span><span class=s1>&#39;prep&#39;</span><span class=p>,</span> <span class=n>preprocess</span><span class=p>),</span>
                     <span class=p>(</span><span class=s1>&#39;clf&#39;</span><span class=p>,</span>  <span class=n>KNeighborsClassifier</span><span class=p>(</span><span class=n>n_neighbors</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>weights</span><span class=o>=</span><span class=s1>&#39;distance&#39;</span><span class=p>))])</span>
<span class=n>knn</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
<span class=n>knn_metrics</span> <span class=o>=</span> <span class=n>evaluate_classifier</span><span class=p>(</span><span class=s2>&quot;k-NN (k=5, distance weights)&quot;</span><span class=p>,</span> <span class=n>knn</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>=== k-NN (k=5, distance weights) ===
Accuracy: 0.859
Precision: 0.873
Recall: 0.873
F1: 0.873
ROC-AUC: 0.890
PR-AUC: 0.886
Confusion matrix:
 [[69 13]
 [13 89]]
Classification report:
               precision    recall  f1-score   support

           0       0.84      0.84      0.84        82
           1       0.87      0.87      0.87       102

    accuracy                           0.86       184
   macro avg       0.86      0.86      0.86       184
weighted avg       0.86      0.86      0.86       184
</code></pre></div> <div class=highlight><pre><span></span><code><span class=n>param_grid_knn</span> <span class=o>=</span> <span class=p>[{</span>
    <span class=s1>&#39;clf__n_neighbors&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mi>3</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span>
    <span class=s1>&#39;clf__weights&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;uniform&#39;</span><span class=p>,</span> <span class=s1>&#39;distance&#39;</span><span class=p>],</span>
    <span class=c1># Minkowski metric with p=1 (Manhattan) or p=2 (Euclidean)</span>
    <span class=s1>&#39;clf__metric&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;minkowski&#39;</span><span class=p>],</span>
    <span class=s1>&#39;clf__p&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>]</span>
<span class=p>}]</span>

<span class=n>base_knn</span> <span class=o>=</span> <span class=n>Pipeline</span><span class=p>(</span><span class=n>steps</span><span class=o>=</span><span class=p>[(</span><span class=s1>&#39;prep&#39;</span><span class=p>,</span> <span class=n>preprocess</span><span class=p>),</span>
                           <span class=p>(</span><span class=s1>&#39;clf&#39;</span><span class=p>,</span> <span class=n>KNeighborsClassifier</span><span class=p>())])</span>

<span class=n>cv</span> <span class=o>=</span> <span class=n>StratifiedKFold</span><span class=p>(</span><span class=n>n_splits</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>29</span><span class=p>)</span>
<span class=n>knn_grid</span> <span class=o>=</span> <span class=n>GridSearchCV</span><span class=p>(</span><span class=n>base_knn</span><span class=p>,</span> <span class=n>param_grid</span><span class=o>=</span><span class=n>param_grid_knn</span><span class=p>,</span> <span class=n>cv</span><span class=o>=</span><span class=n>cv</span><span class=p>,</span>
                        <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;roc_auc&#39;</span><span class=p>,</span> <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>,</span> <span class=n>refit</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>verbose</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>

<span class=n>knn_grid</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Best AUC (CV):&#39;</span><span class=p>,</span> <span class=n>knn_grid</span><span class=o>.</span><span class=n>best_score_</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Best params:&#39;</span><span class=p>,</span> <span class=n>knn_grid</span><span class=o>.</span><span class=n>best_params_</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>Fitting 5 folds for each of 20 candidates, totalling 100 fits
Best AUC (CV): 0.9204453821797994
Best params: {&#39;clf__metric&#39;: &#39;minkowski&#39;, &#39;clf__n_neighbors&#39;: 11, &#39;clf__p&#39;: 1, &#39;clf__weights&#39;: &#39;distance&#39;}
</code></pre></div> <p>Optimising the parameters using grid search and cross validation.</p> <div class=highlight><pre><span></span><code><span class=n>df_knn</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>

<span class=n>df_knn</span><span class=p>[</span><span class=s1>&#39;class&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>knn_grid</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>df</span><span class=p>)</span>
<span class=c1># df_knn.plot.scatter(&#39;RestingBP&#39;, &#39;Cholesterol&#39;, &#39;class&#39;)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>8</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
<span class=n>sns</span><span class=o>.</span><span class=n>scatterplot</span><span class=p>(</span><span class=n>data</span><span class=o>=</span><span class=n>df_knn</span><span class=p>,</span> <span class=n>x</span><span class=o>=</span><span class=s1>&#39;Age&#39;</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=s1>&#39;MaxHR&#39;</span><span class=p>,</span> <span class=n>hue</span><span class=o>=</span><span class=s1>&#39;class&#39;</span><span class=p>,</span> <span class=n>s</span><span class=o>=</span><span class=mi>50</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.75</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Scatter plot showing the incidence of heart disease&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <p><img alt=png src=output_51_0.png></p> <div class=highlight><pre><span></span><code><span class=n>knn_metrics</span> <span class=o>=</span> <span class=n>evaluate_classifier</span><span class=p>(</span><span class=s2>&quot;k-NN (tuned)&quot;</span><span class=p>,</span> <span class=n>knn_grid</span><span class=o>.</span><span class=n>best_estimator_</span><span class=p>)</span>

<span class=c1># Inspect neighbors for one patient</span>
<span class=n>idx</span> <span class=o>=</span> <span class=mi>0</span>
<span class=n>x_query</span> <span class=o>=</span> <span class=n>X_test</span><span class=o>.</span><span class=n>iloc</span><span class=p>[[</span><span class=n>idx</span><span class=p>]]</span>
<span class=n>y_true</span> <span class=o>=</span> <span class=n>y_test</span><span class=o>.</span><span class=n>iloc</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span>
<span class=n>proba</span> <span class=o>=</span> <span class=n>knn_grid</span><span class=o>.</span><span class=n>predict_proba</span><span class=p>(</span><span class=n>x_query</span><span class=p>)[:,</span><span class=mi>1</span><span class=p>][</span><span class=mi>0</span><span class=p>]</span>
<span class=n>pred</span>  <span class=o>=</span> <span class=n>knn_grid</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>x_query</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Plain‑English explanation (k‑NN):&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;• The prediction is driven by the outcomes of the five most similar patients; closer neighbors carry higher weight.&quot;</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Query patient index #</span><span class=si>{</span><span class=n>x_query</span><span class=o>.</span><span class=n>index</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=si>}</span><span class=s2> | True=</span><span class=si>{</span><span class=n>y_true</span><span class=si>}</span><span class=s2>, Pred=</span><span class=si>{</span><span class=n>pred</span><span class=si>}</span><span class=s2>, Prob(HD)=</span><span class=si>{</span><span class=n>proba</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Patient details:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>x_query</span><span class=p>)</span>
<span class=c1># Show actual neighbors from engineered space</span>
<span class=n>Xtr_eng2</span> <span class=o>=</span> <span class=n>preprocess</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>X_train</span><span class=p>)</span>
<span class=n>Xte_eng2</span> <span class=o>=</span> <span class=n>preprocess</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>x_query</span><span class=p>)</span>
<span class=n>base_knn</span> <span class=o>=</span> <span class=n>KNeighborsClassifier</span><span class=p>(</span><span class=n>n_neighbors</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>weights</span><span class=o>=</span><span class=s1>&#39;distance&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>Xtr_eng2</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
<span class=n>dist</span><span class=p>,</span> <span class=n>ind</span> <span class=o>=</span> <span class=n>base_knn</span><span class=o>.</span><span class=n>kneighbors</span><span class=p>(</span><span class=n>Xte_eng2</span><span class=p>,</span> <span class=n>n_neighbors</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>return_distance</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
<span class=n>neighbors</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>({</span><span class=s1>&#39;neighbor_train_idx&#39;</span><span class=p>:</span> <span class=n>y_train</span><span class=o>.</span><span class=n>index</span><span class=o>.</span><span class=n>values</span><span class=p>[</span><span class=n>ind</span><span class=p>[</span><span class=mi>0</span><span class=p>]],</span>
                          <span class=s1>&#39;distance&#39;</span><span class=p>:</span> <span class=n>dist</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span>
                          <span class=s1>&#39;label&#39;</span><span class=p>:</span>   <span class=n>y_train</span><span class=o>.</span><span class=n>iloc</span><span class=p>[</span><span class=n>ind</span><span class=p>[</span><span class=mi>0</span><span class=p>]]</span><span class=o>.</span><span class=n>values</span><span class=p>})</span><span class=o>.</span><span class=n>sort_values</span><span class=p>(</span><span class=s1>&#39;distance&#39;</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Nearest neighbors (closer = more influence):&quot;</span><span class=p>)</span>
<span class=n>neighbors</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>df</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>=== k-NN (tuned) ===
Accuracy: 0.875
Precision: 0.876
Recall: 0.902
F1: 0.889
ROC-AUC: 0.906
PR-AUC: 0.905
Confusion matrix:
 [[69 13]
 [10 92]]
Classification report:
               precision    recall  f1-score   support

           0       0.87      0.84      0.86        82
           1       0.88      0.90      0.89       102

    accuracy                           0.88       184
   macro avg       0.87      0.87      0.87       184
weighted avg       0.87      0.88      0.87       184

Plain‑English explanation (k‑NN):
• The prediction is driven by the outcomes of the five most similar patients; closer neighbors carry higher weight.
Query patient index #95 | True=1, Pred=1, Prob(HD)=0.868
Patient details:
    Age  RestingBP  Cholesterol  MaxHR  Oldpeak Sex ChestPainType RestingECG  \
95   58      130.0        263.0    140      2.0   M           ASY     Normal

   ExerciseAngina ST_Slope FastingBS  
95              Y     Flat         0  
Nearest neighbors (closer = more influence):
</code></pre></div> <div> <style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style> <table border=1 class=dataframe> <thead> <tr style="text-align: right;"> <th></th> <th>neighbor_train_idx</th> <th>distance</th> <th>label</th> <th>Age</th> <th>Sex</th> <th>ChestPainType</th> <th>RestingBP</th> <th>Cholesterol</th> <th>FastingBS</th> <th>RestingECG</th> <th>MaxHR</th> <th>ExerciseAngina</th> <th>Oldpeak</th> <th>ST_Slope</th> <th>HeartDisease</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>562</td> <td>0.806738</td> <td>0</td> <td>40</td> <td>M</td> <td>ATA</td> <td>140.0</td> <td>289.0</td> <td>0</td> <td>Normal</td> <td>172</td> <td>N</td> <td>0.0</td> <td>Up</td> <td>0</td> </tr> <tr> <th>1</th> <td>74</td> <td>0.926989</td> <td>1</td> <td>49</td> <td>F</td> <td>NAP</td> <td>160.0</td> <td>180.0</td> <td>0</td> <td>Normal</td> <td>156</td> <td>N</td> <td>1.0</td> <td>Flat</td> <td>1</td> </tr> <tr> <th>2</th> <td>586</td> <td>1.016484</td> <td>1</td> <td>37</td> <td>M</td> <td>ATA</td> <td>130.0</td> <td>283.0</td> <td>0</td> <td>ST</td> <td>98</td> <td>N</td> <td>0.0</td> <td>Up</td> <td>0</td> </tr> <tr> <th>3</th> <td>501</td> <td>1.032806</td> <td>1</td> <td>48</td> <td>F</td> <td>ASY</td> <td>138.0</td> <td>214.0</td> <td>0</td> <td>Normal</td> <td>108</td> <td>Y</td> <td>1.5</td> <td>Flat</td> <td>1</td> </tr> <tr> <th>4</th> <td>368</td> <td>1.053968</td> <td>1</td> <td>54</td> <td>M</td> <td>NAP</td> <td>150.0</td> <td>195.0</td> <td>0</td> <td>Normal</td> <td>122</td> <td>N</td> <td>0.0</td> <td>Up</td> <td>0</td> </tr> </tbody> </table> </div> <div class=highlight><pre><span></span><code><span class=n>summary</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>([</span><span class=n>lr_metrics</span><span class=p>,</span> <span class=n>dt_metrics</span><span class=p>,</span> <span class=n>cart_metrics</span><span class=p>,</span> <span class=n>nb_metrics</span><span class=p>,</span> <span class=n>knn_metrics</span><span class=p>])</span><span class=o>.</span><span class=n>set_index</span><span class=p>(</span><span class=s1>&#39;model&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>sort_values</span><span class=p>(</span><span class=s1>&#39;roc_auc&#39;</span><span class=p>,</span> <span class=n>ascending</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
<span class=n>summary</span><span class=o>.</span><span class=n>sort_values</span><span class=p>(</span><span class=s1>&#39;accuracy&#39;</span><span class=p>,</span> <span class=n>ascending</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span><span class=o>.</span><span class=n>round</span><span class=p>(</span><span class=mi>3</span><span class=p>)</span>
</code></pre></div> <div> <style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style> <table border=1 class=dataframe> <thead> <tr style="text-align: right;"> <th></th> <th>accuracy</th> <th>precision</th> <th>recall</th> <th>f1</th> <th>roc_auc</th> <th>pr_auc</th> </tr> <tr> <th>model</th> <th></th> <th></th> <th></th> <th></th> <th></th> <th></th> </tr> </thead> <tbody> <tr> <th>k-NN (tuned)</th> <td>0.875</td> <td>0.876</td> <td>0.902</td> <td>0.889</td> <td>0.906</td> <td>0.905</td> </tr> <tr> <th>Logistic Regression (with hyper parameter tuning)</th> <td>0.842</td> <td>0.869</td> <td>0.843</td> <td>0.856</td> <td>0.909</td> <td>0.924</td> </tr> <tr> <th>Naive Bayes (Gaussian, tuned)</th> <td>0.837</td> <td>0.867</td> <td>0.833</td> <td>0.850</td> <td>0.909</td> <td>0.923</td> </tr> <tr> <th>CART (pruned, ccp_alpha=0.00242)</th> <td>0.837</td> <td>0.853</td> <td>0.853</td> <td>0.853</td> <td>0.820</td> <td>0.817</td> </tr> <tr> <th>Decision Tree (tuned)</th> <td>0.821</td> <td>0.822</td> <td>0.863</td> <td>0.842</td> <td>0.880</td> <td>0.859</td> </tr> </tbody> </table> </div> <h2 id=diagnostics-of-the-best-model>Diagnostics of the Best Model<a class=headerlink href=#diagnostics-of-the-best-model title="Permanent link">&para;</a></h2> <p>To ensure robustness and reliability, we perform diagnostics on the best-performing model (k-NN). This includes checking multicollinearity using VIF and plotting learning curves to assess bias-variance tradeoff. </p> <p>These diagnostics help validate model assumptions and guide further improvements. </p> <div class=highlight><pre><span></span><code><span class=n>best_model</span> <span class=o>=</span> <span class=n>knn_grid</span><span class=o>.</span><span class=n>best_estimator_</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>statsmodels.stats.outliers_influence</span> <span class=kn>import</span> <span class=n>variance_inflation_factor</span>

<span class=n>X_num</span> <span class=o>=</span> <span class=n>df</span><span class=p>[</span><span class=n>num_cols</span><span class=p>]</span><span class=o>.</span><span class=n>dropna</span><span class=p>()</span>
<span class=n>X_num_const</span> <span class=o>=</span> <span class=n>sm</span><span class=o>.</span><span class=n>add_constant</span><span class=p>(</span><span class=n>X_num</span><span class=p>)</span>
<span class=n>vif</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>({</span>
    <span class=s1>&#39;feature&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;const&#39;</span><span class=p>]</span> <span class=o>+</span> <span class=nb>list</span><span class=p>(</span><span class=n>X_num</span><span class=o>.</span><span class=n>columns</span><span class=p>),</span>
    <span class=s1>&#39;VIF&#39;</span><span class=p>:</span> <span class=p>[</span><span class=n>variance_inflation_factor</span><span class=p>(</span><span class=n>X_num_const</span><span class=o>.</span><span class=n>values</span><span class=p>,</span> <span class=n>i</span><span class=p>)</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>X_num_const</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>])]</span>
<span class=p>})</span>
<span class=n>vif</span>
</code></pre></div> <div> <style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style> <table border=1 class=dataframe> <thead> <tr style="text-align: right;"> <th></th> <th>feature</th> <th>VIF</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>const</td> <td>160.072777</td> </tr> <tr> <th>1</th> <td>Age</td> <td>1.277888</td> </tr> <tr> <th>2</th> <td>RestingBP</td> <td>1.098974</td> </tr> <tr> <th>3</th> <td>Cholesterol</td> <td>1.011748</td> </tr> <tr> <th>4</th> <td>MaxHR</td> <td>1.205888</td> </tr> <tr> <th>5</th> <td>Oldpeak</td> <td>1.142342</td> </tr> </tbody> </table> </div> <h3 id=roc-auc-curve>ROC-AUC Curve<a class=headerlink href=#roc-auc-curve title="Permanent link">&para;</a></h3> <p>The ROC (Receiver Operating Characteristic) curve is a graphical representation of a classifier's performance across different threshold values. It plots the True Positive Rate (Sensitivity) against the False Positive Rate (1 - Specificity). </p> <p>AUC (Area Under the Curve) quantifies the overall ability of the model to discriminate between positive and negative classes. A higher AUC indicates better performance. </p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>sklearn.metrics</span> <span class=kn>import</span> <span class=n>roc_curve</span><span class=p>,</span> <span class=n>auc</span>
<span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>

<span class=c1># Predict probabilities</span>
<span class=n>y_probs</span> <span class=o>=</span> <span class=n>best_model</span><span class=o>.</span><span class=n>predict_proba</span><span class=p>(</span><span class=n>X_test</span><span class=p>)[:,</span> <span class=mi>1</span><span class=p>]</span>

<span class=c1># Compute ROC curve and AUC</span>
<span class=n>fpr</span><span class=p>,</span> <span class=n>tpr</span><span class=p>,</span> <span class=n>thresholds</span> <span class=o>=</span> <span class=n>roc_curve</span><span class=p>(</span><span class=n>y_test</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=nb>int</span><span class=p>),</span> <span class=n>y_probs</span><span class=p>)</span>
<span class=n>roc_auc</span> <span class=o>=</span> <span class=n>auc</span><span class=p>(</span><span class=n>fpr</span><span class=p>,</span> <span class=n>tpr</span><span class=p>)</span>

<span class=c1># Plot ROC curve</span>
<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>fpr</span><span class=p>,</span> <span class=n>tpr</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;darkorange&#39;</span><span class=p>,</span> <span class=n>lw</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;ROC curve (AUC = </span><span class=si>{</span><span class=n>roc_auc</span><span class=si>:</span><span class=s1>.2f</span><span class=si>}</span><span class=s1>)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>([</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;navy&#39;</span><span class=p>,</span> <span class=n>lw</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;False Positive Rate&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;True Positive Rate&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Receiver Operating Characteristic&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>(</span><span class=n>loc</span><span class=o>=</span><span class=s1>&#39;lower right&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>();</span>
</code></pre></div> <p><img alt=png src=output_58_0.png></p> <p>AUC of 0.91 indicates good performance</p> <h3 id=sensitivity-specificity-curve>Sensitivity-Specificity Curve<a class=headerlink href=#sensitivity-specificity-curve title="Permanent link">&para;</a></h3> <p>This curve shows how sensitivity and specificity vary with different classification thresholds. It helps in selecting a threshold that balances both metrics.</p> <div class=highlight><pre><span></span><code><span class=c1># Compute sensitivity and specificity</span>
<span class=n>sensitivity</span> <span class=o>=</span> <span class=n>tpr</span>
<span class=n>specificity</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>fpr</span>
<span class=c1># Plot Sensitivity-Specificity curve</span>
<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>thresholds</span><span class=p>,</span> <span class=n>sensitivity</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Sensitivity&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>thresholds</span><span class=p>,</span> <span class=n>specificity</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Specificity&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Threshold&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Sensitivity vs Specificity&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>();</span>
</code></pre></div> <p><img alt=png src=output_60_0.png></p> <h3 id=learning-curves>Learning curves<a class=headerlink href=#learning-curves title="Permanent link">&para;</a></h3> <p>Learning curves are a valuable diagnostic tool to understand how a model's performance evolves with increasing training data. They help assess whether a model suffers from high bias (underfitting) or high variance (overfitting), and whether adding more data could improve performance.</p> <div class=highlight><pre><span></span><code><span class=c1># Learning curve for best estimator</span>
<span class=n>train_sizes</span><span class=p>,</span> <span class=n>train_scores</span><span class=p>,</span> <span class=n>val_scores</span> <span class=o>=</span> <span class=n>learning_curve</span><span class=p>(</span><span class=n>best_model</span><span class=p>,</span> <span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>cv</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;roc_auc&#39;</span><span class=p>,</span> <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>,</span>
                                                      <span class=n>train_sizes</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mf>0.1</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>,</span> <span class=mi>5</span><span class=p>),</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>29</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>7</span><span class=p>,</span><span class=mi>5</span><span class=p>))</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>train_sizes</span><span class=p>,</span> <span class=n>train_scores</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span> <span class=s1>&#39;o-&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Train AUC&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>train_sizes</span><span class=p>,</span> <span class=n>val_scores</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span> <span class=s1>&#39;o-&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;CV AUC&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Training examples&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylim</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mf>1.01</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;ROC-AUC&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Learning Curve&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <p><img alt=png src=output_62_0.png></p> <h2 id=ethics-and-robustness>Ethics and robustness<a class=headerlink href=#ethics-and-robustness title="Permanent link">&para;</a></h2> <ul> <li><strong>Medical use requires validation</strong>: consult clinicians; understand labeling &amp; sampling biases. </li> <li>Test <strong>fairness</strong> across groups (e.g., Sex) and ensure no proxy discrimination. </li> <li>Perform <strong>temporal/center splits</strong> if applicable; assess <strong>drift</strong>. </li> <li>Consider <strong>decision support</strong> (calibrated probabilities + cost‑aware thresholds) rather than hard automation. </li> </ul> </article> </div> </div> <a href=# class="md-top md-icon" data-md-component=top data-md-state=hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"/></svg> Back to top </a> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../ML%20using%20scikit-learn/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Multi models (Python)" rel=prev> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </div> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> Previous </span> Multi models (Python) </div> </div> </a> <a href=../Demonstrating%20online%20learning/ class="md-footer__link md-footer__link--next" aria-label="Next: Streaming Machine Learning (Python)" rel=next> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> Next </span> Streaming Machine Learning (Python) </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright> <div class=md-footer-copyright__highlight> <img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png> </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-footer-social> <a href=https://github.com/HarshaAsh target=_blank rel=noopener title=github.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </a> <a href=https://www.linkedin.com/in/sri-harsha-achyuthuni/ target=_blank rel=noopener title=www.linkedin.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg> </a> <a href=https://www.instagram.com/harshaash_com/ target=_blank rel=noopener title=www.instagram.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M224.1 141c-63.6 0-114.9 51.3-114.9 114.9s51.3 114.9 114.9 114.9S339 319.5 339 255.9 287.7 141 224.1 141zm0 189.6c-41.1 0-74.7-33.5-74.7-74.7s33.5-74.7 74.7-74.7 74.7 33.5 74.7 74.7-33.6 74.7-74.7 74.7zm146.4-194.3c0 14.9-12 26.8-26.8 26.8-14.9 0-26.8-12-26.8-26.8s12-26.8 26.8-26.8 26.8 12 26.8 26.8zm76.1 27.2c-1.7-35.9-9.9-67.7-36.2-93.9-26.2-26.2-58-34.4-93.9-36.2-37-2.1-147.9-2.1-184.9 0-35.8 1.7-67.6 9.9-93.9 36.1s-34.4 58-36.2 93.9c-2.1 37-2.1 147.9 0 184.9 1.7 35.9 9.9 67.7 36.2 93.9s58 34.4 93.9 36.2c37 2.1 147.9 2.1 184.9 0 35.9-1.7 67.7-9.9 93.9-36.2 26.2-26.2 34.4-58 36.2-93.9 2.1-37 2.1-147.8 0-184.8zM398.8 388c-7.8 19.6-22.9 34.7-42.6 42.6-29.5 11.7-99.5 9-132.1 9s-102.7 2.6-132.1-9c-19.6-7.8-34.7-22.9-42.6-42.6-11.7-29.5-9-99.5-9-132.1s-2.6-102.7 9-132.1c7.8-19.6 22.9-34.7 42.6-42.6 29.5-11.7 99.5-9 132.1-9s102.7-2.6 132.1 9c19.6 7.8 34.7 22.9 42.6 42.6 11.7 29.5 9 99.5 9 132.1s2.7 102.7-9 132.1z"/></svg> </a> <a href=https://www.facebook.com/sri.harsha.achyuthuni/ target=_blank rel=noopener title=www.facebook.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><path d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.28c-30.8 0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../..", "features": ["content.code.annotate", "content.tabs.link", "header.autohide", "navigation.sections", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest"], "search": "../../assets/javascripts/workers/search.709b4209.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "version": null}</script> <script src=../../assets/javascripts/bundle.56838a2c.min.js></script> </body> </html>