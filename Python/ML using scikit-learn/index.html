<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Harsha's blog on data science"><meta name=author content="Harsha Achyuthuni"><link href=https://www.harshaash.com/Python/ML%20using%20scikit-learn/ rel=canonical><link rel=icon href=../../assets/images/logo.jpg><meta name=generator content="mkdocs-1.2.2, mkdocs-material-7.2.4"><title>ML using scikit-learn (Python) - Data Science with Harsha</title><link rel=stylesheet href=../../assets/stylesheets/main.f7f47774.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.3f5d1f46.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback"><style>:root{--md-text-font-family:"Roboto";--md-code-font-family:"Roboto Mono"}</style><link rel=stylesheet href=../../overrides/assets/stylesheets/user_defined.css><script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-65034507-2","auto"),ga("set","anonymizeIp",!0),ga("send","pageview"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){var e;this.value&&(e=document.location.pathname,ga("send","pageview",e+"?q="+this.value))}),"undefined"!=typeof location$&&location$.subscribe(function(e){ga("send","pageview",e.pathname)})})</script><script async src=https://www.google-analytics.com/analytics.js></script></head> <body dir=ltr data-md-color-scheme data-md-color-primary data-md-color-accent> <script>function __prefix(e){return new URL("../..",location).pathname+"."+e}function __get(e,t=localStorage){return JSON.parse(t.getItem(__prefix(e)))}</script> <script>var palette=__get("__palette");if(null!==palette&&"object"==typeof palette.color)for(var key in palette.color)document.body.setAttribute("data-md-color-"+key,palette.color[key])</script> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#ml-using-scikit-learn class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="Data Science with Harsha" class="md-header__button md-logo" aria-label="Data Science with Harsha" data-md-component=logo> <img src=../../assets/images/logo.jpg alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Data Science with Harsha </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> ML using scikit-learn (Python) </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme data-md-color-primary data-md-color-accent aria-hidden=true type=radio name=__palette id=__palette_1> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_2> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M7 10a2 2 0 0 1 2 2 2 2 0 0 1-2 2 2 2 0 0 1-2-2 2 2 0 0 1 2-2m10-3a5 5 0 0 1 5 5 5 5 0 0 1-5 5H7a5 5 0 0 1-5-5 5 5 0 0 1 5-5h10M7 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3h10a3 3 0 0 0 3-3 3 3 0 0 0-3-3H7z"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme data-md-color-primary data-md-color-accent aria-hidden=true type=radio name=__palette id=__palette_3> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=red data-md-color-accent=red aria-label="Switch to light mode" type=radio name=__palette id=__palette_4> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_3 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3z"/></svg> </label> </form> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08z"/></svg> </a> <button type=reset class="md-search__icon md-icon" aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="Data Science with Harsha" class="md-nav__button md-logo" aria-label="Data Science with Harsha" data-md-component=logo> <img src=../../assets/images/logo.jpg alt=logo> </a> Data Science with Harsha </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> Home </a> </li> <li class=md-nav__item> <a href=../../resume/ class=md-nav__link> Resume </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3 type=checkbox id=__nav_3 checked> <label class=md-nav__link for=__nav_3> Blog <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Blog data-md-level=1> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Blog </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_1 type=checkbox id=__nav_3_1> <label class=md-nav__link for=__nav_3_1> Visualization <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Visualization data-md-level=2> <label class=md-nav__title for=__nav_3_1> <span class="md-nav__icon md-icon"></span> Visualization </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../Vizualisation%20using%20python%20Part%201/ class=md-nav__link> Vizualizing tabular data (Python) </a> </li> <li class=md-nav__item> <a href=../Visualization%20for%20predictive%20analytics/ class=md-nav__link> Vizualising for predictive analytics (Python) </a> </li> <li class=md-nav__item> <a href=../../R/Univariate-analysis/ class=md-nav__link> Univariate Analysis (R) </a> </li> <li class=md-nav__item> <a href=../../R/multivariateAnalysis/ class=md-nav__link> Multivariate Analysis (R) </a> </li> <li class=md-nav__item> <a href=../../R/multicollinearity/ class=md-nav__link> Multicollinearity (R) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_2 type=checkbox id=__nav_3_2> <label class=md-nav__link for=__nav_3_2> Statistics basics <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Statistics basics" data-md-level=2> <label class=md-nav__title for=__nav_3_2> <span class="md-nav__icon md-icon"></span> Statistics basics </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../R/Probability/ class=md-nav__link> Probability (R) </a> </li> <li class=md-nav__item> <a href=../../R/vectors/ class=md-nav__link> Vectors (R) </a> </li> <li class=md-nav__item> <a href=../../R/matrices/ class=md-nav__link> Matrices (R) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_3 type=checkbox id=__nav_3_3> <label class=md-nav__link for=__nav_3_3> Hypothesis Testing <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Hypothesis Testing" data-md-level=2> <label class=md-nav__title for=__nav_3_3> <span class="md-nav__icon md-icon"></span> Hypothesis Testing </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../R/attendance_t_test/ class=md-nav__link> z-test and t-test (R) </a> </li> <li class=md-nav__item> <a href=../../R/anova/ class=md-nav__link> ANOVA Test (R) </a> </li> <li class=md-nav__item> <a href=../../R/chi-sq-goodness-of-fit/ class=md-nav__link> Chi-Square Goodness of fit (R) </a> </li> <li class=md-nav__item> <a href=../../R/chi-sq-test-of-independence/ class=md-nav__link> Chi-Square test of independence (R) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_4 type=checkbox id=__nav_3_4> <label class=md-nav__link for=__nav_3_4> Factor Analysis <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Factor Analysis" data-md-level=2> <label class=md-nav__title for=__nav_3_4> <span class="md-nav__icon md-icon"></span> Factor Analysis </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../R/Curse-of-Dimensionality/ class=md-nav__link> Curse of dimensionality </a> </li> <li class=md-nav__item> <a href=../../R/EFA/ class=md-nav__link> Exploratory factor analysis (R) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_5 type=checkbox id=__nav_3_5> <label class=md-nav__link for=__nav_3_5> Prediction algorithms <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Prediction algorithms" data-md-level=2> <label class=md-nav__title for=__nav_3_5> <span class="md-nav__icon md-icon"></span> Prediction algorithms </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_5_1 type=checkbox id=__nav_3_5_1> <label class=md-nav__link for=__nav_3_5_1> Classification Algorithms <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Classification Algorithms" data-md-level=3> <label class=md-nav__title for=__nav_3_5_1> <span class="md-nav__icon md-icon"></span> Classification Algorithms </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../R/logistic-regression/ class=md-nav__link> Logistic Regression (R) </a> </li> <li class=md-nav__item> <a href=../../R/CHAID/ class=md-nav__link> CHAID Decision Trees (R) </a> </li> <li class=md-nav__item> <a href=../../R/CART-Classification/ class=md-nav__link> CART Classification (R) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_5_2 type=checkbox id=__nav_3_5_2> <label class=md-nav__link for=__nav_3_5_2> Regression Algorithms <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Regression Algorithms" data-md-level=3> <label class=md-nav__title for=__nav_3_5_2> <span class="md-nav__icon md-icon"></span> Regression Algorithms </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../R/part-and-partial-corr/ class=md-nav__link> Part and partial correlation </a> </li> <li class=md-nav__item> <a href=../../R/Linear-regression/ class=md-nav__link> Linear Regression (R) </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_6 type=checkbox id=__nav_3_6> <label class=md-nav__link for=__nav_3_6> Preprocessing data <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Preprocessing data" data-md-level=2> <label class=md-nav__title for=__nav_3_6> <span class="md-nav__icon md-icon"></span> Preprocessing data </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../R/KNN_Imputation/ class=md-nav__link> Null Value Imputation (R) </a> </li> <li class=md-nav__item> <a href=../Machine%20Learning%20Part%201/ class=md-nav__link> Feature engineering (Python) </a> </li> <li class=md-nav__item> <a href=../../R/Handling-Imbalanced-classes/ class=md-nav__link> Handling Imbalanced Classes </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_7 type=checkbox id=__nav_3_7 checked> <label class=md-nav__link for=__nav_3_7> Machine Learning <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Machine Learning" data-md-level=2> <label class=md-nav__title for=__nav_3_7> <span class="md-nav__icon md-icon"></span> Machine Learning </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=https://harshaachyuthuni.shinyapps.io/Machine_Learning/ class=md-nav__link> Interactive Machine Learning (RShiny) </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" data-md-toggle=toc type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> ML using scikit-learn (Python) <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> ML using scikit-learn (Python) </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#predicting-absenteeism class=md-nav__link> Predicting absenteeism </a> </li> <li class=md-nav__item> <a href=#base-model class=md-nav__link> Base model </a> </li> <li class=md-nav__item> <a href=#decision-tree-classifier class=md-nav__link> Decision Tree Classifier </a> <nav class=md-nav aria-label="Decision Tree Classifier"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#downsampling class=md-nav__link> Downsampling </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#multiple-models class=md-nav__link> Multiple models </a> </li> <li class=md-nav__item> <a href=#predictions class=md-nav__link> Predictions </a> </li> <li class=md-nav__item> <a href=#save-models class=md-nav__link> Save Models </a> </li> <li class=md-nav__item> <a href=#references class=md-nav__link> References </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../Demonstrating%20online%20learning/ class=md-nav__link> Streaming Machine Learning (Python) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_8 type=checkbox id=__nav_3_8> <label class=md-nav__link for=__nav_3_8> Time Series forecasting <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Time Series forecasting" data-md-level=2> <label class=md-nav__title for=__nav_3_8> <span class="md-nav__icon md-icon"></span> Time Series forecasting </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../R/time-series/ class=md-nav__link> Introduction to stationarity (R) </a> </li> <li class=md-nav__item> <a href=../../R/Stationarity-tests/ class=md-nav__link> Stationary Tests (R) </a> </li> <li class=md-nav__item> <a href=../../R/ARIMA/ class=md-nav__link> ARIMA in R </a> </li> <li class=md-nav__item> <a href=../ARIMA%20Forecasting/ class=md-nav__link> ARIMA in Python </a> </li> <li class=md-nav__item> <a href=../../R/Seasonal-Time-Series/ class=md-nav__link> Seasonal time series (R) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_9 type=checkbox id=__nav_3_9> <label class=md-nav__link for=__nav_3_9> Deep learning <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Deep learning" data-md-level=2> <label class=md-nav__title for=__nav_3_9> <span class="md-nav__icon md-icon"></span> Deep learning </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../R/ANN-1/ class=md-nav__link> Artificial Neural Network (Theory) </a> </li> <li class=md-nav__item> <a href=../../R/ANN2/ class=md-nav__link> The math behind ANN </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_10 type=checkbox id=__nav_3_10> <label class=md-nav__link for=__nav_3_10> Prescriptive Analytics <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Prescriptive Analytics" data-md-level=2> <label class=md-nav__title for=__nav_3_10> <span class="md-nav__icon md-icon"></span> Prescriptive Analytics </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../R/Linear-programming/ class=md-nav__link> Linear Programming (R) </a> </li> <li class=md-nav__item> <a href=../../R/adoption_of_new_product/ class=md-nav__link> Adoption of new product (R) </a> </li> <li class=md-nav__item> <a href=../Diffusion%20on%20networks/ class=md-nav__link> Bass Forecasting model (Python) </a> </li> <li class=md-nav__item> <a href=../../Others/AHP/ class=md-nav__link> Analytic Hierarchy Process </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_11 type=checkbox id=__nav_3_11> <label class=md-nav__link for=__nav_3_11> Clustering <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Clustering data-md-level=2> <label class=md-nav__title for=__nav_3_11> <span class="md-nav__icon md-icon"></span> Clustering </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../R/hierarchical_clustering/ class=md-nav__link> Hierarchical Clustering </a> </li> <li class=md-nav__item> <a href=../../R/kMeansClustering/ class=md-nav__link> K-Means Clustering </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_12 type=checkbox id=__nav_3_12> <label class=md-nav__link for=__nav_3_12> Reinforcement Learning <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Reinforcement Learning" data-md-level=2> <label class=md-nav__title for=__nav_3_12> <span class="md-nav__icon md-icon"></span> Reinforcement Learning </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../R/CustomerLifetimeValue/ class=md-nav__link> Customer Lifetime Value </a> </li> <li class=md-nav__item> <a href=../../R/recommendation-systems/ class=md-nav__link> Recommendation Systems </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_13 type=checkbox id=__nav_3_13> <label class=md-nav__link for=__nav_3_13> Networks <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Networks data-md-level=2> <label class=md-nav__title for=__nav_3_13> <span class="md-nav__icon md-icon"></span> Networks </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../Introduction%20to%20Networkx/ class=md-nav__link> Introduction to NetworkX (Python) </a> </li> <li class=md-nav__item> <a href=../Network%20Science/ class=md-nav__link> Network Science (Python) </a> </li> <li class=md-nav__item> <a href=../Network%20centrality/ class=md-nav__link> Network Centrality (Python) </a> </li> <li class=md-nav__item> <a href=../Shortest%20path%20problems/ class=md-nav__link> Shortest path using integer programming (Python) </a> </li> <li class=md-nav__item> <a href=../Network%20Flow%20problems/ class=md-nav__link> Network flow problems (Python) </a> </li> <li class=md-nav__item> <a href=../Community%20detection/ class=md-nav__link> Community detection (Python) </a> </li> <li class=md-nav__item> <a href=../Bipartite%20matching/ class=md-nav__link> Bipartite matching (Python) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_14 type=checkbox id=__nav_3_14> <label class=md-nav__link for=__nav_3_14> Deployment <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Deployment data-md-level=2> <label class=md-nav__title for=__nav_3_14> <span class="md-nav__icon md-icon"></span> Deployment </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../Machine%20learning%20as%20HTTP%20Request/ class=md-nav__link> ML deployment in Flask (Python) </a> </li> <li class=md-nav__item> <a href=../Saving%20predictions%20in%20database/ class=md-nav__link> Handling databases using python </a> </li> <li class=md-nav__item> <a href=../ORM/ class=md-nav__link> ORM (Python) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_15 type=checkbox id=__nav_3_15> <label class=md-nav__link for=__nav_3_15> Higher education review <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Higher education review" data-md-level=2> <label class=md-nav__title for=__nav_3_15> <span class="md-nav__icon md-icon"></span> Higher education review </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Others/IIMB%20BAI/ class=md-nav__link> IIMB BAI </a> </li> <li class=md-nav__item> <a href=../../Others/part%20time%20data%20science%20masters/ class=md-nav__link> Part-time DS masters </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_16 type=checkbox id=__nav_3_16> <label class=md-nav__link for=__nav_3_16> External blogs <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="External blogs" data-md-level=2> <label class=md-nav__title for=__nav_3_16> <span class="md-nav__icon md-icon"></span> External blogs </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Others/Imperial%20College%20London/ class=md-nav__link> Imperial college London </a> </li> <li class=md-nav__item> <a href=../../Others/Rolls%20Royce/ class=md-nav__link> Rolls Royce </a> </li> <li class=md-nav__item> <a href=../../Others/Publications/ class=md-nav__link> Publications/conferences </a> </li> <li class=md-nav__item> <a href=../../Others/Deployed%20apps/ class=md-nav__link> Deployed apps </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_17 type=checkbox id=__nav_3_17> <label class=md-nav__link for=__nav_3_17> Projects <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Projects data-md-level=2> <label class=md-nav__title for=__nav_3_17> <span class="md-nav__icon md-icon"></span> Projects </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Others/Scarecrow/ class=md-nav__link> Scarecrow </a> </li> <li class=md-nav__item> <a href=../../Others/bid%20allocation%20model/ class=md-nav__link> Bid Allocation </a> </li> <li class=md-nav__item> <a href=../../Others/IIMB%20project/ class=md-nav__link> Reward and Recognition contests </a> </li> <li class=md-nav__item> <a href=../../Others/supply%20chain%20analytics/ class=md-nav__link> Supply chain analytics </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#predicting-absenteeism class=md-nav__link> Predicting absenteeism </a> </li> <li class=md-nav__item> <a href=#base-model class=md-nav__link> Base model </a> </li> <li class=md-nav__item> <a href=#decision-tree-classifier class=md-nav__link> Decision Tree Classifier </a> <nav class=md-nav aria-label="Decision Tree Classifier"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#downsampling class=md-nav__link> Downsampling </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#multiple-models class=md-nav__link> Multiple models </a> </li> <li class=md-nav__item> <a href=#predictions class=md-nav__link> Predictions </a> </li> <li class=md-nav__item> <a href=#save-models class=md-nav__link> Save Models </a> </li> <li class=md-nav__item> <a href=#references class=md-nav__link> References </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=ml-using-scikit-learn>ML using scikit learn<a class=headerlink href=#ml-using-scikit-learn title="Permanent link">&para;</a></h1> <h2 id=predicting-absenteeism>Predicting absenteeism<a class=headerlink href=#predicting-absenteeism title="Permanent link">&para;</a></h2> <p>A large problem within organisations is how to motivate their employees. This is a continuation of the <a href="../Machine Learning Part 1">previous blog</a> where we went through various feature engineering methods to come up with a comprehensive dataset. In this blog, we will use this data in order to predict employment absenteeism. The goal is to identify who are likely to be absent in the near future. This blog doesn't go through the machine learning concepts, or business logic, but implementation of machine learning using <em>scikit-learn</em> package in python. </p> <p>As a first step, let us load and look at the data.</p> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>warnings</span>
<span class=n>warnings</span><span class=o>.</span><span class=n>filterwarnings</span><span class=p>(</span><span class=s1>&#39;ignore&#39;</span><span class=p>,</span> <span class=n>category</span><span class=o>=</span><span class=ne>FutureWarning</span><span class=p>)</span>

<span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
<span class=kn>import</span> <span class=nn>seaborn</span> <span class=k>as</span> <span class=nn>sns</span>
<span class=kn>import</span> <span class=nn>plotly.express</span> <span class=k>as</span> <span class=nn>px</span>
<span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
<span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
<span class=o>%</span><span class=n>matplotlib</span> <span class=n>inline</span> 
</code></pre></div> <div class=highlight><pre><span></span><code><span class=n>pd</span><span class=o>.</span><span class=n>set_option</span><span class=p>(</span><span class=s1>&#39;display.max_columns&#39;</span><span class=p>,</span> <span class=kc>None</span><span class=p>)</span>

<span class=n>df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s2>&quot;data_after_feature_engg.csv&quot;</span><span class=p>)</span>
<span class=n>df</span><span class=p>[</span><span class=s1>&#39;date&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>to_datetime</span><span class=p>(</span><span class=n>df</span><span class=o>.</span><span class=n>date</span><span class=p>)</span>
<span class=n>df</span><span class=o>.</span><span class=n>head</span><span class=p>()</span>
</code></pre></div> <div> <style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style> <table border=1 class=dataframe> <thead> <tr style="text-align: right;"> <th></th> <th>employee</th> <th>date</th> <th>last_likes</th> <th>last_dislikes</th> <th>feedbackType</th> <th>likes_till_date</th> <th>dislikes_till_date</th> <th>last_2_likes</th> <th>last_2_dislikes</th> <th>days_since_last_comment</th> <th>last_vote</th> <th>timezone</th> <th>stillExists</th> <th>no_of_days_since_first_vote</th> <th>no_of_votes_till_date</th> <th>perc_days_voted</th> <th>avg_vote_till_date</th> <th>avg_vote</th> <th>last_2_votes_avg</th> <th>days_since_last_vote</th> <th>employee_joined_after_jun17</th> <th>countdown_to_last_day</th> <th>reason</th> <th>on_leave</th> <th>no_leaves_till_date</th> <th>last_2_days_leaves</th> <th>previous_day_leave</th> <th>weekday</th> <th>month</th> <th>day</th> <th>week</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>17r</td> <td>2018-05-29</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>3</td> <td>Europe/Madrid</td> <td>1</td> <td>1</td> <td>1</td> <td>1.0</td> <td>3.0</td> <td>2.121212</td> <td>3.0</td> <td>0</td> <td>1</td> <td>999</td> <td>NaN</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>Tuesday</td> <td>May</td> <td>29</td> <td>1</td> </tr> <tr> <th>1</th> <td>17r</td> <td>2018-05-30</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>3</td> <td>Europe/Madrid</td> <td>1</td> <td>1</td> <td>1</td> <td>1.0</td> <td>3.0</td> <td>2.121212</td> <td>3.0</td> <td>0</td> <td>1</td> <td>999</td> <td>NaN</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>Wednesday</td> <td>May</td> <td>30</td> <td>2</td> </tr> <tr> <th>2</th> <td>17r</td> <td>2018-05-31</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>3</td> <td>Europe/Madrid</td> <td>1</td> <td>2</td> <td>1</td> <td>1.0</td> <td>3.0</td> <td>2.121212</td> <td>3.0</td> <td>1</td> <td>1</td> <td>999</td> <td>NaN</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>Thursday</td> <td>May</td> <td>31</td> <td>3</td> </tr> <tr> <th>3</th> <td>17r</td> <td>2018-01-06</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>3</td> <td>Europe/Madrid</td> <td>1</td> <td>3</td> <td>2</td> <td>0.5</td> <td>3.0</td> <td>2.121212</td> <td>3.0</td> <td>0</td> <td>1</td> <td>999</td> <td>NaN</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>Friday</td> <td>Jun</td> <td>1</td> <td>1</td> </tr> <tr> <th>4</th> <td>17r</td> <td>2018-02-06</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>3</td> <td>Europe/Madrid</td> <td>1</td> <td>4</td> <td>2</td> <td>0.5</td> <td>3.0</td> <td>2.121212</td> <td>3.0</td> <td>0</td> <td>1</td> <td>999</td> <td>NaN</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>Saturday</td> <td>Jun</td> <td>2</td> <td>2</td> </tr> </tbody> </table> </div> <h2 id=base-model>Base model<a class=headerlink href=#base-model title="Permanent link">&para;</a></h2> <p>This data is at an employee-day level, and we can predict if any employee will take leave on any particular date. As very few employees take leave on any particular day, we will have a highly imbalanced dataset.</p> <div class=highlight><pre><span></span><code><span class=mi>1</span><span class=o>-</span><span class=n>df</span><span class=o>.</span><span class=n>on_leave</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>
</code></pre></div> <div class=highlight><pre><span></span><code>0.9514513766404592
</code></pre></div> <p>This indicates that only 5% of the dataset contains information about employees taking leaves. This means that if we predicted that all the employees are not taking a leave (class 0), we would be 95% accurate, but such prediction is not useful. This is the base model, and we need to see to it that we have accuracy greater than 95%.</p> <h2 id=decision-tree-classifier>Decision Tree Classifier<a class=headerlink href=#decision-tree-classifier title="Permanent link">&para;</a></h2> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>sklearn.tree</span> <span class=kn>import</span> <span class=n>DecisionTreeClassifier</span><span class=p>,</span> <span class=n>plot_tree</span>
<span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>train_test_split</span><span class=p>,</span> <span class=n>GridSearchCV</span>
<span class=kn>from</span> <span class=nn>sklearn.metrics</span> <span class=kn>import</span> <span class=n>classification_report</span><span class=p>,</span> <span class=n>plot_confusion_matrix</span><span class=p>,</span> <span class=n>confusion_matrix</span><span class=p>,</span> <span class=n>accuracy_score</span><span class=p>,</span> <span class=n>roc_curve</span><span class=p>,</span> <span class=n>roc_auc_score</span>
</code></pre></div> <p>From the different features that we have created, we are selecting what we think will be relevant features for predicting which employee might be absent.</p> <div class=highlight><pre><span></span><code><span class=n>indep_vars</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;last_likes&#39;</span><span class=p>,</span> <span class=s1>&#39;last_dislikes&#39;</span><span class=p>,</span> <span class=s1>&#39;feedbackType&#39;</span><span class=p>,</span> 
     <span class=s1>&#39;likes_till_date&#39;</span><span class=p>,</span> <span class=s1>&#39;dislikes_till_date&#39;</span><span class=p>,</span> <span class=s1>&#39;last_2_likes&#39;</span><span class=p>,</span> <span class=s1>&#39;last_2_dislikes&#39;</span><span class=p>,</span> 
     <span class=s1>&#39;days_since_last_comment&#39;</span><span class=p>,</span> <span class=s1>&#39;last_vote&#39;</span><span class=p>,</span> <span class=s1>&#39;timezone&#39;</span><span class=p>,</span> <span class=s1>&#39;stillExists&#39;</span><span class=p>,</span>
       <span class=s1>&#39;no_of_days_since_first_vote&#39;</span><span class=p>,</span> <span class=s1>&#39;no_of_votes_till_date&#39;</span><span class=p>,</span>
       <span class=s1>&#39;perc_days_voted&#39;</span><span class=p>,</span> <span class=s1>&#39;avg_vote_till_date&#39;</span><span class=p>,</span> <span class=s1>&#39;avg_vote&#39;</span><span class=p>,</span> <span class=s1>&#39;last_2_votes_avg&#39;</span><span class=p>,</span>
       <span class=s1>&#39;days_since_last_vote&#39;</span><span class=p>,</span> <span class=s1>&#39;employee_joined_after_jun17&#39;</span><span class=p>,</span> <span class=s1>&#39;countdown_to_last_day&#39;</span><span class=p>,</span>
        <span class=s1>&#39;no_leaves_till_date&#39;</span><span class=p>,</span> <span class=s1>&#39;weekday&#39;</span><span class=p>,</span> <span class=s1>&#39;month&#39;</span><span class=p>]</span>
</code></pre></div> <p>The dependent variable is <em>on_leave</em>. We are also creating dummy variables that represent categorical data.</p> <div class=highlight><pre><span></span><code><span class=n>data_targets</span> <span class=o>=</span> <span class=n>df</span><span class=p>[</span><span class=s1>&#39;on_leave&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=s1>&#39;int&#39;</span><span class=p>)</span>
<span class=n>data_features</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>get_dummies</span><span class=p>(</span><span class=n>df</span><span class=p>[</span><span class=n>indep_vars</span><span class=p>],</span> <span class=n>prefix</span> <span class=o>=</span> <span class=s2>&quot;_&quot;</span><span class=p>,</span> <span class=n>drop_first</span><span class=o>=</span> <span class=kc>True</span><span class=p>)</span>
</code></pre></div> <p>To prevent overfitting, we are splitting the data into test data and train data. Test data has 30% of the data (selected randomly) while the train data has the remaining 70% on which we train the model. This model is tested against the test data to validate for overfitting.</p> <div class=highlight><pre><span></span><code><span class=n>x_train</span><span class=p>,</span> <span class=n>x_test</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>y_test</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span><span class=n>data_features</span><span class=p>,</span> <span class=n>data_targets</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>.30</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>35</span><span class=p>,</span> \
                                                    <span class=n>stratify</span><span class=o>=</span><span class=n>data_targets</span><span class=p>)</span>
</code></pre></div> <p>Before building an ensemble of models, we can build a decision tree model and understand if the features we have selected perform the classification reasonably.</p> <div class=highlight><pre><span></span><code><span class=n>tree_clf</span> <span class=o>=</span> <span class=n>DecisionTreeClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>35</span><span class=p>,</span> <span class=n>max_depth</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>class_weight</span><span class=o>=</span><span class=s2>&quot;balanced&quot;</span><span class=p>)</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>x_train</span><span class=p>,</span><span class=n>y_train</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=k>def</span> <span class=nf>plot_feature_importance</span><span class=p>(</span><span class=n>model</span><span class=p>):</span>
    <span class=n>fs</span><span class=p>,</span> <span class=n>ax</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>20</span><span class=p>,</span><span class=mi>10</span><span class=p>))</span>
    <span class=n>number_of_features</span> <span class=o>=</span> <span class=n>x_train</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>barh</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=n>number_of_features</span><span class=p>),</span> <span class=n>model</span><span class=o>.</span><span class=n>feature_importances_</span><span class=p>,</span> <span class=n>align</span><span class=o>=</span><span class=s1>&#39;center&#39;</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>yticks</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>number_of_features</span><span class=p>),</span><span class=n>x_train</span><span class=o>.</span><span class=n>columns</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s2>&quot;Feature Importance&quot;</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s2>&quot;Feature&quot;</span><span class=p>)</span>
<span class=n>plot_feature_importance</span><span class=p>(</span><span class=n>tree_clf</span><span class=p>)</span>
</code></pre></div> <p><img alt=png src=output_15_0.png></p> <div class=highlight><pre><span></span><code><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>20</span><span class=p>,</span><span class=mi>20</span><span class=p>))</span>
<span class=n>plot_tree</span><span class=p>(</span><span class=n>tree_clf</span><span class=p>,</span>  <span class=n>fontsize</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>feature_names</span> <span class=o>=</span> <span class=n>x_train</span><span class=o>.</span><span class=n>columns</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <p><img alt=png src=output_16_0.png></p> <p>We can observe that the features that are important make reasonable sense. 1. <em>Number of leaves till date</em>: The number of leaves that an employee has taken already will affect the future leaves that a person would take 2. <em>number of days since first vote</em> (proxy to the employee tenure), <em>employee_joined_after_Jun17</em> (proxy to newer employees) are significant, and we have seen these trends in the visualizations in the <a href=../Machine%20Learning%20Part%201/#feature-engineering>feature engineering section</a> 3. As seen in the <a href=../Machine%20Learning%20Part%201/#employee-absenteeism-dataset>visualisations</a>, employees took leaves during months like <em>June</em> and <em>October</em> which have come up as significant in the analysis</p> <p>We can see the model is not overfit with similar accuracy across test and train datasets. The confusion matrix is plotted below:</p> <div class=highlight><pre><span></span><code><span class=n>plt</span><span class=o>.</span><span class=n>rcParams</span><span class=p>[</span><span class=s2>&quot;figure.figsize&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>5</span><span class=p>)</span>
<span class=n>plot_confusion_matrix</span><span class=p>(</span><span class=n>tree_clf</span><span class=p>,</span> <span class=n>x_test</span><span class=p>,</span> <span class=n>y_test</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Accuracy on train data is&#39;</span><span class=p>,</span> <span class=nb>round</span><span class=p>(</span><span class=n>tree_clf</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>x_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>),</span><span class=mi>2</span><span class=p>))</span>
<span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Accuracy on test data is&#39;</span><span class=p>,</span> <span class=nb>round</span><span class=p>(</span><span class=n>tree_clf</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>x_test</span><span class=p>,</span> <span class=n>y_test</span><span class=p>),</span><span class=mi>2</span><span class=p>))</span>
</code></pre></div> <div class=highlight><pre><span></span><code>Accuracy on train data is 0.81
Accuracy on test data is 0.81
</code></pre></div> <p><img alt=png src=output_18_1.png></p> <div class=highlight><pre><span></span><code><span class=n>y_test_pred</span> <span class=o>=</span> <span class=n>tree_clf</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>x_test</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>classification_report</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_test_pred</span><span class=p>))</span>
</code></pre></div> <div class=highlight><pre><span></span><code>              precision    recall  f1-score   support

           0       1.00      0.80      0.89      9549
           1       0.20      0.98      0.34       487

    accuracy                           0.81     10036
   macro avg       0.60      0.89      0.61     10036
weighted avg       0.96      0.81      0.86     10036
</code></pre></div> <p>We can observe that the precision is just 20% (on classifying when an employee will take a leave). This is due to imbalance of classes. This can be rectified by many ways, one of which includes under-sampling. For other methods, <a href=../../R/handling-imbalanced-classes/ >refer the blog on handling imbalanced classes</a>. We are also using GridSearch to find the best tuning parameters and n-fold cross validation. </p> <h3 id=downsampling>Downsampling<a class=headerlink href=#downsampling title="Permanent link">&para;</a></h3> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>imblearn.pipeline</span> <span class=kn>import</span> <span class=n>Pipeline</span><span class=p>,</span> <span class=n>make_pipeline</span>
<span class=kn>from</span> <span class=nn>imblearn.under_sampling</span> <span class=kn>import</span> <span class=n>RandomUnderSampler</span>
<span class=n>param_grid_dt</span> <span class=o>=</span> <span class=p>{</span>
    <span class=s1>&#39;classification__criterion&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;gini&#39;</span><span class=p>,</span> <span class=s1>&#39;entropy&#39;</span><span class=p>],</span>
    <span class=s1>&#39;classification__max_depth&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mi>2</span><span class=p>,</span><span class=mi>5</span><span class=p>,</span><span class=mi>10</span><span class=p>],</span>
    <span class=s1>&#39;classification__max_features&#39;</span><span class=p>:[</span><span class=mf>0.2</span><span class=p>,</span> <span class=mf>0.5</span><span class=p>,</span> <span class=mf>0.8</span><span class=p>]</span>
<span class=p>}</span>
<span class=n>model_dt_p</span> <span class=o>=</span> <span class=n>Pipeline</span><span class=p>([</span>
    <span class=p>(</span><span class=s1>&#39;sampling&#39;</span><span class=p>,</span> <span class=n>RandomUnderSampler</span><span class=p>()),</span> <span class=c1># While training, downsample the majority class randomly</span>
    <span class=p>(</span><span class=s1>&#39;classification&#39;</span><span class=p>,</span> <span class=n>DecisionTreeClassifier</span><span class=p>())</span> <span class=c1># Train and predict using rf classification model</span>
    <span class=p>])</span>
<span class=n>model_dt</span> <span class=o>=</span> <span class=n>GridSearchCV</span><span class=p>(</span><span class=n>model_dt_p</span><span class=p>,</span> <span class=n>param_grid_dt</span><span class=p>,</span> <span class=n>cv</span><span class=o>=</span><span class=mi>5</span><span class=p>)</span>
<span class=n>model_dt</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>x_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>GridSearchCV(cv=5,
             estimator=Pipeline(steps=[(&#39;sampling&#39;, RandomUnderSampler()),
                                       (&#39;classification&#39;,
                                        DecisionTreeClassifier())]),
             param_grid={&#39;classification__criterion&#39;: [&#39;gini&#39;, &#39;entropy&#39;],
                         &#39;classification__max_depth&#39;: [2, 5, 10],
                         &#39;classification__max_features&#39;: [0.2, 0.5, 0.8]})
</code></pre></div> <div class=highlight><pre><span></span><code><span class=n>y_test_pred</span> <span class=o>=</span> <span class=n>model_dt</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>x_test</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>classification_report</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_test_pred</span><span class=p>))</span>
<span class=n>plot_confusion_matrix</span><span class=p>(</span><span class=n>model_dt</span><span class=p>,</span> <span class=n>x_test</span><span class=p>,</span> <span class=n>y_test</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Accuracy on train data is&#39;</span><span class=p>,</span> <span class=nb>round</span><span class=p>(</span><span class=n>model_dt</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>x_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>),</span><span class=mi>2</span><span class=p>))</span>
<span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Accuracy on test data is&#39;</span><span class=p>,</span> <span class=nb>round</span><span class=p>(</span><span class=n>model_dt</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>x_test</span><span class=p>,</span> <span class=n>y_test</span><span class=p>),</span><span class=mi>2</span><span class=p>))</span>
</code></pre></div> <div class=highlight><pre><span></span><code>              precision    recall  f1-score   support

           0       1.00      0.96      0.98      9549
           1       0.54      0.98      0.69       487

    accuracy                           0.96     10036
   macro avg       0.77      0.97      0.84     10036
weighted avg       0.98      0.96      0.96     10036

Accuracy on train data is 0.96
Accuracy on test data is 0.96
</code></pre></div> <p><img alt=png src=output_22_1.png></p> <p>Here we observe that with a simple decision tree classifier, we already reach an accuracy above 95% (base accuracy) with good precision and recall values. This model is better than our base model. We could further improve it by using ensemble methods which we will look into later in the blog.</p> <div class=highlight><pre><span></span><code><span class=k>def</span> <span class=nf>print_stats</span><span class=p>(</span><span class=n>model</span><span class=p>):</span>
    <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Best params for the model&#39;</span><span class=p>,</span> <span class=n>model</span><span class=o>.</span><span class=n>best_params_</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Best score on the cross validation data&#39;</span><span class=p>,</span> <span class=nb>round</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>best_score_</span><span class=p>,</span> <span class=mi>2</span><span class=p>))</span>
    <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Accuracy on train data&#39;</span><span class=p>,</span> <span class=nb>round</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>x_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>),</span><span class=mi>2</span><span class=p>))</span>
    <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Accuracy on test data&#39;</span><span class=p>,</span> <span class=nb>round</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>x_test</span><span class=p>,</span> <span class=n>y_test</span><span class=p>),</span><span class=mi>2</span><span class=p>))</span>
<span class=n>print_stats</span><span class=p>(</span><span class=n>model_dt</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <div class=highlight><pre><span></span><code>Best params for the model {&#39;classification__criterion&#39;: &#39;entropy&#39;, &#39;classification__max_depth&#39;: 10, &#39;classification__max_features&#39;: 0.5}
Best score on the cross validation data 0.96
Accuracy on train data 0.96
Accuracy on test data 0.96
</code></pre></div> <div class=highlight><pre><span></span><code><span class=n>y_test_pred</span> <span class=o>=</span> <span class=n>model_dt</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>x_test</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>classification_report</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_test_pred</span><span class=p>))</span>
</code></pre></div> <div class=highlight><pre><span></span><code>              precision    recall  f1-score   support

           0       1.00      0.96      0.98      9549
           1       0.54      0.98      0.69       487

    accuracy                           0.96     10036
   macro avg       0.77      0.97      0.84     10036
weighted avg       0.98      0.96      0.96     10036
</code></pre></div> <h2 id=multiple-models>Multiple models<a class=headerlink href=#multiple-models title="Permanent link">&para;</a></h2> <p>After manually applying a few models, we can scale up to use grid search method to search for the best classifier and parameters in a quick and efficient manner. We can use Logistic Regression, Multinomial Naive Bayes, KNN Classifiers, Ensemble models and any model in the <a href=https://scikit-learn.org/stable/supervised_learning.html#supervised-learning>sklearn library</a>. </p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>sklearn.linear_model</span> <span class=kn>import</span> <span class=n>LogisticRegression</span>
<span class=kn>from</span> <span class=nn>sklearn.naive_bayes</span> <span class=kn>import</span> <span class=n>MultinomialNB</span>
<span class=kn>from</span> <span class=nn>sklearn.neighbors</span> <span class=kn>import</span> <span class=n>KNeighborsClassifier</span>
<span class=kn>from</span> <span class=nn>sklearn.ensemble</span> <span class=kn>import</span> <span class=n>RandomForestClassifier</span><span class=p>,</span><span class=n>GradientBoostingClassifier</span>
<span class=kn>from</span> <span class=nn>sklearn.pipeline</span> <span class=kn>import</span> <span class=n>Pipeline</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=c1># setting up models</span>

<span class=n>clf1</span> <span class=o>=</span> <span class=n>LogisticRegression</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>35</span><span class=p>)</span>
<span class=n>clf2</span> <span class=o>=</span> <span class=n>MultinomialNB</span><span class=p>()</span>
<span class=n>clf3</span> <span class=o>=</span> <span class=n>KNeighborsClassifier</span><span class=p>()</span>
<span class=n>clf4</span> <span class=o>=</span> <span class=n>DecisionTreeClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>35</span><span class=p>)</span>
<span class=n>clf5</span> <span class=o>=</span> <span class=n>RandomForestClassifier</span><span class=p>(</span><span class=n>random_state</span> <span class=o>=</span> <span class=mi>35</span><span class=p>)</span>
<span class=n>clf6</span> <span class=o>=</span> <span class=n>GradientBoostingClassifier</span><span class=p>(</span><span class=n>random_state</span> <span class=o>=</span> <span class=mi>35</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=c1># setting up hyperparameters </span>

<span class=c1># Hyperparameters for Logistic regression https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression</span>
<span class=n>hyperparam1</span> <span class=o>=</span> <span class=p>{}</span>
<span class=n>hyperparam1</span><span class=p>[</span><span class=s1>&#39;classifier__C&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=p>[</span><span class=mi>10</span><span class=o>**-</span><span class=mi>4</span><span class=p>,</span> <span class=mi>10</span><span class=o>**-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>10</span><span class=o>**</span><span class=mi>0</span><span class=p>]</span> <span class=c1># The hyper-parameter is C and its inside &#39;classifier&#39; part of pipeline</span>
<span class=n>hyperparam1</span><span class=p>[</span><span class=s1>&#39;classifier__penalty&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;l1&#39;</span><span class=p>,</span> <span class=s1>&#39;l2&#39;</span><span class=p>]</span> <span class=c1># The hyper-parameter is penalty and its inside &#39;classifier&#39; part of pipeline</span>
<span class=n>hyperparam1</span><span class=p>[</span><span class=s1>&#39;classifier__class_weight&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=p>[</span><span class=kc>None</span><span class=p>,</span> <span class=s1>&#39;balanced&#39;</span><span class=p>]</span>
<span class=n>hyperparam1</span><span class=p>[</span><span class=s1>&#39;classifier&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=p>[</span><span class=n>clf1</span><span class=p>]</span>

<span class=c1># Hyperparameters for Naive Bayes</span>
<span class=n>hyperparam2</span> <span class=o>=</span> <span class=p>{}</span>
<span class=n>hyperparam2</span><span class=p>[</span><span class=s1>&#39;classifier__alpha&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=p>[</span><span class=mi>10</span><span class=o>**</span><span class=mi>0</span><span class=p>,</span><span class=mi>10</span><span class=o>**</span><span class=mi>4</span><span class=p>]</span>
<span class=n>hyperparam2</span><span class=p>[</span><span class=s1>&#39;classifier&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=p>[</span><span class=n>clf2</span><span class=p>]</span>

<span class=c1># Hyperparameters for KNN</span>
<span class=n>hyperparam3</span> <span class=o>=</span> <span class=p>{}</span>
<span class=n>hyperparam3</span><span class=p>[</span><span class=s1>&#39;classifier__n_neighbors&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=p>[</span><span class=mi>2</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>10</span><span class=p>]</span>
<span class=n>hyperparam3</span><span class=p>[</span><span class=s1>&#39;classifier&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=p>[</span><span class=n>clf3</span><span class=p>]</span>

<span class=c1># Hyperparameters for Decision Trees</span>
<span class=n>hyperparam4</span> <span class=o>=</span> <span class=p>{}</span>
<span class=n>hyperparam4</span><span class=p>[</span><span class=s1>&#39;classifier__max_depth&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=p>[</span><span class=mi>2</span><span class=p>,</span><span class=mi>5</span><span class=p>,</span><span class=mi>10</span><span class=p>,</span> <span class=kc>None</span><span class=p>]</span>
<span class=n>hyperparam4</span><span class=p>[</span><span class=s1>&#39;classifier__min_samples_split&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=p>[</span><span class=mi>2</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>10</span><span class=p>]</span>
<span class=n>hyperparam4</span><span class=p>[</span><span class=s1>&#39;classifier__class_weight&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=p>[</span><span class=kc>None</span><span class=p>,</span> <span class=s1>&#39;balanced&#39;</span><span class=p>]</span>
<span class=n>hyperparam4</span><span class=p>[</span><span class=s1>&#39;classifier&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=p>[</span><span class=n>clf4</span><span class=p>]</span>

<span class=c1># Hyperparameters for Random Forest</span>
<span class=n>hyperparam5</span> <span class=o>=</span> <span class=p>{}</span>
<span class=n>hyperparam5</span><span class=p>[</span><span class=s1>&#39;classifier__n_estimators&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=p>[</span><span class=mi>100</span><span class=p>,</span> <span class=mi>250</span><span class=p>]</span>
<span class=n>hyperparam5</span><span class=p>[</span><span class=s1>&#39;classifier__max_depth&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=p>[</span><span class=mi>2</span><span class=p>,</span><span class=mi>5</span><span class=p>,</span><span class=mi>10</span><span class=p>]</span>
<span class=n>hyperparam5</span><span class=p>[</span><span class=s1>&#39;classifier__class_weight&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=p>[</span><span class=kc>None</span><span class=p>,</span> <span class=s1>&#39;balanced&#39;</span><span class=p>]</span>
<span class=n>hyperparam5</span><span class=p>[</span><span class=s1>&#39;classifier&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=p>[</span><span class=n>clf5</span><span class=p>]</span>

<span class=c1># Hyperparameters for Gradient Boosting</span>
<span class=n>hyperparam6</span> <span class=o>=</span> <span class=p>{}</span>
<span class=n>hyperparam6</span><span class=p>[</span><span class=s1>&#39;classifier__n_estimators&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=p>[</span><span class=mi>100</span><span class=p>,</span> <span class=mi>250</span><span class=p>]</span>
<span class=n>hyperparam6</span><span class=p>[</span><span class=s1>&#39;classifier__max_depth&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=p>[</span><span class=mi>2</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>10</span><span class=p>]</span>
<span class=n>hyperparam6</span><span class=p>[</span><span class=s1>&#39;classifier__min_samples_split&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=p>[</span><span class=mi>2</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>10</span><span class=p>]</span>
<span class=n>hyperparam6</span><span class=p>[</span><span class=s1>&#39;classifier&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=p>[</span><span class=n>clf6</span><span class=p>]</span>

<span class=n>pipe</span> <span class=o>=</span> <span class=n>Pipeline</span><span class=p>([(</span><span class=s1>&#39;classifier&#39;</span><span class=p>,</span><span class=n>clf1</span><span class=p>)])</span>
<span class=n>hyperparam_total</span> <span class=o>=</span> <span class=p>[</span><span class=n>hyperparam1</span><span class=p>,</span> <span class=n>hyperparam2</span><span class=p>,</span> <span class=n>hyperparam3</span><span class=p>,</span> <span class=n>hyperparam4</span><span class=p>,</span> <span class=n>hyperparam5</span><span class=p>,</span> <span class=n>hyperparam6</span><span class=p>]</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=o>%%</span><span class=n>time</span>
<span class=c1># Record how long the search takes</span>

<span class=c1># Train the grid search model</span>
<span class=n>model_grid_search</span> <span class=o>=</span> <span class=n>GridSearchCV</span><span class=p>(</span><span class=n>pipe</span><span class=p>,</span> <span class=n>hyperparam_total</span><span class=p>,</span> <span class=n>cv</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>,</span> <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;roc_auc&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>x_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>C:\ProgramData\Anaconda3\lib\site-packages\sklearn\model_selection\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.76530486        nan 0.78573417        nan 0.76227159
        nan 0.81272732        nan 0.7669747         nan 0.81235721
        nan        nan 0.9792672  0.98689225 0.98684304 0.80196935
 0.80196935 0.80196935 0.9807685  0.9807685  0.98227199 0.974107
 0.97684471 0.98018112 0.96721555 0.9697727  0.97256904 0.87247414
 0.87247414 0.87247414 0.95249357 0.95249357 0.95249357 0.96331177
 0.96410843 0.96467699 0.96485967 0.96883658 0.97032722 0.96982298
 0.96802826 0.99322296 0.99325364 0.99761825 0.99778465 0.96814859
 0.97048243 0.98832118 0.98900645 0.9941528  0.99483174 0.99417744
 0.99651075 0.99417744 0.99651075 0.99417744 0.99651075 0.99771714
 0.99782095 0.99764383 0.99792168 0.99770636 0.99797557 0.99532432
 0.99816234 0.99575252 0.99821671 0.99738392 0.99794075]
  warnings.warn(


Wall time: 22min 59s
</code></pre></div> <div class=highlight><pre><span></span><code><span class=c1># Output the best estimator which is a random forecast classifier </span>
<span class=n>model_grid_search</span><span class=o>.</span><span class=n>best_estimator_</span>
</code></pre></div> <div class=highlight><pre><span></span><code>Pipeline(steps=[(&#39;classifier&#39;,
                 GradientBoostingClassifier(max_depth=10, min_samples_split=5,
                                            n_estimators=250,
                                            random_state=35))])
</code></pre></div> <p>After running grid search to find the best parameters and models, we find the best model to be Gradient Boosting with the best parameters below.</p> <div class=highlight><pre><span></span><code><span class=c1># Output the parameters in the best estimator</span>
<span class=n>model_grid_search</span><span class=o>.</span><span class=n>best_params_</span>
</code></pre></div> <div class=highlight><pre><span></span><code>{&#39;classifier&#39;: GradientBoostingClassifier(max_depth=10, min_samples_split=5, n_estimators=250,
                            random_state=35),
 &#39;classifier__max_depth&#39;: 10,
 &#39;classifier__min_samples_split&#39;: 5,
 &#39;classifier__n_estimators&#39;: 250}
</code></pre></div> <p>The accuracy on the cross validated data close to 99%.</p> <div class=highlight><pre><span></span><code><span class=nb>round</span><span class=p>(</span><span class=n>model_grid_search</span><span class=o>.</span><span class=n>best_score_</span><span class=p>,</span> <span class=mi>4</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>0.9982
</code></pre></div> <p>On the test data also, we have a near perfect precision, recall and accuracy.</p> <div class=highlight><pre><span></span><code><span class=n>y_test_pred</span> <span class=o>=</span> <span class=n>model_grid_search</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>x_test</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>classification_report</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_test_pred</span><span class=p>))</span>
</code></pre></div> <div class=highlight><pre><span></span><code>              precision    recall  f1-score   support

           0       1.00      1.00      1.00      9549
           1       0.99      0.96      0.97       487

    accuracy                           1.00     10036
   macro avg       0.99      0.98      0.99     10036
weighted avg       1.00      1.00      1.00     10036
</code></pre></div> <div class=highlight><pre><span></span><code><span class=n>plot_confusion_matrix</span><span class=p>(</span><span class=n>model_grid_search</span><span class=p>,</span> <span class=n>x_test</span><span class=p>,</span> <span class=n>y_test</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <p><img alt=png src=output_38_0.png></p> <p>The features that are used and their importances in the model is:</p> <div class=highlight><pre><span></span><code><span class=k>def</span> <span class=nf>print_most_imp_features</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>data_features</span><span class=p>):</span>
    <span class=n>feat_imp_df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>({</span><span class=s1>&#39;columns&#39;</span> <span class=p>:</span> <span class=n>data_features</span><span class=o>.</span><span class=n>columns</span><span class=p>,</span> <span class=s1>&#39;importance&#39;</span><span class=p>:(</span><span class=n>model</span><span class=o>.</span><span class=n>best_estimator_</span><span class=o>.</span><span class=n>named_steps</span><span class=p>[</span><span class=s2>&quot;classifier&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>feature_importances_</span><span class=o>*</span><span class=mi>100</span><span class=p>)</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=nb>int</span><span class=p>)})</span>
    <span class=k>return</span> <span class=n>feat_imp_df</span><span class=p>[</span><span class=n>feat_imp_df</span><span class=o>.</span><span class=n>importance</span><span class=o>&gt;</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>sort_values</span><span class=p>(</span><span class=s1>&#39;importance&#39;</span><span class=p>,</span> <span class=n>ascending</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
<span class=n>print_most_imp_features</span><span class=p>(</span><span class=n>model_grid_search</span><span class=p>,</span> <span class=n>data_features</span><span class=p>)</span>
</code></pre></div> <div> <style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style> <table border=1 class=dataframe> <thead> <tr style="text-align: right;"> <th></th> <th>columns</th> <th>importance</th> </tr> </thead> <tbody> <tr> <th>18</th> <td>no_leaves_till_date</td> <td>28</td> </tr> <tr> <th>9</th> <td>no_of_days_since_first_vote</td> <td>25</td> </tr> <tr> <th>32</th> <td>__Aug</td> <td>8</td> </tr> <tr> <th>41</th> <td>__Oct</td> <td>7</td> </tr> <tr> <th>37</th> <td>__Jun</td> <td>6</td> </tr> <tr> <th>12</th> <td>avg_vote_till_date</td> <td>5</td> </tr> <tr> <th>11</th> <td>perc_days_voted</td> <td>3</td> </tr> <tr> <th>13</th> <td>avg_vote</td> <td>3</td> </tr> <tr> <th>5</th> <td>last_2_dislikes</td> <td>2</td> </tr> <tr> <th>3</th> <td>dislikes_till_date</td> <td>1</td> </tr> <tr> <th>6</th> <td>days_since_last_comment</td> <td>1</td> </tr> <tr> <th>10</th> <td>no_of_votes_till_date</td> <td>1</td> </tr> </tbody> </table> </div> <div class=highlight><pre><span></span><code><span class=k>def</span> <span class=nf>plot_roc_curve</span><span class=p>(</span><span class=n>fpr</span><span class=p>,</span> <span class=n>tpr</span><span class=p>,</span> <span class=n>auc</span><span class=p>):</span>
    <span class=n>fig</span><span class=p>,</span> <span class=n>ax</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>()</span>
    <span class=n>ax</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>fpr</span><span class=p>,</span> <span class=n>tpr</span><span class=p>)</span>
    <span class=n>ax</span><span class=o>.</span><span class=n>set</span><span class=p>(</span><span class=n>xlabel</span><span class=o>=</span><span class=s1>&#39;False Positive Rate&#39;</span><span class=p>,</span> <span class=n>ylabel</span><span class=o>=</span><span class=s1>&#39;True Positive Rate&#39;</span><span class=p>)</span>
    <span class=n>ax</span><span class=o>.</span><span class=n>grid</span><span class=p>()</span>
    <span class=n>ax</span><span class=o>.</span><span class=n>text</span><span class=p>(</span><span class=mf>0.6</span><span class=p>,</span> <span class=mf>0.3</span><span class=p>,</span> <span class=s1>&#39;ROC AUC Score: </span><span class=si>{:.3f}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>auc</span><span class=p>),</span>
            <span class=n>bbox</span><span class=o>=</span><span class=nb>dict</span><span class=p>(</span><span class=n>boxstyle</span><span class=o>=</span><span class=s1>&#39;square,pad=0.3&#39;</span><span class=p>,</span> <span class=n>fc</span><span class=o>=</span><span class=s1>&#39;white&#39;</span><span class=p>,</span> <span class=n>ec</span><span class=o>=</span><span class=s1>&#39;k&#39;</span><span class=p>))</span>
    <span class=n>lims</span> <span class=o>=</span> <span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>min</span><span class=p>([</span><span class=n>ax</span><span class=o>.</span><span class=n>get_xlim</span><span class=p>(),</span> <span class=n>ax</span><span class=o>.</span><span class=n>get_ylim</span><span class=p>()]),</span> <span class=n>np</span><span class=o>.</span><span class=n>max</span><span class=p>([</span><span class=n>ax</span><span class=o>.</span><span class=n>get_xlim</span><span class=p>(),</span> <span class=n>ax</span><span class=o>.</span><span class=n>get_ylim</span><span class=p>()])]</span>
    <span class=n>ax</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>lims</span><span class=p>,</span> <span class=n>lims</span><span class=p>,</span> <span class=s1>&#39;k--&#39;</span><span class=p>)</span>
    <span class=n>ax</span><span class=o>.</span><span class=n>set_xlim</span><span class=p>(</span><span class=n>lims</span><span class=p>)</span>
    <span class=n>ax</span><span class=o>.</span><span class=n>set_ylim</span><span class=p>(</span><span class=n>lims</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;ROC curve&#39;</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=n>auc</span> <span class=o>=</span> <span class=n>roc_auc_score</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_test_pred</span><span class=p>)</span>
<span class=n>fpr</span><span class=p>,</span> <span class=n>tpr</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>roc_curve</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_test_pred</span><span class=p>)</span>
<span class=n>plot_roc_curve</span><span class=p>(</span><span class=n>fpr</span><span class=p>,</span> <span class=n>tpr</span><span class=p>,</span> <span class=n>auc</span><span class=p>)</span>
</code></pre></div> <p><img alt=png src=output_42_0.png></p> <h2 id=predictions>Predictions<a class=headerlink href=#predictions title="Permanent link">&para;</a></h2> <p>Using this model, we can predict who is going to be absent in the next few days. </p> <div class=highlight><pre><span></span><code><span class=n>next_day_df</span> <span class=o>=</span> <span class=n>df</span><span class=p>[</span><span class=n>df</span><span class=o>.</span><span class=n>date</span> <span class=o>==</span> <span class=nb>max</span><span class=p>(</span><span class=n>df</span><span class=o>.</span><span class=n>date</span><span class=p>)]</span><span class=o>.</span><span class=n>reset_index</span><span class=p>()</span>
<span class=n>next_day_df</span><span class=o>.</span><span class=n>no_of_days_since_first_vote</span> <span class=o>+=</span> <span class=mi>1</span>
<span class=n>next_day_df</span><span class=o>.</span><span class=n>days_since_last_vote</span> <span class=o>+=</span> <span class=mi>1</span>

<span class=n>day_name</span><span class=o>=</span> <span class=p>[</span><span class=s1>&#39;Monday&#39;</span><span class=p>,</span> <span class=s1>&#39;Tuesday&#39;</span><span class=p>,</span> <span class=s1>&#39;Wednesday&#39;</span><span class=p>,</span> <span class=s1>&#39;Thursday&#39;</span><span class=p>,</span> <span class=s1>&#39;Friday&#39;</span><span class=p>,</span> <span class=s1>&#39;Saturday&#39;</span><span class=p>,</span><span class=s1>&#39;Sunday&#39;</span><span class=p>]</span>
<span class=n>month_name</span> <span class=o>=</span> <span class=p>[</span><span class=kc>None</span><span class=p>,</span> <span class=s1>&#39;Jan&#39;</span><span class=p>,</span> <span class=s1>&#39;Feb&#39;</span><span class=p>,</span> <span class=s1>&#39;Mar&#39;</span><span class=p>,</span> <span class=s1>&#39;Apr&#39;</span><span class=p>,</span> <span class=s1>&#39;May&#39;</span><span class=p>,</span> <span class=s1>&#39;Jun&#39;</span><span class=p>,</span> <span class=s1>&#39;Jul&#39;</span><span class=p>,</span> <span class=s1>&#39;Aug&#39;</span><span class=p>,</span> <span class=s1>&#39;Sep&#39;</span><span class=p>,</span> <span class=s1>&#39;Oct&#39;</span><span class=p>,</span> <span class=s1>&#39;Nov&#39;</span><span class=p>,</span> <span class=s1>&#39;Dec&#39;</span><span class=p>]</span>
<span class=n>next_day_df</span><span class=o>.</span><span class=n>date</span> <span class=o>=</span> <span class=n>next_day_df</span><span class=o>.</span><span class=n>date</span> <span class=o>+</span> <span class=n>pd</span><span class=o>.</span><span class=n>DateOffset</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
<span class=n>next_day_df</span><span class=p>[</span><span class=s1>&#39;weekday&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>next_day_df</span><span class=o>.</span><span class=n>date</span><span class=o>.</span><span class=n>dt</span><span class=o>.</span><span class=n>weekday</span><span class=o>.</span><span class=n>apply</span><span class=p>(</span><span class=k>lambda</span> <span class=n>x</span><span class=p>:</span><span class=n>day_name</span><span class=p>[</span><span class=n>x</span><span class=p>])</span>
<span class=n>next_day_df</span><span class=p>[</span><span class=s1>&#39;month&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>next_day_df</span><span class=o>.</span><span class=n>date</span><span class=o>.</span><span class=n>dt</span><span class=o>.</span><span class=n>month</span><span class=o>.</span><span class=n>apply</span><span class=p>(</span><span class=k>lambda</span> <span class=n>x</span><span class=p>:</span><span class=n>month_name</span><span class=p>[</span><span class=n>x</span><span class=p>])</span>
<span class=n>next_day_df</span><span class=p>[</span><span class=s1>&#39;week&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>next_day_df</span><span class=o>.</span><span class=n>date</span><span class=o>.</span><span class=n>dt</span><span class=o>.</span><span class=n>day</span>

<span class=c1># Handle catogorical variables</span>
<span class=n>next_day_df_predict</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>get_dummies</span><span class=p>(</span><span class=n>next_day_df</span><span class=p>[</span><span class=n>indep_vars</span><span class=p>],</span> <span class=n>prefix</span> <span class=o>=</span> <span class=s2>&quot;_&quot;</span><span class=p>)</span>
<span class=n>next_day_df_predict</span> <span class=o>=</span> <span class=n>next_day_df_predict</span><span class=o>.</span><span class=n>reindex</span><span class=p>(</span><span class=n>columns</span><span class=o>=</span><span class=n>x_train</span><span class=o>.</span><span class=n>columns</span><span class=p>,</span> <span class=n>fill_value</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>

<span class=n>prob_current</span> <span class=o>=</span> <span class=n>model_grid_search</span><span class=o>.</span><span class=n>predict_proba</span><span class=p>(</span><span class=n>next_day_df_predict</span><span class=p>)</span>
<span class=n>next_day_df</span><span class=p>[</span><span class=s1>&#39;leave_prob&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>prob_current</span><span class=p>[:,</span><span class=mi>1</span><span class=p>]</span>
</code></pre></div> <p>The top 5 employees who have the highest probability to be absent in the next day are:</p> <div class=highlight><pre><span></span><code><span class=n>next_day_df</span><span class=o>.</span><span class=n>sort_values</span><span class=p>(</span><span class=s1>&#39;leave_prob&#39;</span><span class=p>,</span> <span class=n>ascending</span> <span class=o>=</span> <span class=kc>False</span><span class=p>)</span><span class=o>.</span><span class=n>head</span><span class=p>(</span><span class=mi>5</span><span class=p>)</span>
</code></pre></div> <div> <style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style> <table border=1 class=dataframe> <thead> <tr style="text-align: right;"> <th></th> <th>index</th> <th>employee</th> <th>date</th> <th>last_likes</th> <th>last_dislikes</th> <th>feedbackType</th> <th>likes_till_date</th> <th>dislikes_till_date</th> <th>last_2_likes</th> <th>last_2_dislikes</th> <th>days_since_last_comment</th> <th>last_vote</th> <th>timezone</th> <th>stillExists</th> <th>no_of_days_since_first_vote</th> <th>no_of_votes_till_date</th> <th>perc_days_voted</th> <th>avg_vote_till_date</th> <th>avg_vote</th> <th>last_2_votes_avg</th> <th>days_since_last_vote</th> <th>employee_joined_after_jun17</th> <th>countdown_to_last_day</th> <th>reason</th> <th>on_leave</th> <th>no_leaves_till_date</th> <th>last_2_days_leaves</th> <th>previous_day_leave</th> <th>weekday</th> <th>month</th> <th>day</th> <th>week</th> <th>leave_prob</th> </tr> </thead> <tbody> <tr> <th>22</th> <td>13699</td> <td>DNY</td> <td>2019-12-03</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>3</td> <td>Europe/Madrid</td> <td>1</td> <td>651</td> <td>229</td> <td>0.352851</td> <td>2.934498</td> <td>2.936441</td> <td>3.0</td> <td>1</td> <td>0</td> <td>999</td> <td>NaN</td> <td>0</td> <td>2</td> <td>0</td> <td>0</td> <td>Tuesday</td> <td>Dec</td> <td>12</td> <td>3</td> <td>9.382249e-10</td> </tr> <tr> <th>34</th> <td>20478</td> <td>YDm</td> <td>2019-12-03</td> <td>19</td> <td>0</td> <td>CONGRATULATION</td> <td>523</td> <td>250</td> <td>34</td> <td>9</td> <td>42</td> <td>3</td> <td>Europe/Madrid</td> <td>1</td> <td>651</td> <td>537</td> <td>0.827427</td> <td>2.942272</td> <td>2.943636</td> <td>3.0</td> <td>1</td> <td>0</td> <td>999</td> <td>NaN</td> <td>0</td> <td>1</td> <td>0</td> <td>0</td> <td>Tuesday</td> <td>Dec</td> <td>12</td> <td>3</td> <td>7.326212e-10</td> </tr> <tr> <th>38</th> <td>22997</td> <td>aQJ</td> <td>2019-12-03</td> <td>8</td> <td>8</td> <td>INFORMATION</td> <td>237</td> <td>71</td> <td>56</td> <td>10</td> <td>163</td> <td>3</td> <td>Europe/Madrid</td> <td>1</td> <td>462</td> <td>139</td> <td>0.446945</td> <td>3.071942</td> <td>3.071942</td> <td>3.0</td> <td>151</td> <td>1</td> <td>999</td> <td>NaN</td> <td>0</td> <td>14</td> <td>0</td> <td>0</td> <td>Tuesday</td> <td>Dec</td> <td>12</td> <td>3</td> <td>5.486968e-10</td> </tr> <tr> <th>37</th> <td>22508</td> <td>aKP</td> <td>2019-12-03</td> <td>10</td> <td>23</td> <td>SUGGESTION</td> <td>482</td> <td>148</td> <td>51</td> <td>43</td> <td>58</td> <td>4</td> <td>Europe/Madrid</td> <td>1</td> <td>651</td> <td>103</td> <td>0.173693</td> <td>3.805825</td> <td>3.805825</td> <td>4.0</td> <td>57</td> <td>0</td> <td>999</td> <td>NaN</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>Tuesday</td> <td>Dec</td> <td>12</td> <td>3</td> <td>4.874565e-10</td> </tr> <tr> <th>12</th> <td>7723</td> <td>5WZ</td> <td>2019-12-03</td> <td>0</td> <td>0</td> <td>OTHER</td> <td>38</td> <td>7</td> <td>0</td> <td>0</td> <td>7</td> <td>3</td> <td>Europe/Berlin</td> <td>0</td> <td>646</td> <td>548</td> <td>0.849612</td> <td>2.958029</td> <td>2.959436</td> <td>3.0</td> <td>1</td> <td>0</td> <td>999</td> <td>NaN</td> <td>0</td> <td>31</td> <td>0</td> <td>0</td> <td>Tuesday</td> <td>Dec</td> <td>12</td> <td>3</td> <td>4.845051e-10</td> </tr> </tbody> </table> </div> <h2 id=save-models>Save Models<a class=headerlink href=#save-models title="Permanent link">&para;</a></h2> <p>The last step is to save models for future deployment or run. Scikit-learn models are usually saved as pickle files.</p> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>pickle</span>
<span class=c1># Dump the trained model with Pickle</span>
<span class=n>model_pkl_filename</span> <span class=o>=</span> <span class=s1>&#39;classifier_employee_absenteeism.pkl&#39;</span>
<span class=c1># Open the file to save as pkl file</span>
<span class=n>model_pkl</span> <span class=o>=</span> <span class=nb>open</span><span class=p>(</span><span class=n>model_pkl_filename</span><span class=p>,</span> <span class=s1>&#39;wb&#39;</span><span class=p>)</span>
<span class=n>pickle</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>model_grid_search</span><span class=p>,</span> <span class=n>model_pkl</span><span class=p>)</span>
<span class=c1># Close the pickle instances</span>
<span class=n>model_pkl</span><span class=o>.</span><span class=n>close</span><span class=p>()</span>
</code></pre></div> <h2 id=references>References<a class=headerlink href=#references title="Permanent link">&para;</a></h2> <ol> <li>Scikit-learn documentation: <a href=https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html>link</a> </li> <li>Satyam Kumar, How to tune multiple ML models with GridSearchCV at once?: <a href=https://towardsdatascience.com/how-to-tune-multiple-ml-models-with-gridsearchcv-at-once-9fcebfcc6c23>link</a> </li> </ol> </article> </div> </div> <a href=# class="md-top md-icon" data-md-component=top data-md-state=hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"/></svg> Back to top </a> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../../R/Handling-Imbalanced-classes/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Handling Imbalanced Classes" rel=prev> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </div> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> Previous </span> Handling Imbalanced Classes </div> </div> </a> <a href=../Demonstrating%20online%20learning/ class="md-footer__link md-footer__link--next" aria-label="Next: Streaming Machine Learning (Python)" rel=next> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> Next </span> Streaming Machine Learning (Python) </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright> <div class=md-footer-copyright__highlight> Copyright &copy; 2016 - 2021 Martin Donath </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-footer-social> <a href=https://github.com/HarshaAsh target=_blank rel=noopener title=github.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </a> <a href=https://www.linkedin.com/in/sri-harsha-achyuthuni/ target=_blank rel=noopener title=www.linkedin.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg> </a> <a href=https://www.instagram.com/harsha_uni/ target=_blank rel=noopener title=www.instagram.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M224.1 141c-63.6 0-114.9 51.3-114.9 114.9s51.3 114.9 114.9 114.9S339 319.5 339 255.9 287.7 141 224.1 141zm0 189.6c-41.1 0-74.7-33.5-74.7-74.7s33.5-74.7 74.7-74.7 74.7 33.5 74.7 74.7-33.6 74.7-74.7 74.7zm146.4-194.3c0 14.9-12 26.8-26.8 26.8-14.9 0-26.8-12-26.8-26.8s12-26.8 26.8-26.8 26.8 12 26.8 26.8zm76.1 27.2c-1.7-35.9-9.9-67.7-36.2-93.9-26.2-26.2-58-34.4-93.9-36.2-37-2.1-147.9-2.1-184.9 0-35.8 1.7-67.6 9.9-93.9 36.1s-34.4 58-36.2 93.9c-2.1 37-2.1 147.9 0 184.9 1.7 35.9 9.9 67.7 36.2 93.9s58 34.4 93.9 36.2c37 2.1 147.9 2.1 184.9 0 35.9-1.7 67.7-9.9 93.9-36.2 26.2-26.2 34.4-58 36.2-93.9 2.1-37 2.1-147.8 0-184.8zM398.8 388c-7.8 19.6-22.9 34.7-42.6 42.6-29.5 11.7-99.5 9-132.1 9s-102.7 2.6-132.1-9c-19.6-7.8-34.7-22.9-42.6-42.6-11.7-29.5-9-99.5-9-132.1s-2.6-102.7 9-132.1c7.8-19.6 22.9-34.7 42.6-42.6 29.5-11.7 99.5-9 132.1-9s102.7-2.6 132.1 9c19.6 7.8 34.7 22.9 42.6 42.6 11.7 29.5 9 99.5 9 132.1s2.7 102.7-9 132.1z"/></svg> </a> <a href=https://www.facebook.com/sri.harsha.achyuthuni/ target=_blank rel=noopener title=www.facebook.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><path d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.28c-30.8 0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../..", "features": ["content.code.annotate", "content.tabs.link", "header.autohide", "navigation.sections", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest"], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../../assets/javascripts/workers/search.709b4209.min.js", "version": null}</script> <script src=../../assets/javascripts/bundle.56838a2c.min.js></script> </body> </html>