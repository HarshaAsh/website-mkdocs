<!doctype html><html lang=en class=no-js> <head><!-- Code from google optimiser --><script src="https://www.googleoptimize.com/optimize.js?id=OPT-M98W6LW"></script><!-- Code from Mouseflow --><script type=text/javascript>
      window._mfq = window._mfq || [];
      (function() {
        var mf = document.createElement("script");
        mf.type = "text/javascript"; mf.defer = true;
        mf.src = "//cdn.mouseflow.com/projects/7b4494c9-7974-49f0-9777-d14450db37e6.js";
        document.getElementsByTagName("head")[0].appendChild(mf);
      })();
    </script><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Harsha's notes on data science"><meta name=author content="Harsha Achyuthuni"><link href=https://www.harshaash.com/Python/RAG/ rel=canonical><link rel=icon href=../../assets/images/logo.jpg><meta name=generator content="mkdocs-1.5.0, mkdocs-material-7.2.4"><title>RAG - Data Science with Harsha</title><link rel=stylesheet href=../../assets/stylesheets/main.f7f47774.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.3f5d1f46.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback"><style>:root{--md-text-font-family:"Roboto";--md-code-font-family:"Roboto Mono"}</style><link rel=stylesheet href=../../overrides/assets/stylesheets/user_defined.css><script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-65034507-2","auto"),ga("set","anonymizeIp",!0),ga("send","pageview"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){var e;this.value&&(e=document.location.pathname,ga("send","pageview",e+"?q="+this.value))}),"undefined"!=typeof location$&&location$.subscribe(function(e){ga("send","pageview",e.pathname)})})</script><script async src=https://www.google-analytics.com/analytics.js></script></head> <body dir=ltr data-md-color-scheme data-md-color-primary data-md-color-accent> <script>function __prefix(e){return new URL("../..",location).pathname+"."+e}function __get(e,t=localStorage){return JSON.parse(t.getItem(__prefix(e)))}</script> <script>var palette=__get("__palette");if(null!==palette&&"object"==typeof palette.color)for(var key in palette.color)document.body.setAttribute("data-md-color-"+key,palette.color[key])</script> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#rag-retrieval-augmented-generation class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="Data Science with Harsha" class="md-header__button md-logo" aria-label="Data Science with Harsha" data-md-component=logo> <img src=../../assets/images/logo.jpg alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Data Science with Harsha </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> RAG </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme data-md-color-primary data-md-color-accent aria-hidden=true type=radio name=__palette id=__palette_1> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_2> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M7 10a2 2 0 0 1 2 2 2 2 0 0 1-2 2 2 2 0 0 1-2-2 2 2 0 0 1 2-2m10-3a5 5 0 0 1 5 5 5 5 0 0 1-5 5H7a5 5 0 0 1-5-5 5 5 0 0 1 5-5h10M7 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3h10a3 3 0 0 0 3-3 3 3 0 0 0-3-3H7z"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme data-md-color-primary data-md-color-accent aria-hidden=true type=radio name=__palette id=__palette_3> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=red data-md-color-accent=red aria-label="Switch to light mode" type=radio name=__palette id=__palette_4> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_3 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3z"/></svg> </label> </form> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08z"/></svg> </a> <button type=reset class="md-search__icon md-icon" aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="Data Science with Harsha" class="md-nav__button md-logo" aria-label="Data Science with Harsha" data-md-component=logo> <img src=../../assets/images/logo.jpg alt=logo> </a> Data Science with Harsha </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> Home </a> </li> <li class=md-nav__item> <a href=../../resume/ class=md-nav__link> Resume </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3 type=checkbox id=__nav_3 checked> <label class=md-nav__link for=__nav_3> Blog <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Blog data-md-level=1> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Blog </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Others/Table_of_Contents/ class=md-nav__link> Table of Contents </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_2 type=checkbox id=__nav_3_2> <label class=md-nav__link for=__nav_3_2> Visualization <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Visualization data-md-level=2> <label class=md-nav__title for=__nav_3_2> <span class="md-nav__icon md-icon"></span> Visualization </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../Vizualisation%20using%20python%20Part%201/ class=md-nav__link> Vizualizing tabular data (Python) </a> </li> <li class=md-nav__item> <a href=../Visualization%20for%20predictive%20analytics/ class=md-nav__link> Vizualising for predictive analytics (Python) </a> </li> <li class=md-nav__item> <a href=../../R/Univariate-analysis/ class=md-nav__link> Univariate Analysis (R) </a> </li> <li class=md-nav__item> <a href=../../R/multivariateAnalysis/ class=md-nav__link> Multivariate Analysis (R) </a> </li> <li class=md-nav__item> <a href=../../R/multicollinearity/ class=md-nav__link> Multicollinearity (R) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_3 type=checkbox id=__nav_3_3> <label class=md-nav__link for=__nav_3_3> Statistics basics <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Statistics basics" data-md-level=2> <label class=md-nav__title for=__nav_3_3> <span class="md-nav__icon md-icon"></span> Statistics basics </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../R/Probability/ class=md-nav__link> Probability (R) </a> </li> <li class=md-nav__item> <a href=../../R/vectors/ class=md-nav__link> Vectors (R) </a> </li> <li class=md-nav__item> <a href=../../R/matrices/ class=md-nav__link> Matrices (R) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_4 type=checkbox id=__nav_3_4> <label class=md-nav__link for=__nav_3_4> Hypothesis Testing <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Hypothesis Testing" data-md-level=2> <label class=md-nav__title for=__nav_3_4> <span class="md-nav__icon md-icon"></span> Hypothesis Testing </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../R/attendance_t_test/ class=md-nav__link> z-test and t-test (R) </a> </li> <li class=md-nav__item> <a href=../../R/anova/ class=md-nav__link> ANOVA Test (R) </a> </li> <li class=md-nav__item> <a href=../../R/chi-sq-goodness-of-fit/ class=md-nav__link> Chi-Square Goodness of fit (R) </a> </li> <li class=md-nav__item> <a href=../../R/chi-sq-test-of-independence/ class=md-nav__link> Chi-Square test of independence (R) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_5 type=checkbox id=__nav_3_5> <label class=md-nav__link for=__nav_3_5> Factor Analysis <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Factor Analysis" data-md-level=2> <label class=md-nav__title for=__nav_3_5> <span class="md-nav__icon md-icon"></span> Factor Analysis </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../R/Curse-of-Dimensionality/ class=md-nav__link> Curse of dimensionality </a> </li> <li class=md-nav__item> <a href=../../R/EFA/ class=md-nav__link> Exploratory factor analysis (R) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_6 type=checkbox id=__nav_3_6> <label class=md-nav__link for=__nav_3_6> Prediction algorithms <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Prediction algorithms" data-md-level=2> <label class=md-nav__title for=__nav_3_6> <span class="md-nav__icon md-icon"></span> Prediction algorithms </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_6_1 type=checkbox id=__nav_3_6_1> <label class=md-nav__link for=__nav_3_6_1> Classification Algorithms <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Classification Algorithms" data-md-level=3> <label class=md-nav__title for=__nav_3_6_1> <span class="md-nav__icon md-icon"></span> Classification Algorithms </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../R/logistic-regression/ class=md-nav__link> Logistic Regression (R) </a> </li> <li class=md-nav__item> <a href=../../R/CHAID/ class=md-nav__link> CHAID Decision Trees (R) </a> </li> <li class=md-nav__item> <a href=../../R/CART-Classification/ class=md-nav__link> CART Classification (R) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_6_2 type=checkbox id=__nav_3_6_2> <label class=md-nav__link for=__nav_3_6_2> Regression Algorithms <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Regression Algorithms" data-md-level=3> <label class=md-nav__title for=__nav_3_6_2> <span class="md-nav__icon md-icon"></span> Regression Algorithms </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../R/part-and-partial-corr/ class=md-nav__link> Part and partial correlation </a> </li> <li class=md-nav__item> <a href=../../R/Linear-regression/ class=md-nav__link> Linear Regression (R) </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_7 type=checkbox id=__nav_3_7> <label class=md-nav__link for=__nav_3_7> Preprocessing data <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Preprocessing data" data-md-level=2> <label class=md-nav__title for=__nav_3_7> <span class="md-nav__icon md-icon"></span> Preprocessing data </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../R/KNN_Imputation/ class=md-nav__link> Null Value Imputation (R) </a> </li> <li class=md-nav__item> <a href=../Machine%20Learning%20Part%201/ class=md-nav__link> Feature engineering (Python) </a> </li> <li class=md-nav__item> <a href=../../R/Handling-Imbalanced-classes/ class=md-nav__link> Handling Imbalanced Classes </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_8 type=checkbox id=__nav_3_8> <label class=md-nav__link for=__nav_3_8> Machine Learning <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Machine Learning" data-md-level=2> <label class=md-nav__title for=__nav_3_8> <span class="md-nav__icon md-icon"></span> Machine Learning </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=https://harshaachyuthuni.shinyapps.io/Machine_Learning/ class=md-nav__link> Interactive Machine Learning (RShiny) </a> </li> <li class=md-nav__item> <a href=../ML%20using%20scikit-learn/ class=md-nav__link> ML using scikit-learn (Python) </a> </li> <li class=md-nav__item> <a href=../Demonstrating%20online%20learning/ class=md-nav__link> Streaming Machine Learning (Python) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_9 type=checkbox id=__nav_3_9> <label class=md-nav__link for=__nav_3_9> Time Series forecasting <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Time Series forecasting" data-md-level=2> <label class=md-nav__title for=__nav_3_9> <span class="md-nav__icon md-icon"></span> Time Series forecasting </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../R/time-series/ class=md-nav__link> Introduction to stationarity (R) </a> </li> <li class=md-nav__item> <a href=../../R/Stationarity-tests/ class=md-nav__link> Stationary Tests (R) </a> </li> <li class=md-nav__item> <a href=../../R/ARIMA/ class=md-nav__link> ARIMA in R </a> </li> <li class=md-nav__item> <a href=../ARIMA%20Forecasting/ class=md-nav__link> ARIMA in Python </a> </li> <li class=md-nav__item> <a href=../../R/Seasonal-Time-Series/ class=md-nav__link> Seasonal time series (R) </a> </li> <li class=md-nav__item> <a href=../../R/VAR-models/ class=md-nav__link> VAR Models (R) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_10 type=checkbox id=__nav_3_10> <label class=md-nav__link for=__nav_3_10> Deep learning <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Deep learning" data-md-level=2> <label class=md-nav__title for=__nav_3_10> <span class="md-nav__icon md-icon"></span> Deep learning </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../ANN-1/ class=md-nav__link> Perceptron </a> </li> <li class=md-nav__item> <a href=../Backpropagation/ class=md-nav__link> Backpropagation </a> </li> <li class=md-nav__item> <a href=../DNN/ class=md-nav__link> Tensorflow and Keras </a> </li> <li class=md-nav__item> <a href=../Time%20series%20deep%20learning/ class=md-nav__link> Time series (python) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_11 type=checkbox id=__nav_3_11 checked> <label class=md-nav__link for=__nav_3_11> Generative AI <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Generative AI" data-md-level=2> <label class=md-nav__title for=__nav_3_11> <span class="md-nav__icon md-icon"></span> Generative AI </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../LLM%20Tokenizers/ class=md-nav__link> LLM Tokenizers </a> </li> <li class=md-nav__item> <a href=../Agentic%20AI/ class=md-nav__link> Agentic AI </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" data-md-toggle=toc type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> RAG <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> RAG </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#rag-retrieval-augmented-generation class=md-nav__link> RAG: Retrieval-Augmented Generation </a> </li> <li class=md-nav__item> <a href=#article-reader-chatbot class=md-nav__link> Article reader chatbot </a> <nav class=md-nav aria-label="Article reader chatbot"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#why-is-rag-required class=md-nav__link> Why is RAG Required? </a> </li> <li class=md-nav__item> <a href=#how-rag-works class=md-nav__link> How RAG Works </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#rag-using-openai class=md-nav__link> RAG using OpenAI </a> <nav class=md-nav aria-label="RAG using OpenAI"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#retrieval class=md-nav__link> Retrieval </a> <nav class=md-nav aria-label=Retrieval> <ul class=md-nav__list> <li class=md-nav__item> <a href=#chunking class=md-nav__link> Chunking </a> </li> <li class=md-nav__item> <a href=#embedding-and-building-search-index class=md-nav__link> Embedding and building search index </a> </li> <li class=md-nav__item> <a href=#search class=md-nav__link> Search </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#augmented class=md-nav__link> Augmented </a> </li> <li class=md-nav__item> <a href=#generation class=md-nav__link> Generation </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#rag-with-local-models class=md-nav__link> RAG with local models </a> </li> <li class=md-nav__item> <a href=#rag-evaluation class=md-nav__link> RAG evaluation </a> </li> <li class=md-nav__item> <a href=#references class=md-nav__link> References </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_12 type=checkbox id=__nav_3_12> <label class=md-nav__link for=__nav_3_12> Prescriptive Analytics <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Prescriptive Analytics" data-md-level=2> <label class=md-nav__title for=__nav_3_12> <span class="md-nav__icon md-icon"></span> Prescriptive Analytics </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../R/Linear-programming/ class=md-nav__link> Linear Programming (R) </a> </li> <li class=md-nav__item> <a href=../../R/adoption_of_new_product/ class=md-nav__link> Adoption of new product (R) </a> </li> <li class=md-nav__item> <a href=../Diffusion%20on%20networks/ class=md-nav__link> Bass Forecasting model (Python) </a> </li> <li class=md-nav__item> <a href=../../Others/AHP/ class=md-nav__link> Analytic Hierarchy Process </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_13 type=checkbox id=__nav_3_13> <label class=md-nav__link for=__nav_3_13> Clustering <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Clustering data-md-level=2> <label class=md-nav__title for=__nav_3_13> <span class="md-nav__icon md-icon"></span> Clustering </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../R/hierarchical_clustering/ class=md-nav__link> Hierarchical Clustering </a> </li> <li class=md-nav__item> <a href=../../R/kMeansClustering/ class=md-nav__link> K-Means Clustering </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_14 type=checkbox id=__nav_3_14> <label class=md-nav__link for=__nav_3_14> Reinforcement Learning <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Reinforcement Learning" data-md-level=2> <label class=md-nav__title for=__nav_3_14> <span class="md-nav__icon md-icon"></span> Reinforcement Learning </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../R/CustomerLifetimeValue/ class=md-nav__link> Customer Lifetime Value </a> </li> <li class=md-nav__item> <a href=../../R/recommendation-systems/ class=md-nav__link> Recommendation Systems (R) </a> </li> <li class=md-nav__item> <a href=../Neural_collaborative_filtering/ class=md-nav__link> Collaborative Filtering (Python) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_15 type=checkbox id=__nav_3_15> <label class=md-nav__link for=__nav_3_15> Networks <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Networks data-md-level=2> <label class=md-nav__title for=__nav_3_15> <span class="md-nav__icon md-icon"></span> Networks </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../Introduction%20to%20Networkx/ class=md-nav__link> Introduction to NetworkX (Python) </a> </li> <li class=md-nav__item> <a href=../Network%20Science/ class=md-nav__link> Network Science (Python) </a> </li> <li class=md-nav__item> <a href=../Network%20centrality/ class=md-nav__link> Network Centrality (Python) </a> </li> <li class=md-nav__item> <a href=../Shortest%20path%20problems/ class=md-nav__link> Shortest path using integer programming (Python) </a> </li> <li class=md-nav__item> <a href=../Network%20Flow%20problems/ class=md-nav__link> Network flow problems (Python) </a> </li> <li class=md-nav__item> <a href=../Community%20detection/ class=md-nav__link> Community detection (Python) </a> </li> <li class=md-nav__item> <a href=../Bipartite%20matching/ class=md-nav__link> Bipartite matching (Python) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_16 type=checkbox id=__nav_3_16> <label class=md-nav__link for=__nav_3_16> Deployment <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Deployment data-md-level=2> <label class=md-nav__title for=__nav_3_16> <span class="md-nav__icon md-icon"></span> Deployment </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../Machine%20learning%20as%20HTTP%20Request/ class=md-nav__link> ML deployment in Flask (Python) </a> </li> <li class=md-nav__item> <a href=../Saving%20predictions%20in%20database/ class=md-nav__link> Handling databases using python </a> </li> <li class=md-nav__item> <a href=../ORM/ class=md-nav__link> ORM (Python) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_17 type=checkbox id=__nav_3_17> <label class=md-nav__link for=__nav_3_17> Higher education review <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Higher education review" data-md-level=2> <label class=md-nav__title for=__nav_3_17> <span class="md-nav__icon md-icon"></span> Higher education review </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Others/IIMB%20BAI/ class=md-nav__link> IIMB BAI </a> </li> <li class=md-nav__item> <a href=../../Others/part%20time%20data%20science%20masters/ class=md-nav__link> Part-time DS masters </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_18 type=checkbox id=__nav_3_18> <label class=md-nav__link for=__nav_3_18> External blogs <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="External blogs" data-md-level=2> <label class=md-nav__title for=__nav_3_18> <span class="md-nav__icon md-icon"></span> External blogs </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Others/Imperial%20College%20London/ class=md-nav__link> Imperial college London </a> </li> <li class=md-nav__item> <a href=../../Others/Rolls%20Royce/ class=md-nav__link> Rolls Royce </a> </li> <li class=md-nav__item> <a href=../../Others/Publications/ class=md-nav__link> Publications/conferences </a> </li> <li class=md-nav__item> <a href=../../Others/Deployed%20apps/ class=md-nav__link> Deployed apps </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_19 type=checkbox id=__nav_3_19> <label class=md-nav__link for=__nav_3_19> Projects <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Projects data-md-level=2> <label class=md-nav__title for=__nav_3_19> <span class="md-nav__icon md-icon"></span> Projects </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Others/preventive_maintainence/ class=md-nav__link> Preventive maintainence </a> </li> <li class=md-nav__item> <a href=../../Others/competitor%20intelligence/ class=md-nav__link> Competitor intelligence </a> </li> <li class=md-nav__item> <a href=../../Others/Scarecrow/ class=md-nav__link> Intelligent annotation </a> </li> <li class=md-nav__item> <a href=../../Others/bid%20allocation%20model/ class=md-nav__link> Bid Allocation </a> </li> <li class=md-nav__item> <a href=../../Others/IIMB%20project/ class=md-nav__link> Reward and Recognition contests </a> </li> <li class=md-nav__item> <a href=../../Others/supply%20chain%20analytics/ class=md-nav__link> Supply chain analytics </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#rag-retrieval-augmented-generation class=md-nav__link> RAG: Retrieval-Augmented Generation </a> </li> <li class=md-nav__item> <a href=#article-reader-chatbot class=md-nav__link> Article reader chatbot </a> <nav class=md-nav aria-label="Article reader chatbot"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#why-is-rag-required class=md-nav__link> Why is RAG Required? </a> </li> <li class=md-nav__item> <a href=#how-rag-works class=md-nav__link> How RAG Works </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#rag-using-openai class=md-nav__link> RAG using OpenAI </a> <nav class=md-nav aria-label="RAG using OpenAI"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#retrieval class=md-nav__link> Retrieval </a> <nav class=md-nav aria-label=Retrieval> <ul class=md-nav__list> <li class=md-nav__item> <a href=#chunking class=md-nav__link> Chunking </a> </li> <li class=md-nav__item> <a href=#embedding-and-building-search-index class=md-nav__link> Embedding and building search index </a> </li> <li class=md-nav__item> <a href=#search class=md-nav__link> Search </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#augmented class=md-nav__link> Augmented </a> </li> <li class=md-nav__item> <a href=#generation class=md-nav__link> Generation </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#rag-with-local-models class=md-nav__link> RAG with local models </a> </li> <li class=md-nav__item> <a href=#rag-evaluation class=md-nav__link> RAG evaluation </a> </li> <li class=md-nav__item> <a href=#references class=md-nav__link> References </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1>RAG</h1> <h2 id=rag-retrieval-augmented-generation>RAG: Retrieval-Augmented Generation<a class=headerlink href=#rag-retrieval-augmented-generation title="Permanent link">&para;</a></h2> <p>RAG stands for Retrieval-Augmented Generation. It's a technique that enhances large language models (LLMs) by allowing them to access and incorporate external knowledge sources during the generation process. It is used in chatbots to answer questions based on specific text, internal company documents, code documentation, news articles, etc. </p> <h2 id=article-reader-chatbot>Article reader chatbot<a class=headerlink href=#article-reader-chatbot title="Permanent link">&para;</a></h2> <p>I have built a chatbot <a href=https://share.streamlit.io/app/read-article/ >Article Reader</a> where users can upload a document/link to get answers based on the document only (website or PDF). Unlike regular LLM chatbots, this will not answer questions outside the documents shared. A screenshot of the tool is shown below:</p> <p><img alt=png src=article%20reader.png></p> <h3 id=why-is-rag-required>Why is RAG Required?<a class=headerlink href=#why-is-rag-required title="Permanent link">&para;</a></h3> <ol> <li>Overcoming Limitations of LLMs: LLMs are trained on massive datasets, but they may not have access to the most up-to-date or specific information. RAG addresses this by providing LLMs with a way to access and utilize external knowledge bases. In our case, we can share internal company documents or an annual report of a comapny and ask questions based on the shared document alone. </li> <li>Improved Accuracy and Relevance: By incorporating external knowledge, RAG helps LLMs generate more accurate and relevant responses, especially when dealing with factual questions or domain-specific topics.   </li> <li>Enhanced Contextualization: RAG enables LLMs to better understand the context of a query by considering external information, leading to more coherent and informative responses.   </li> <li>Up-to-Date Information: RAG allows LLMs to access the latest information from external sources, ensuring that their responses are current and relevant.   </li> </ol> <h3 id=how-rag-works>How RAG Works<a class=headerlink href=#how-rag-works title="Permanent link">&para;</a></h3> <ol> <li>Retrieval: The LLM receives a query and retrieves relevant documents or passages from an external knowledge base.   </li> <li>Augmentation: The retrieved information is integrated into the LLM's input, either by concatenating it with the original query or by feeding it directly to the model.   </li> <li>Generation: The LLM generates a response based on the augmented input, incorporating the external knowledge into its output.   In essence, RAG combines the strengths of retrieval-based models (for finding relevant information) and generative models (for generating human-like text), creating a more powerful and versatile AI system. </li> </ol> <p>Let us now build two RAG models end-to-end, one using Open AI and the other using local models (Llama).</p> <h2 id=rag-using-openai>RAG using OpenAI<a class=headerlink href=#rag-using-openai title="Permanent link">&para;</a></h2> <p>Let us say we want to read a person's resume and find out the years of experience of the person. We can use the <a href=https://share.streamlit.io/app/read-article/ >Article Reader</a> chatbot to upload the resume and ask the question. </p> <p>Let us first read a resume.</p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>PyPDF2</span> <span class=kn>import</span> <span class=n>PdfReader</span>
<span class=kn>from</span> <span class=nn>langchain.text_splitter</span> <span class=kn>import</span> <span class=n>RecursiveCharacterTextSplitter</span>
<span class=kn>from</span> <span class=nn>langchain_community.embeddings.sentence_transformer</span> <span class=kn>import</span> <span class=n>SentenceTransformerEmbeddings</span>
<span class=kn>from</span> <span class=nn>langchain_openai</span> <span class=kn>import</span> <span class=n>OpenAIEmbeddings</span>
<span class=kn>from</span> <span class=nn>langchain_core.documents</span> <span class=kn>import</span> <span class=n>Document</span>
<span class=kn>from</span> <span class=nn>langchain_qdrant</span> <span class=kn>import</span> <span class=n>QdrantVectorStore</span>
<span class=kn>from</span> <span class=nn>qdrant_client</span> <span class=kn>import</span> <span class=n>QdrantClient</span>
<span class=kn>import</span> <span class=nn>openai</span>
<span class=kn>import</span> <span class=nn>config</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=k>def</span> <span class=nf>extract_text_from_pdf</span><span class=p>(</span><span class=n>pdf_file</span><span class=p>):</span>
    <span class=n>pdf_text</span> <span class=o>=</span> <span class=s1>&#39;&#39;</span>
    <span class=n>reader</span> <span class=o>=</span> <span class=n>PdfReader</span><span class=p>(</span><span class=n>pdf_file</span><span class=p>)</span>
    <span class=k>for</span> <span class=n>page_no</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>reader</span><span class=o>.</span><span class=n>pages</span><span class=p>)):</span>
        <span class=n>pdf_text</span> <span class=o>=</span> <span class=n>pdf_text</span> <span class=o>+</span> <span class=n>reader</span><span class=o>.</span><span class=n>pages</span><span class=p>[</span><span class=n>page_no</span><span class=p>]</span><span class=o>.</span><span class=n>extract_text</span><span class=p>()</span>
    <span class=k>if</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>pdf_text</span><span class=p>)</span><span class=o>==</span><span class=mi>0</span><span class=p>):</span>
        <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span><span class=s1>&#39;No text extracted from this pdf.&#39;</span><span class=p>)</span>
    <span class=k>return</span> <span class=n>pdf_text</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=n>text_article</span> <span class=o>=</span> <span class=n>extract_text_from_pdf</span><span class=p>(</span><span class=s2>&quot;Harsha_Achyuthuni_resume.pdf&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;The first 100 chars in the resume are:</span><span class=se>\n</span><span class=s2>&quot;</span><span class=p>,</span> <span class=n>text_article</span><span class=p>[:</span><span class=mi>100</span><span class=p>])</span>
</code></pre></div> <div class=highlight><pre><span></span><code>The first 100 chars in the resume are:
 Achyuthuni Sri Harsha
Data Scientist, Deloitte, Imperial College London, IIMB, harshaash.com
E-mail:
</code></pre></div> <div class=highlight><pre><span></span><code><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;The total number of words in the document are: &quot;</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=n>text_article</span><span class=o>.</span><span class=n>split</span><span class=p>()))</span>
</code></pre></div> <div class=highlight><pre><span></span><code>The total number of words in the document are:  1611
</code></pre></div> <p>Let us define the question that we want to ask:</p> <div class=highlight><pre><span></span><code><span class=n>query</span> <span class=o>=</span> <span class=s2>&quot;How many years of experience does the candidate have?&quot;</span>
</code></pre></div> <h3 id=retrieval>Retrieval<a class=headerlink href=#retrieval title="Permanent link">&para;</a></h3> <p>The first step of RAG is dense retrieval. This technique leverages the power of embeddings – unique numerical representations of text – to efficiently search for the most relevant information within a document. </p> <p>To achieve this, we break down the document into smaller, manageable chunks. Each chunk is then transformed into a dense vector (its embedding), capturing the essence of its meaning. This collection of embeddings forms an index, enabling the system to swiftly locate the chunks that most closely align with the user's query (which is also converted into an embedding). </p> <p>This is a three step process:<br> 1. Get the text and chunk the sentences<br> 2. Embed the sentences<br> 3. Build search index<br> 4. Search </p> <h4 id=chunking>Chunking<a class=headerlink href=#chunking title="Permanent link">&para;</a></h4> <p>There are many ways to split the document into chunks such as: 1. Each sentence is a chunk<br> 2. Each paragraph is a chunk<br> 3. The document is split evenly with a similar number of tokens in each chunk<br> 4. Some chunks lose meaning if we do not include the text around them. So we can add context by adding some text before and after the chunk.</p> <p>Let us split the document into chunks of size 100 tokens with a 25% overlap on each side.</p> <div class=highlight><pre><span></span><code><span class=c1># Split the text based on tokens into chunks</span>
<span class=n>text_splitter</span> <span class=o>=</span> <span class=n>RecursiveCharacterTextSplitter</span><span class=o>.</span><span class=n>from_tiktoken_encoder</span><span class=p>(</span>
    <span class=n>encoding_name</span><span class=o>=</span><span class=s1>&#39;cl100k_base&#39;</span><span class=p>,</span>
    <span class=n>chunk_size</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=c1># Minimum chunk size is 100</span>
    <span class=n>chunk_overlap</span><span class=o>=</span><span class=mi>25</span> <span class=c1># Overlap in the chunk size is 25</span>
<span class=p>)</span>
<span class=n>split_texts</span> <span class=o>=</span> <span class=n>text_splitter</span><span class=o>.</span><span class=n>split_text</span><span class=p>(</span><span class=n>text_article</span><span class=p>)</span>
<span class=n>split_texts</span> <span class=o>=</span> <span class=p>[</span><span class=n>Document</span><span class=p>(</span><span class=n>page_content</span> <span class=o>=</span> <span class=n>split_texts</span><span class=p>[</span><span class=n>i</span><span class=p>])</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>split_texts</span><span class=p>))]</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;The total number of chunks in the document are: &quot;</span><span class=o>+</span><span class=nb>str</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>split_texts</span><span class=p>)))</span>
</code></pre></div> <div class=highlight><pre><span></span><code>The total number of chunks in the document are: 34
</code></pre></div> <p>For a chunk size of 100 tokens, the below image shows how the text has been chunked. The highlighted yellow and red are separate chunks with the common part being overlapped. <img alt=png src=chunking.png></p> <h4 id=embedding-and-building-search-index>Embedding and building search index<a class=headerlink href=#embedding-and-building-search-index title="Permanent link">&para;</a></h4> <p>To generate embeddings, I am using OpenAI's tokenizer. Each chunk is converted into an embedding vector. </p> <p>These embeddings are then stored using <a href=https://cloud.qdrant.io/ >Qdrant</a>, a free vector database. Qdrant is specifically designed to handle and search through large collections of embeddings, making it an ideal choice for my RAG system. This also helps me retrieve the most relevant information during the retrieval phase. </p> <div class=highlight><pre><span></span><code><span class=c1># Create embeddings</span>
<span class=n>embeddings</span> <span class=o>=</span> <span class=n>OpenAIEmbeddings</span><span class=p>(</span><span class=n>api_key</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>open_api_key</span><span class=p>,</span> <span class=n>model</span><span class=o>=</span><span class=s2>&quot;text-embedding-3-large&quot;</span><span class=p>)</span>
</code></pre></div> <p>Storing these embeddings into a vector database called <em>my_chat_documents</em></p> <div class=highlight><pre><span></span><code><span class=c1># Initialise vector database</span>
<span class=n>qdrant_client</span> <span class=o>=</span> <span class=n>QdrantClient</span><span class=p>(</span>
    <span class=n>url</span><span class=o>=</span><span class=n>config</span><span class=o>.</span><span class=n>qdrant_url</span><span class=p>,</span> 
    <span class=n>api_key</span><span class=o>=</span><span class=n>config</span><span class=o>.</span><span class=n>qdrant_api_key</span><span class=p>,</span>
<span class=p>)</span>
<span class=c1># Delete existing collection</span>
<span class=n>qdrant_client</span><span class=o>.</span><span class=n>delete_collection</span><span class=p>(</span><span class=n>collection_name</span><span class=o>=</span><span class=s2>&quot;my_chat_documents&quot;</span><span class=p>)</span>

<span class=c1># Store embeddings in vector db</span>
<span class=n>qdrant</span> <span class=o>=</span> <span class=n>QdrantVectorStore</span><span class=o>.</span><span class=n>from_documents</span><span class=p>(</span>
    <span class=n>split_texts</span><span class=p>,</span>
    <span class=n>embeddings</span><span class=p>,</span>
    <span class=n>url</span><span class=o>=</span><span class=n>config</span><span class=o>.</span><span class=n>qdrant_url</span><span class=p>,</span> 
    <span class=n>api_key</span><span class=o>=</span><span class=n>config</span><span class=o>.</span><span class=n>qdrant_api_key</span><span class=p>,</span>
    <span class=n>prefer_grpc</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
    <span class=n>collection_name</span><span class=o>=</span><span class=s2>&quot;my_chat_documents&quot;</span><span class=p>,</span>
<span class=p>)</span>

<span class=p>[</span><span class=n>qdrant_client</span><span class=o>.</span><span class=n>get_collections</span><span class=p>()</span><span class=o>.</span><span class=n>collections</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>name</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>qdrant_client</span><span class=o>.</span><span class=n>get_collections</span><span class=p>()</span><span class=o>.</span><span class=n>collections</span><span class=p>))]</span>
</code></pre></div> <div class=highlight><pre><span></span><code>[&#39;my_chat_documents&#39;]
</code></pre></div> <h4 id=search>Search<a class=headerlink href=#search title="Permanent link">&para;</a></h4> <p>I am going to use the vector database to search for the vector that is closest to the query. This can be done by creating embedding vector for the query using the same embedding models and tokenizer and finding <em>nearest neighbours</em> using similarity scores like <em>cosine similarity</em></p> <div class=highlight><pre><span></span><code><span class=c1># retrieve selected part of the website</span>
<span class=n>qdrant</span> <span class=o>=</span> <span class=n>QdrantVectorStore</span><span class=o>.</span><span class=n>from_existing_collection</span><span class=p>(</span>
  <span class=n>embedding</span><span class=o>=</span><span class=n>embeddings</span><span class=p>,</span>
  <span class=n>collection_name</span><span class=o>=</span><span class=s2>&quot;my_chat_documents&quot;</span><span class=p>,</span>
  <span class=n>url</span><span class=o>=</span><span class=n>config</span><span class=o>.</span><span class=n>qdrant_url</span><span class=p>,</span> <span class=n>api_key</span><span class=o>=</span><span class=n>config</span><span class=o>.</span><span class=n>qdrant_api_key</span>
<span class=p>)</span>
<span class=c1># Find closest chunks</span>
<span class=n>relevant_document_chunks</span> <span class=o>=</span> <span class=n>qdrant</span><span class=o>.</span><span class=n>similarity_search</span><span class=p>(</span><span class=n>query</span><span class=o>=</span><span class=n>query</span><span class=p>,</span><span class=n>k</span><span class=o>=</span><span class=mi>3</span><span class=p>)</span>
<span class=n>context_list</span> <span class=o>=</span> <span class=p>[</span><span class=n>d</span><span class=o>.</span><span class=n>page_content</span> <span class=k>for</span> <span class=n>d</span> <span class=ow>in</span> <span class=n>relevant_document_chunks</span><span class=p>]</span>
</code></pre></div> <h3 id=augmented>Augmented<a class=headerlink href=#augmented title="Permanent link">&para;</a></h3> <p>The top three chunks are:</p> <div class=highlight><pre><span></span><code><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>-----------------------</span><span class=se>\n</span><span class=s2>&quot;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>context_list</span><span class=p>))</span>
</code></pre></div> <div class=highlight><pre><span></span><code>Summary
Harsha has 7 years of experience in Data Science and Machine learning. As a senior consultant at
Deloitte, he likes solving complex business problems using data, statistics, technology and business
understanding. He has worked on projects across the data science spectrum, including regression,
classification, deep learning, machine learning, AI, ChatGPT, reinforcement learning, optimization,
unsupervised learning and streaming machine learning.
-----------------------
Achyuthuni Sri Harsha
Data Scientist, Deloitte, Imperial College London, IIMB, harshaash.com
E-mail: achyuthuni.sri.harsha@gmail.com ✼Phone/Whatsapp: +91-9019413416
LinkedIn: sri-harsha-achyuthuni ✼Website: www.harshaash.com
Summary
Harsha has 7 years of experience in Data Science and Machine learning. As a senior consultant at
-----------------------
Solutions that he built are currently deployed at Walmart, Rolls Royce and Dr Reddys. He has also
built, presented and converted POCs across many Fortune 500 clients.
He has a masters from Imperial College London in Business Analytics and is an alumnus of IIM
Bangalore.
Technical skills
Analytics Python, R, CPLEX
Data Engineering SQL, Alteryx
Visualisation Tableau, HTML, Javascript
</code></pre></div> <p>The first two chunks (out of the three) have the years of experience mentioned and are relevant. Joining these three chunks gives me a comprehensive and augmented text that can be used for generation. </p> <div class=highlight><pre><span></span><code><span class=n>agumented_search_context</span> <span class=o>=</span> <span class=s2>&quot;. &quot;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>context_list</span><span class=p>)</span>
</code></pre></div> <h3 id=generation>Generation<a class=headerlink href=#generation title="Permanent link">&para;</a></h3> <p>In the prompt, we will provide an additional variable named context where we provide context to the LLM. This context is the chunks that are relevant for the answer. </p> <div class=highlight><pre><span></span><code><span class=n>qna_system_message</span> <span class=o>=</span> <span class=s1>&#39;&#39;&#39;You will be provided with a text, and your task is to answer the question based on the text alone. </span>
<span class=s1>    If you are unable to answer or doubtful, please say &quot;I dont know&quot;&#39;&#39;&#39;</span>
<span class=n>qna_user_message_template</span> <span class=o>=</span> <span class=s2>&quot;&quot;&quot;</span>
<span class=s2>###Context</span>
<span class=s2>Here are some documents that are relevant to the question mentioned below.</span>
<span class=si>{context}</span>

<span class=s2>###Question</span>
<span class=si>{question}</span>
<span class=s2>&quot;&quot;&quot;</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=n>prompt</span> <span class=o>=</span> <span class=p>[</span>
    <span class=p>{</span><span class=s1>&#39;role&#39;</span><span class=p>:</span><span class=s1>&#39;system&#39;</span><span class=p>,</span> <span class=s1>&#39;content&#39;</span><span class=p>:</span> <span class=n>qna_system_message</span><span class=p>},</span>
    <span class=p>{</span><span class=s1>&#39;role&#39;</span><span class=p>:</span> <span class=s1>&#39;user&#39;</span><span class=p>,</span> <span class=s1>&#39;content&#39;</span><span class=p>:</span> <span class=n>qna_user_message_template</span><span class=o>.</span><span class=n>format</span><span class=p>(</span>
         <span class=n>context</span><span class=o>=</span><span class=n>agumented_search_context</span><span class=p>,</span>
         <span class=n>question</span><span class=o>=</span><span class=n>query</span>
        <span class=p>)</span>
    <span class=p>}</span>
<span class=p>]</span>
<span class=n>openai</span><span class=o>.</span><span class=n>api_key</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>open_api_key</span>
<span class=n>response</span> <span class=o>=</span> <span class=n>openai</span><span class=o>.</span><span class=n>chat</span><span class=o>.</span><span class=n>completions</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
    <span class=n>model</span><span class=o>=</span><span class=s2>&quot;gpt-3.5-turbo&quot;</span><span class=p>,</span>
    <span class=n>messages</span><span class=o>=</span><span class=n>prompt</span><span class=p>,</span>
    <span class=n>temperature</span><span class=o>=</span><span class=mi>0</span>
<span class=p>)</span>

<span class=n>prediction</span> <span class=o>=</span> <span class=n>response</span><span class=o>.</span><span class=n>choices</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>message</span><span class=o>.</span><span class=n>content</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=nb>print</span><span class=p>(</span><span class=n>prediction</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>The candidate has 7 years of experience.
</code></pre></div> <p>The RAG architecture was able to find the correct answer. </p> <h2 id=rag-with-local-models>RAG with local models<a class=headerlink href=#rag-with-local-models title="Permanent link">&para;</a></h2> <p>Many organizations prioritize data privacy and security, often prohibiting the sharing of sensitive information with external services. This presents a significant challenge for traditional RAG implementations, which often rely on cloud-based models and external knowledge sources.</p> <p>To address these concerns, I have implemented a RAG architecture using entirely local models. This approach eliminates the need for internet connectivity and ensures that all data processing and model interactions occur within the organization's secure internal systems.</p> <p>Downloading a pre-trained LLM locally: The most common open source LLM is Facebook's <a href=https://huggingface.co/microsoft/Phi-3.5-mini-instruct>Llama</a>.</p> <div class=highlight><pre><span></span><code><span class=err>!</span><span class=n>wget</span> <span class=n>https</span><span class=p>:</span><span class=o>//</span><span class=n>huggingface</span><span class=o>.</span><span class=n>co</span><span class=o>/</span><span class=n>microsoft</span><span class=o>/</span><span class=n>Phi</span><span class=o>-</span><span class=mi>3</span><span class=o>-</span><span class=n>mini</span><span class=o>-</span><span class=mi>4</span><span class=n>k</span><span class=o>-</span><span class=n>instruct</span><span class=o>-</span><span class=n>gguf</span><span class=o>/</span><span class=n>resolve</span><span class=o>/</span><span class=n>main</span><span class=o>/</span><span class=n>Phi</span><span class=o>-</span><span class=mi>3</span><span class=o>-</span><span class=n>mini</span><span class=o>-</span><span class=mi>4</span><span class=n>k</span><span class=o>-</span><span class=n>instruct</span><span class=o>-</span><span class=n>q4</span><span class=o>.</span><span class=n>gguf</span>
</code></pre></div> <div class=highlight><pre><span></span><code>Phi-3-mini-4k-instr 100%[===================&gt;]   2.23G  39.2MB/s    in 57s
</code></pre></div> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>langchain</span> <span class=kn>import</span> <span class=n>LlamaCpp</span>

<span class=n>llm</span> <span class=o>=</span> <span class=n>LlamaCpp</span><span class=p>(</span>
    <span class=n>model_path</span><span class=o>=</span><span class=s2>&quot;Phi-3-mini-4k-instruct-q4.gguf&quot;</span><span class=p>,</span>
    <span class=n>n_gpu_layers</span><span class=o>=-</span><span class=mi>1</span><span class=p>,</span>
    <span class=n>max_tokens</span><span class=o>=</span><span class=mi>500</span><span class=p>,</span>
    <span class=n>n_ctx</span><span class=o>=</span><span class=mi>2048</span><span class=p>,</span>
    <span class=n>seed</span><span class=o>=</span><span class=mi>42</span><span class=p>,</span>
    <span class=n>verbose</span><span class=o>=</span><span class=kc>False</span>
<span class=p>)</span>
</code></pre></div> <p>For embedding the text, the BAAI/bge-small-en-v1.5 model is used.</p> <p><div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>langchain.embeddings.huggingface</span> <span class=kn>import</span> <span class=n>HuggingFaceEmbeddings</span>

<span class=c1># Embedding Model for converting text to numerical representations</span>
<span class=n>embedding_model</span> <span class=o>=</span> <span class=n>HuggingFaceEmbeddings</span><span class=p>(</span>
    <span class=n>model_name</span><span class=o>=</span><span class=s1>&#39;BAAI/bge-small-en-v1.5&#39;</span>
<span class=p>)</span>
</code></pre></div> <img alt=png src=download%20package.png></p> <p>A vector database is created using the embedding model</p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>langchain.vectorstores</span> <span class=kn>import</span> <span class=n>FAISS</span>

<span class=c1># Split into a list of sentences</span>
<span class=n>texts</span> <span class=o>=</span> <span class=n>text_article</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s1>&#39;</span><span class=se>\n</span><span class=s1>&#39;</span><span class=p>)</span>

<span class=c1># Clean up to remove empty spaces and new lines</span>
<span class=n>texts</span> <span class=o>=</span> <span class=p>[</span><span class=n>t</span><span class=o>.</span><span class=n>strip</span><span class=p>(</span><span class=s1>&#39; </span><span class=se>\n</span><span class=s1>&#39;</span><span class=p>)</span> <span class=k>for</span> <span class=n>t</span> <span class=ow>in</span> <span class=n>texts</span><span class=p>]</span>

<span class=c1># Create a local vector database</span>
<span class=n>db</span> <span class=o>=</span> <span class=n>FAISS</span><span class=o>.</span><span class=n>from_texts</span><span class=p>(</span><span class=n>texts</span><span class=p>,</span> <span class=n>embedding_model</span><span class=p>)</span>
</code></pre></div> <p>Similar to the previous implementation, I have created the prompt such that the context is provided along with the query</p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>langchain</span> <span class=kn>import</span> <span class=n>PromptTemplate</span>
<span class=kn>from</span> <span class=nn>langchain.chains</span> <span class=kn>import</span> <span class=n>RetrievalQA</span>


<span class=c1># Create a prompt template</span>
<span class=n>template</span> <span class=o>=</span> <span class=s2>&quot;&quot;&quot;&lt;|user|&gt;</span>
<span class=s2>Relevant information:</span>
<span class=si>{context}</span>

<span class=s2>Provide a concise answer the following question using the relevant information provided above:</span>
<span class=si>{question}</span><span class=s2>&lt;|end|&gt;</span>
<span class=s2>&lt;|assistant|&gt;&quot;&quot;&quot;</span>
<span class=n>prompt</span> <span class=o>=</span> <span class=n>PromptTemplate</span><span class=p>(</span>
    <span class=n>template</span><span class=o>=</span><span class=n>template</span><span class=p>,</span>
    <span class=n>input_variables</span><span class=o>=</span><span class=p>[</span><span class=s2>&quot;context&quot;</span><span class=p>,</span> <span class=s2>&quot;question&quot;</span><span class=p>]</span>
<span class=p>)</span>

<span class=c1># RAG Pipeline</span>
<span class=n>rag</span> <span class=o>=</span> <span class=n>RetrievalQA</span><span class=o>.</span><span class=n>from_chain_type</span><span class=p>(</span>
    <span class=n>llm</span><span class=o>=</span><span class=n>llm</span><span class=p>,</span>
    <span class=n>chain_type</span><span class=o>=</span><span class=s1>&#39;stuff&#39;</span><span class=p>,</span>
    <span class=n>retriever</span><span class=o>=</span><span class=n>db</span><span class=o>.</span><span class=n>as_retriever</span><span class=p>(),</span>
    <span class=n>chain_type_kwargs</span><span class=o>=</span><span class=p>{</span>
        <span class=s2>&quot;prompt&quot;</span><span class=p>:</span> <span class=n>prompt</span>
    <span class=p>},</span>
    <span class=n>verbose</span><span class=o>=</span><span class=kc>True</span>
<span class=p>)</span>
</code></pre></div> <p>The answer to the query is</p> <div class=highlight><pre><span></span><code><span class=n>rag</span><span class=o>.</span><span class=n>invoke</span><span class=p>(</span><span class=n>query</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>1m&gt; Finished chain.

{&#39;query&#39;: &#39;How many years of experience does the candidate have?&#39;,
 &#39;result&#39;: &#39; The candidate has 7 years of experience in Data Science and Machine learning.&#39;}
</code></pre></div> <h2 id=rag-evaluation>RAG evaluation<a class=headerlink href=#rag-evaluation title="Permanent link">&para;</a></h2> <p>RAG responses can be evaluated on various parameters, like fluency, perceived utility, citation recall and precision, faithfulness, relevance and groundedness. Let us look at relevance and groundedness in detail. </p> <p>We can use the LLM-as-a-judge method to check the quality of the RAG system.<br> 1. Groundedness: If the answer is based solely on the context provided<br> 2. Relevance: If the answer is relevant and answers all aspects of the query</p> <div class=highlight><pre><span></span><code><span class=n>groundedness_rater_system_message</span> <span class=o>=</span> <span class=s2>&quot;&quot;&quot;</span>
<span class=s2>You are tasked with rating AI generated answers to questions posed by users.</span>
<span class=s2>You will be presented a question, context used by the AI system to generate the answer and an AI generated answer to the question.</span>
<span class=s2>In the input, the question will begin with ###Question, the context will begin with ###Context while the AI generated answer will begin with ###Answer.</span>

<span class=s2>Evaluation criteria:</span>
<span class=s2>The task is to judge the extent to which the metric is followed by the answer.</span>
<span class=s2>1 - The metric is not followed at all</span>
<span class=s2>2 - The metric is followed only to a limited extent</span>
<span class=s2>3 - The metric is followed to a good extent</span>
<span class=s2>4 - The metric is followed mostly</span>
<span class=s2>5 - The metric is followed completely</span>

<span class=s2>Metric:</span>
<span class=s2>The answer should be derived only from the information presented in the context</span>

<span class=s2>Instructions:</span>
<span class=s2>1. First write down the steps that are needed to evaluate the answer as per the metric.</span>
<span class=s2>2. Give a step-by-step explanation if the answer adheres to the metric considering the question and context as the input.</span>
<span class=s2>3. Next, evaluate the extent to which the metric is followed.</span>
<span class=s2>4. Use the previous information to rate the answer using the evaluaton criteria and assign a score.</span>
<span class=s2>&quot;&quot;&quot;</span>

<span class=n>groundedness_prompt</span> <span class=o>=</span> <span class=p>[</span>
    <span class=p>{</span><span class=s1>&#39;role&#39;</span><span class=p>:</span><span class=s1>&#39;system&#39;</span><span class=p>,</span> <span class=s1>&#39;content&#39;</span><span class=p>:</span> <span class=n>groundedness_rater_system_message</span><span class=p>},</span>
    <span class=p>{</span><span class=s1>&#39;role&#39;</span><span class=p>:</span> <span class=s1>&#39;user&#39;</span><span class=p>,</span> <span class=s1>&#39;content&#39;</span><span class=p>:</span> <span class=n>user_message_template</span><span class=o>.</span><span class=n>format</span><span class=p>(</span>
        <span class=n>question</span><span class=o>=</span><span class=n>query</span><span class=p>,</span>
        <span class=n>context</span><span class=o>=</span><span class=n>agumented_search_context</span><span class=p>,</span>
        <span class=n>answer</span><span class=o>=</span><span class=n>prediction</span>
        <span class=p>)</span>
    <span class=p>}</span>
<span class=p>]</span>

<span class=n>response</span> <span class=o>=</span> <span class=n>openai</span><span class=o>.</span><span class=n>chat</span><span class=o>.</span><span class=n>completions</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
    <span class=n>model</span><span class=o>=</span><span class=s2>&quot;gpt-3.5-turbo&quot;</span><span class=p>,</span>
    <span class=n>messages</span><span class=o>=</span><span class=n>groundedness_prompt</span><span class=p>,</span>
    <span class=n>temperature</span><span class=o>=</span><span class=mi>0</span>
<span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=n>response</span><span class=o>.</span><span class=n>choices</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>message</span><span class=o>.</span><span class=n>content</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>Steps to evaluate the answer:
1. Identify the specific information in the context related to the candidate&#39;s experience.
2. Check if the answer provided matches the exact number of years of experience mentioned in the context.
3. Determine if any additional information not present in the context is included in the answer.

Explanation:
1. The context clearly states that Harsha has 7 years of experience in Data Science and Machine learning.
2. The answer provided states &quot;The candidate has 7 years of experience,&quot; which directly matches the information given in the context.
3. The answer does not include any additional information beyond what is provided in the context.

The answer follows the metric completely by accurately stating the number of years of experience the candidate has based on the information given in the context.

### Evaluation: 5
### Score: 5
</code></pre></div> <div class=highlight><pre><span></span><code><span class=n>relevance_rater_system_message</span> <span class=o>=</span> <span class=s2>&quot;&quot;&quot;</span>
<span class=s2>You are tasked with rating AI generated answers to questions posed by users.</span>
<span class=s2>You will be presented a question, context used by the AI system to generate the answer and an AI generated answer to the question.</span>
<span class=s2>In the input, the question will begin with ###Question, the context will begin with ###Context while the AI generated answer will begin with ###Answer.</span>

<span class=s2>Evaluation criteria:</span>
<span class=s2>The task is to judge the extent to which the metric is followed by the answer.</span>
<span class=s2>1 - The metric is not followed at all</span>
<span class=s2>2 - The metric is followed only to a limited extent</span>
<span class=s2>3 - The metric is followed to a good extent</span>
<span class=s2>4 - The metric is followed mostly</span>
<span class=s2>5 - The metric is followed completely</span>

<span class=s2>Metric:</span>
<span class=s2>Relevance measures how well the answer addresses the main aspects of the question, based on the context.</span>
<span class=s2>Consider whether all and only the important aspects are contained in the answer when evaluating relevance.</span>

<span class=s2>Instructions:</span>
<span class=s2>1. First write down the steps that are needed to evaluate the context as per the metric.</span>
<span class=s2>2. Give a step-by-step explanation if the context adheres to the metric considering the question as the input.</span>
<span class=s2>3. Next, evaluate the extent to which the metric is followed.</span>
<span class=s2>4. Use the previous information to rate the context using the evaluaton criteria and assign a score.</span>
<span class=s2>&quot;&quot;&quot;</span>

<span class=n>relevance_prompt</span> <span class=o>=</span> <span class=p>[</span>
    <span class=p>{</span><span class=s1>&#39;role&#39;</span><span class=p>:</span><span class=s1>&#39;system&#39;</span><span class=p>,</span> <span class=s1>&#39;content&#39;</span><span class=p>:</span> <span class=n>relevance_rater_system_message</span><span class=p>},</span>
    <span class=p>{</span><span class=s1>&#39;role&#39;</span><span class=p>:</span> <span class=s1>&#39;user&#39;</span><span class=p>,</span> <span class=s1>&#39;content&#39;</span><span class=p>:</span> <span class=n>user_message_template</span><span class=o>.</span><span class=n>format</span><span class=p>(</span>
        <span class=n>question</span><span class=o>=</span><span class=n>query</span><span class=p>,</span>
        <span class=n>context</span><span class=o>=</span><span class=n>agumented_search_context</span><span class=p>,</span>
        <span class=n>answer</span><span class=o>=</span><span class=n>prediction</span>
        <span class=p>)</span>
    <span class=p>}</span>
<span class=p>]</span>

<span class=n>response</span> <span class=o>=</span> <span class=n>openai</span><span class=o>.</span><span class=n>chat</span><span class=o>.</span><span class=n>completions</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
    <span class=n>model</span><span class=o>=</span><span class=s2>&quot;gpt-3.5-turbo&quot;</span><span class=p>,</span>
    <span class=n>messages</span><span class=o>=</span><span class=n>relevance_prompt</span><span class=p>,</span>
    <span class=n>temperature</span><span class=o>=</span><span class=mi>0</span>
<span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=n>response</span><span class=o>.</span><span class=n>choices</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>message</span><span class=o>.</span><span class=n>content</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>1. Identify the main aspects of the question: The main aspect of the question is to determine the number of years of experience the candidate has.

2. Look for relevant information in the context: Search for details related to the candidate&#39;s experience in the context provided.

3. Determine if the answer contains the specific number of years of experience: Check if the answer explicitly states the number of years of experience the candidate has.

4. Evaluate if the answer addresses the main aspect of the question: Assess whether the answer accurately provides the number of years of experience as requested in the question.

Explanation:
The context clearly states that Harsha has 7 years of experience in Data Science and Machine learning. The AI generated answer directly addresses the main aspect of the question by stating &quot;The candidate has 7 years of experience.&quot; The answer is relevant as it provides the specific number of years of experience the candidate has based on the information in the context.

Therefore, the answer follows the metric of relevance completely by addressing the main aspect of the question accurately.

###Final Rating
5 - The metric is followed completely
</code></pre></div> <p>Written with assistance from Generative AI</p> <h2 id=references>References<a class=headerlink href=#references title="Permanent link">&para;</a></h2> <ol> <li><a href=https://github.com/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter08/Chapter%208%20-%20Semantic%20Search.ipynb>Hands-On Large Language Models, Chapter 8 - Semantic Search, Jay Alammar &amp; Maarten Grootendorst</a> </li> <li>AI Expert Bootcamp, Great Learning </li> </ol> </article> </div> </div> <a href=# class="md-top md-icon" data-md-component=top data-md-state=hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"/></svg> Back to top </a> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../Agentic%20AI/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Agentic AI" rel=prev> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </div> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> Previous </span> Agentic AI </div> </div> </a> <a href=../../R/Linear-programming/ class="md-footer__link md-footer__link--next" aria-label="Next: Linear Programming (R)" rel=next> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> Next </span> Linear Programming (R) </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright> <div class=md-footer-copyright__highlight> <img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png> </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-footer-social> <a href=https://github.com/HarshaAsh target=_blank rel=noopener title=github.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </a> <a href=https://www.linkedin.com/in/sri-harsha-achyuthuni/ target=_blank rel=noopener title=www.linkedin.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg> </a> <a href=https://www.instagram.com/harshaash_com/ target=_blank rel=noopener title=www.instagram.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M224.1 141c-63.6 0-114.9 51.3-114.9 114.9s51.3 114.9 114.9 114.9S339 319.5 339 255.9 287.7 141 224.1 141zm0 189.6c-41.1 0-74.7-33.5-74.7-74.7s33.5-74.7 74.7-74.7 74.7 33.5 74.7 74.7-33.6 74.7-74.7 74.7zm146.4-194.3c0 14.9-12 26.8-26.8 26.8-14.9 0-26.8-12-26.8-26.8s12-26.8 26.8-26.8 26.8 12 26.8 26.8zm76.1 27.2c-1.7-35.9-9.9-67.7-36.2-93.9-26.2-26.2-58-34.4-93.9-36.2-37-2.1-147.9-2.1-184.9 0-35.8 1.7-67.6 9.9-93.9 36.1s-34.4 58-36.2 93.9c-2.1 37-2.1 147.9 0 184.9 1.7 35.9 9.9 67.7 36.2 93.9s58 34.4 93.9 36.2c37 2.1 147.9 2.1 184.9 0 35.9-1.7 67.7-9.9 93.9-36.2 26.2-26.2 34.4-58 36.2-93.9 2.1-37 2.1-147.8 0-184.8zM398.8 388c-7.8 19.6-22.9 34.7-42.6 42.6-29.5 11.7-99.5 9-132.1 9s-102.7 2.6-132.1-9c-19.6-7.8-34.7-22.9-42.6-42.6-11.7-29.5-9-99.5-9-132.1s-2.6-102.7 9-132.1c7.8-19.6 22.9-34.7 42.6-42.6 29.5-11.7 99.5-9 132.1-9s102.7-2.6 132.1 9c19.6 7.8 34.7 22.9 42.6 42.6 11.7 29.5 9 99.5 9 132.1s2.7 102.7-9 132.1z"/></svg> </a> <a href=https://www.facebook.com/sri.harsha.achyuthuni/ target=_blank rel=noopener title=www.facebook.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><path d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.28c-30.8 0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../..", "features": ["content.code.annotate", "content.tabs.link", "header.autohide", "navigation.sections", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest"], "search": "../../assets/javascripts/workers/search.709b4209.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "version": null}</script> <script src=../../assets/javascripts/bundle.56838a2c.min.js></script> </body> </html>